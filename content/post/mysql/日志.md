---
title: "MySQL日志"
description: 
date: 2023-05-03T14:47:17+08:00
license: 
hidden: false
comments: true
draft: false
categories:
  - MySQL
---
# MySQL日志

* undo log（回滚日志）：用于实现事务原子性、MVCC（ReadView + undo log）。
* redo log（重做日志）：用于实现事务的持久性、数据掉电恢复。
* binlog（归档日志）：数据备份、主从同步。

## undo log
一条记录的每一次更新操作产生的 undo log 格式都有一个 roll_pointer 指针和一个 trx_id 事务id：

<div style="text-align:center"><img width=500px src=../../assets/img/版本链.webp /></div>

* 通过 trx_id 可以知道该记录是被哪个事务修改的；
* 通过 roll_pointer 指针可以将这些 undo log 串成一个链表，这个链表就被称为**版本链**；

> TIP
>
> undo log刷盘和数据页的刷盘逻辑是一样的，通过redo log保证数据持久化.
> **buffer pool 中有 undo 页**，对 undo 页的修改也都会记录到 redo log。redo log 会每秒刷盘，提交事务时也会刷盘，数据页和 undo 页都是靠这个机制保证持久化的。


## buffer pool

buffer pool所在的位置：
<div style="text-align:center"><img width=250px src=../../assets/img/缓冲池.drawio.webp /></div>

[buffer pool结构](https://xiaolincoding.com/mysql/buffer_pool/buffer_pool.html)：
<div style="text-align:center"><img width=450px src=../../assets/img/bufferpool内容.drawio.webp /></div>

* 当修改数据时，如果数据存在于 Buffer Pool 中，那直接修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页（该页的内存数据和磁盘上的数据已经不一致），为了减少磁盘I/O，不会立即将脏页写入磁盘，**后续由后台线程选择一个合适的时机将脏页写入到磁盘**。这就是 **WAL （Write-Ahead Logging）技术**。
* 开启事务后，InnoDB 层更新记录前，首先要记录相应的 undo log，如果是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面。

## redo log

### 为什么要redo log

Buffer Pool 是提高了读写效率没错，但是问题来了，Buffer Pool 是基于内存的，而内存总是不可靠，万一断电重启，还没来得及落盘的脏页数据就会丢失。

**为了防止断电导致数据丢失的问题**，当有一条记录需要更新的时候，InnoDB 引擎就会先更新内存（同时标记为脏页），然后将本次对这个页的修改以 redo log 的形式记录下来，这个时候更新就算完成了。
<div style="text-align:center"><img width=500px src=../../assets/img/wal.webp /></div>

> TIP
>
> 被修改 Undo 页面，需要记录对应 redo log：
> 开启事务后，InnoDB 层更新记录前，首先要记录相应的 undo log，如果是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面。
不过，在内存修改该 Undo 页面后，需要记录对应的 redo log。

写入 redo log 的方式使用了**追加**操作， 所以磁盘操作是**顺序写**，而写入数据需要先找到写入位置，然后才写到磁盘，所以磁盘操作是随机写。
磁盘的「顺序写 」比「随机写」 高效的多，因此 redo log 写入磁盘的开销更小。

### redo log持久化机制

* 主要有下面几个时机：
  * MySQL 正常关闭时；
  * 当 redo log buffer 中记录的写入量大于 redo log buffer 内存空间的一半时，会触发落盘；
  * InnoDB 的后台线程每隔 1 秒，将 redo log buffer 持久化到磁盘。
  * 每次事务提交时都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘（这个策略可由 innodb_flush_log_at_trx_commit 参数控制，下面会说）。

如何通过`innodb_flush_log_at_trx_commit`进行刷盘时机控制：

![redo log持久化机制1](../../assets/img/innodb_flush_log_at_trx_commit.drawio.webp)

> TIP
> 
> InnoDB 的后台线程每隔 1 秒：
> 
> 针对参数 0 ：会把缓存在 redo log buffer 中的 redo log ，通过调用 write() 写到操作系统的 Page Cache，然后调用 fsync() 持久化到磁盘。所以参数为 0 的策略，MySQL 进程的崩溃会导致上一秒钟所有事务数据的丢失;
> 
> 针对参数 2 ：调用 fsync，将缓存在操作系统中 Page Cache 里的 redo log 持久化到磁盘。所以参数为 2 的策略，较取值为 0 情况下更安全，因为 MySQL 进程的崩溃并不会丢失数据，**只有在操作系统崩溃或者系统断电的情况下**，上一秒钟所有事务数据才可能丢失。
> 
> ![redo log持久化机制2](../../assets/img/innodb_flush_log_at_trx_commit2.drawio.webp)


### redo log 写满了怎么办
redo log 是循环写的方式，相当于一个环形，InnoDB 用 write pos 表示 redo log 当前记录写到的位置，用 checkpoint 表示当前要擦除的位置：
<div style="text-align:center"><img width=450px src=../../assets/img/checkpoint.webp /></div>

如果 write pos 追上了 checkpoint，就意味着 redo log 文件满了，这时 MySQL 不能再执行新的更新操作，也就是说 **MySQL 会被阻塞**（因此所以针对并发量大的系统，适当设置 redo log 的文件大小非常重要），此时会停下来将 Buffer Pool 中的**脏页刷新到磁盘**中，然后标记 redo log 哪些记录可以被擦除，接着对旧的 redo log 记录进行擦除，等擦除完旧记录腾出了空间，checkpoint 就会往后移动（图中顺时针），然后 MySQL 恢复正常运行，继续执行新的更新操作。


## binlog
MySQL 在完成一条更新操作后，**Server 层**还会生成一条 binlog，等之后**事务提交的时候**，会将该事物执行过程中产生的所有 binlog 统一写 入 binlog 文件。

### redo log 和 binlog的比较
* binlog 是 MySQL 的 Server 层实现的日志，所有存储引擎都可以使用；redo log 是 Innodb 存储引擎实现的日志；
* binlog 有 3 种格式类型，分别是 STATEMENT（默认格式，相当于记录逻辑操作）、ROW、 MIXED。（STATEMENT 有动态函数的问题）
  redo log 是物理日志，记录的是在某个数据页做了什么修改；
* binlog 是追加写，写满一个文件，就创建一个新的文件继续写，不会覆盖以前的日志，保存的是**全量**的日志。redo log 是循环写，日志空间大小是固定。
* binlog 用于备份恢复、主从复制；redo log 用于掉电等故障恢复。

### 主从复制
<div style="text-align:center"><img width=450px src=../../assets/img/主从复制过程.drawio.webp /></div>
在完成主从复制之后，可以在写数据时只写主库，在读数据时只读从库，这样即使写请求会锁表或者锁记录，也不会影响读请求的执行。

主从复制模型：同步、异步（默认）、半同步（半数复制成功即认为成功）

### 刷盘时机
事务执行过程中，先把日志写到 binlog cache（Server 层的 cache），**事务提交的时候，再把 binlog cache 写到 binlog 文件中**。
<div style="text-align:center"><img width=450px src=../../assets/img/binlogcache.drawio.webp /></div>

> MySQL提供一个 sync_binlog 参数来控制数据库的 binlog 刷到磁盘上的频率：
> * sync_binlog = 0 的时候，表示每次提交事务都只 write，不 fsync，后续交由操作系统决定何时将数据持久化到磁盘；
> * sync_binlog = 1 的时候，表示每次提交事务都会 write，然后马上执行 fsync；
> * sync_binlog =N(N>1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。 

[page cache介绍](https://xiaolincoding.com/os/6_file_system/pagecache.html#page-cache)

## 一个update语句的执行流程（从日志角度看）
`UPDATE t_user SET name = 'xiaolin' WHERE id = 1; `

* 执行器负责具体执行，会调用存储引擎的接口，通过主键索引树搜索获取 id = 1 这一行记录：如果数据在buffer pool中，则直接返回给执行器，否则从磁盘加载数据页到pool中；
* 执行器得到聚簇索引记录后，会看一下更新前的记录和更新后的记录是否一样：一样的话就不用执行了，否则交给引擎层去处理；
* 开启事务，记录undo log，写入buffer pool的undo log页，同时记录redo log；
* 更新内存数据，标记为脏页，记录redo log，不直接将脏页刷盘，等待合适的时机再将脏页数据持久化；
* 语句执行完毕后，记录binlog，将binlog保存到binlog cache中，等待事务提交后（涉及两阶段提交）将binlog cache中的数据刷盘。
* 事务提交（两阶段提交为例）：
  * prepare 阶段：将 redo log 对应的事务状态设置为 prepare，然后将 redo log 刷新到硬盘；
  * commit 阶段：将 binlog 刷新到磁盘，接着调用引擎的提交事务接口，将 redo log 状态设置为 commit（将事务设置为 commit 状态后，刷入到磁盘 redo log 文件，更新redo log commit阶段标记）； 

## 两阶段提交

<div style="text-align:center"><img width=500px src=../../assets/img/两阶段提交.drawio.webp /></div>

### 为什么需要两阶段提交
事务提交后，redo log 和 binlog 都要持久化到磁盘，但是这两个是独立的逻辑，可能出现**半成功的状态**，这样就造成两份日志之间的逻辑不一致。

### 过程
* prepare 阶段：将 XID（内部 XA 事务的 ID） 写入到 redo log，同时将 redo log 对应的事务状态设置为 prepare，然后将 redo log 持久化到磁盘（innodb_flush_log_at_trx_commit = 1 的作用）；

* commit 阶段：把 XID 写入到 binlog，然后将 binlog 持久化到磁盘（sync_binlog = 1 的作用），接着调用引擎的提交事务接口，将 redo log 状态设置为 commit，此时该状态并不需要持久化到磁盘，只需要 write 到文件系统的 page cache 中就够了，因为只要 binlog 写磁盘成功，就算 redo log 的状态还是 prepare 也没有关系，一样会被认为事务已经执行成功；

> TIP
>
> 事务没提交的时候，redo log 可能会被持久化到磁盘：
> 事务执行中间过程的 redo log 也是直接写在 redo log buffer 中的，这些缓存在 redo log buffer 里的 redo log 也会被「后台线程」每隔一秒一起持久化到磁盘。
> 也就是说，事务没提交的时候，redo log 也是可能被持久化到磁盘的。但是，若binlog还没刷盘，则还是认为事务失败，日志需要回滚。

### 两阶段提交的缺点
* 磁盘I/O压力大
  * 使用[组提交](https://xiaolincoding.com/mysql/log/how_update.html)可以减少I/O次数
  * 将 sync_binlog 设置为大于 1 的值（比较常见是 100~1000），表示每次提交事务都 write，但累积 N 个事务后才 fsync。
  * 将 innodb_flush_log_at_trx_commit 设置为 2，由OS决定page cache的刷盘时机。
* 锁竞争激烈

[拓展阅读：分布式事务](https://zhuanlan.zhihu.com/p/263555694)
[{"content":"Java技术栈集锦（个人向） rbmonster/learning-note: java开发 面试八股文（个人的面试及工作总结） (github.com)\ndocsify-demo (gitee.io)\nAobingJava/JavaFamily: 【Java面试+Java学习指南】 一份涵盖大部分Java程序员所需要掌握的核心知识。 (github.com)\nJava常识 Java vs C++\nJava 不提供指针来直接访问内存，程序内存更加安全 Java 的类是单继承的，C++ 支持多重继承；虽然 Java 的类不可以多继承，但是接口可以多继承。 Java 有自动内存管理垃圾回收机制(GC)，不需要程序员手动释放无用内存。 C ++同时支持方法重载和操作符重载，但是 Java 只支持方法重载（操作符重载增加了复杂性，这与 Java 最初的设计思想不符）\u0026hellip;\u0026hellip;\n字符常量占 2 个字节; 字符串常量占若干个字节。\n重写：\n方法名、参数列表必须相同，子类方法返回值类型应比父类方法返回值类型更小或相等，抛出的异常范围小于等于父类，访问修饰符范围大于等于父类。 如果父类方法访问修饰符为 private/final/static 则子类就不能重写该方法（同名的子类private叫重新实现该方法），但是被 static 修饰的方法能够被再次声明。 构造方法无法被重写。 数据类型\n基本类型 位数 字节 默认值 取值范围 byte 8 1 0 -128 ~ 127 short 16 2 0 -32768 ~ 32767 int 32 4 0 -2147483648 ~ 2147483647 long 64 8 0L -9223372036854775808 ~ 9223372036854775807 char 16 2 \u0026lsquo;u0000\u0026rsquo; 0 ~ 65535 float 32 4 0f 1.4E-45 ~ 3.4028235E38 double 64 8 0d 4.9E-324 ~ 1.7976931348623157E308 boolean 1 false true、false 对于 boolean，官方文档未明确定义，它依赖于 JVM 厂商的具体实现。逻辑上理解是占用 1 位，但是实际中会考虑计算机高效存储因素。\nJava 的每种基本类型所占存储空间的大小不会像其他大多数语言那样随机器硬件架构的变化而变化。这种所占存储空间大小的不变性是 Java 程序比用其他大多数语言编写的程序更具可移植性的原因之一\nHotSpot 虚拟机引入了 JIT 优化之后，会对对象进行逃逸分析，如果发现某一个对象并没有逃逸到方法外部，那么就可能通过标量替换来实现栈上分配，而避免堆上分配内存。\n如果 HashSet 在对比的时候，同样的 hashCode 有多个对象，它会继续使用 equals() 来判断是否真的相同。也就是说 hashCode 帮助我们大大缩小了查找成本。\n重写 equals() 时必须重写 hashCode() 方法。\nString 中的 equals 方法是被重写过的，比较的是 String 字符串的值是否相等。 Object 的 equals 方法是比较的对象的内存地址。\n对于编译期可以确定值的字符串，也就是常量字符串 ，jvm 会将其存入字符串常量池。并且，字符串常量拼接得到的字符串常量在编译阶段就已经被存放字符串常量池，这个得益于编译器的优化。引用的值在程序编译期是无法确定的，编译器无法对其进行优化。\n字符串使用 final 关键字声明之后，可以让编译器当做常量来处理。\n1 2 3 4 5 6 final String str1 = \u0026#34;str\u0026#34;; final String str2 = \u0026#34;ing\u0026#34;; // 下面两个表达式其实是等价的 String c = \u0026#34;str\u0026#34; + \u0026#34;ing\u0026#34;;// 常量池中的对象 String d = str1 + str2; // 常量池中的对象 System.out.println(c == d);// true 如果 ，编译器在运行时才能知道其确切值的话，就无法对其优化。\n1 2 3 4 5 6 7 8 final String str1 = \u0026#34;str\u0026#34;; final String str2 = getStr(); String c = \u0026#34;str\u0026#34; + \u0026#34;ing\u0026#34;;// 常量池中的对象 String d = str1 + str2; // 在堆上创建的新的对象 System.out.println(c == d);// false public static String getStr() { return \u0026#34;ing\u0026#34;; } 异常：\nChecked Exception 即 受检查异常 ，Java 代码在编译过程中，如果受检查异常没有被 catch或者throws 关键字处理的话，就没办法通过编译。除了RuntimeException及其子类以外，其他的Exception类及其子类都属于受检查异常 。常见的受检查异常有： IO 相关的异常、ClassNotFoundException 、SQLException\u0026hellip;。\nUnchecked Exception 即 不受检查异常 ，Java 代码在编译过程中 ，我们即使不处理不受检查异常也可以正常通过编译。RuntimeException 及其子类都统称为非受检查异常，常见的有：\nNullPointerException(空指针错误) IllegalArgumentException(参数错误比如方法入参类型错误) NumberFormatException（字符串转换为数字格式错误，IllegalArgumentException的子类） ArrayIndexOutOfBoundsException（数组越界错误） ClassCastException（类型转换错误） ArithmeticException（算术错误） SecurityException （安全错误比如权限不够） UnsupportedOperationException(不支持的操作错误比如重复创建同一用户) \u0026hellip;\u0026hellip; finally 块 ： 无论是否捕获或处理异常，finally 块里的语句都会被执行。当在 try 块或 catch 块中遇到 return 语句时，finally 语句块将在方法返回之前被执行。注意：不要在 finally 语句块中使用 return! 当 try 语句和 finally 语句中都有 return 语句时，try 语句块中的 return 语句会被忽略。 在某些情况下，finally 中的代码不会被执行，比如，finally 之前虚拟机被终止运行的话，finally 中的代码就不会被执行。\n在 try-with-resources 语句中，任何 catch 或 finally 块在声明的资源关闭后运行。面对必须要关闭的资源，我们总是应该优先使用 try-with-resources 而不是try-finally。 泛型：\n泛型一般有三种使用方式:泛型类、泛型接口、泛型方法。\n1 2 3 4 5 6 7 public static \u0026lt; E \u0026gt; void printArray( E[] inputArray ) { for ( E element : inputArray ){ System.out.printf( \u0026#34;%s \u0026#34;, element ); } System.out.println(); } 类在实例化时才能真正的传递类型参数，由于静态方法的加载先于类的实例化，也就是说类中的泛型还没有传递真正的类型参数，静态的方法的加载就已经完成了，所以静态泛型方法是没有办法使用类上声明的泛型的，只能使用自己声明的 \u0026lt;E\u0026gt;。\nstatic 变量因为不属于任何对象(Object)，所以无论有没有 transient 关键字修饰，均不会被序列化。\n字符流是由 Java 虚拟机将字节转换得到的，问题就出在这个过程还算是非常耗时，并且，如果我们不知道编码类型就很容易出现乱码问题。所以， I/O 流就干脆提供了一个直接操作字符的接口，方便我们平时对字符进行流操作。\n代理\n静态代理\n静态代理在编译时就将接口、实现类、代理类这些都变成了一个个实际的 class 文件。\n动态代理\nJDK 动态代理有一个最致命的问题是其只能代理实现了接口的类。 CGLIB是一个基于ASM的字节码生成库，它允许我们在运行时对字节码进行修改和动态生成。CGLIB 通过继承方式实现代理。很多知名的开源框架都使用到了CGLIB， 例如 Spring 中的 AOP 模块中：如果目标对象实现了接口，则默认采用 JDK 动态代理，否则采用 CGLIB 动态代理。 比较：\n灵活性 ：动态代理更加灵活，不需要必须实现接口，可以直接代理实现类，并且可以不需要针对每个目标类都创建一个代理类。另外，静态代理中，接口一旦新增加方法，目标对象和代理对象都要进行修改，这是非常麻烦的！\nJVM 层面 ：静态代理在编译时就将接口、实现类、代理类这些都变成了一个个实际的 class 文件。而动态代理是在运行时动态生成类字节码，并加载到 JVM 中的。\nIO\nIO 多路复用模型，通过减少无效的系统调用，减少了对 CPU 资源的消耗。\nTODO\nJava基础 包装类 new Integer(123) 与 Integer.valueOf(123) 的区别在于：\nnew Integer(123) 每次都会新建一个对象；\nInteger.valueOf(123) 会使用缓存池中的对象，多次调用会取得同一个对象的引用。\n包装类的缓存：\nByte,Short,Integer,Long 这 4 种包装类默认创建了数值 [-128，127] 的相应类型的缓存数据，Character 创建了数值在 [0,127] 范围的缓存数据，Boolean 直接返回 True or False。\nvalueOf：\n1 2 3 4 5 6 7 8 9 10 11 12 13 public static Integer valueOf(int i) { if (i \u0026gt;= IntegerCache.low \u0026amp;\u0026amp; i \u0026lt;= IntegerCache.high) return IntegerCache.cache[i + (-IntegerCache.low)]; return new Integer(i); } private static class IntegerCache { static final int low = -128; static final int high; static { // high value may be configured by property int h = 127; } } 超出对应范围仍然会去创建新的对象。\n装箱的过程其实是调用valueOf。\n包装类都为final 不可继承\n序列化和反序列化\n序列化时，并不保存静态变量，这其实比较容易理解，序列化保存的是对象的状态，静态变量属于类的状态，因此 序列化并不保存静态变量。\nTransient 关键字的作用是控制变量的序列化，在变量声明前加上该关键字，可以阻止该变量被序列化到文件中，在被反序列化后，transient 变量的值被设为初始值，如 int 型的是 0，对象型的是 null。\n精度问题\n由于double不能精确表示0.1等数，因此对于一些对精度要求很高的应用场景，不能使用double，要使用BigDecimal。BigDecimal都是不可变的（immutable）的， 在进行每一次四则运算时，都会产生一个新的对象 ，所以在做加减乘除运算时要记得要保存操作后的值。\n字符串相关\n字符串贴近底层，被定义为final，不可被继承\nJVM在堆内存上留出一个称为字符串常量池的特殊区域，不使用new关键字创建的字符串对象存储在堆的字符串常量池部分，使用new关键字创建的字符串对象存储在堆的普通内存部分。\n单线程操作字符串缓冲区下操作大量数据，适用StringBuilder\n注意符号引用：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 String a = \u0026#34;hello2\u0026#34;; String b = \u0026#34;hello\u0026#34;; String c = b + 2; System.out.println((a == c)); // 输出结果为:false。由于有符号引用b的存在，所以 String c = b + 2;不会在编译期间被优化，不会把b+2当做字面常量来处理的。 // 个人理解：因为c不能直接表现为常量池中的字面量，故c经过连接环节，被赋了零值，相当于新建了一个字符串对象，之后在初始化阶段给这个对象赋了真正的值。 String a = \u0026#34;hello2\u0026#34;; final String b = \u0026#34;hello\u0026#34;; String c = b + 2; System.out.println((a == c)); // 输出结果为：true。对于被final修饰的变量，会在class文件常量池中保存一个副本，也就是说不会通过连接而进行访问。 // ==比较的其实就是对象的引用值 java中final属型及初始化问题_myllxy的博客-CSDN博客\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 class Test { final static int a = 1; static int b = 2; static { System.out.println(\u0026#34;访问编译期常量不触发类初始化\u0026#34;); } } public class TestMode { public static void main(String[] args) { System.out.println(Test.a); } } //仅输出1 //若是访问了b，则是1、静态代码块、2 class Price { static Price P = new Price(2.7); static double apple = 20;//加上final或是放到前面去执行，那么输出结果为17.3 double Price; public Price(double orange) { Price = apple - orange; } } class Main { public static void main(String[] args) { System.out.println(Price.P.Price);//结果为-2.7 } } //这个程序中，在类加载阶段的准备阶段p和apple会被编译器赋予对应类型的默认初值（null和0.0），在随后的类加载的初始化阶段，由于static字段执行顺序是由字段在源文件中出现的顺序决定的，所以会先执行new Price(2.7)，分配对象空间并对其做初始化，在这个时候apple的值还是0.0，所以最终结果为-2.7。 装包与拆包\n1 2 3 4 5 6 7 8 9 Integer a = -128; Integer b = -128; System.out.println(a == b); //true Integer a = -129; Integer b = -129; System.out.println(a == b); //false //Integer在-128至127这个范围内是直接从IntegerCache里面取，否则创建新的对象 内存分配 方法区\n存放装载的类数据信息，包括： 基本信息：每个类的全限定名、每个类的直接超类的全限定名、该类是类还是接口、该类型的访问修饰符、直接超接口的全限定名的有序列表。 每个已装载类的详细信息：运行时常量池、字段信息、方法信息、静态变量、到类classloader的引用、到类class的引用。\n栈内存 Java栈内存由局部变量区、操作数栈、帧数据区组成，以帧的形式存放本地方法的调用状态（包括方法调用的参数、局部变量、中间结果……）。\n堆内存 堆内存用来存放由new创建的对象和数组。在堆中分配的内存，由Java虚拟机的自动垃圾回收器来管理。\n本地方法栈内存 Java通过Java本地接口JNI（Java Native Interface）来调用其它语言编写的程序，在Java里面用native修饰符来描述一个方法是本地方法。\n静态 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 //在创建静态内部类的实例时，不需要创建外部类的实例。 public class Outer { static class Inner { int a = 0; // 实例变量a static int b = 0; // 静态变量 b } } class OtherClass { Outer.Inner oi = new Outer.Inner(); int a2 = oi.a; // 访问实例成员 int b2 = Outer.Inner.b; // 访问静态成员 } //静态内部类可以直接访问外部类的静态成员，如果要访问外部类的实例成员，则需要通过外部类的实例去访问。 public class Outer { int a = 0; // 实例变量 static int b = 0; // 静态变量 static class Inner { Outer o = new Outer; int a2 = o.a; // 访问实例变量 int b2 = b; // 访问静态变量 } } 注意，静态变量或是静态方法和类有关，在实现继承使用多态特性的时候，静态结果和接收方类有关，这要和一般方法区别，因为复写之后，子类一般方法会覆盖父类实现，导致多态后出现子类效果。\n只能访问所属类的静态字段和静态方法，方法中不能有 this 和 super 关键字，这两个关键字与具体对象关联。\n初始化顺序 静态变量和静态语句块的初始化顺序取决于它们在代码中的顺序。\n父类（静态变量、静态语句块）\n子类（静态变量、静态语句块）\n父类（实例变量、普通语句块）\n父类（构造函数）\n子类（实例变量、普通语句块）\n子类（构造函数）\n监听器 如果当前线程没有获得一个对象的监听器，调用该方法就会抛出一个IllegalMonitorStateException\n获得当前对象的监听器的方式： 执行此对象的同步 (Sychronized) 实例方法 执行在此对象上进行同步的 synchronized 语句的方法 对于 Class 类型的对象，执行该类的同步静态方法 修饰符和继承 如果不加访问修饰符，表示包级可见。 protected 用于修饰成员，表示在继承体系中成员对于子类可见，但是这个访问修饰符对于类没有意义。 private 仅自己可见 public 所有均可见 private 和 protected 不能修饰类。\n如果子类的方法重写了父类的方法，那么子类中该方法的访问级别不允许低于父类的访问级别。\n接口和抽象类 接口的字段默认都是 static 和 final 的。 抽象类中可以有明确的方法体。抽象方法只能出现在抽象类中，并且要被抽象类的子类所实现。 抽象类： 拓展继承该抽象类的模块的类的行为功能（开放闭合原则） 接口：约束继承该接口的类行为（依赖倒置原则） 泛型 在调用泛型方法时，可以指定泛型，也可以不指定泛型。\n在不指定泛型的情况下，泛型变量的类型为该方法中的几种类型的同一父类的最小级，直到 Object。 在指定泛型的情况下，该方法的几种类型必须是该泛型的实例的类型或者其子类。 类型擦除带来的问题及解决方案\n编译器针对引用检查泛型类型，再进行擦除\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 public class Test { public static void main(String[] args) { ArrayList\u0026lt;String\u0026gt; list1 = new ArrayList(); list1.add(\u0026#34;1\u0026#34;); //编译通过 list1.add(1); //编译错误 String str1 = list1.get(0); //返回类型就是String ArrayList list2 = new ArrayList\u0026lt;String\u0026gt;(); list2.add(\u0026#34;1\u0026#34;); //编译通过 list2.add(1); //编译通过 Object object = list2.get(0); //返回类型就是Object //直接用对象要保证类型符合（我觉得可以理解为返回了一个同类型的引用） new ArrayList\u0026lt;String\u0026gt;().add(\u0026#34;11\u0026#34;); //编译通过 new ArrayList\u0026lt;String\u0026gt;().add(22); //编译错误 String str2 = new ArrayList\u0026lt;String\u0026gt;().get(0); //返回类型就是String } } 类型检查就是针对引用的\n1 2 3 4 5 ArrayList\u0026lt;String\u0026gt; list1 = new ArrayList\u0026lt;Object\u0026gt;(); //编译错误 ArrayList\u0026lt;Object\u0026gt; list2 = new ArrayList\u0026lt;String\u0026gt;(); //编译错误 //第一个比较好理解，会出现classCast的异常 //第二个是因为，泛型的出现就是为了解决类型转换的问题。我们使用了泛型，到头来，还是要自己强转，违背了泛型设计的初衷。所以java不允许这么干。再说，你如果又用list2往里面add()新的对象，那么到时候取得时候，我怎么知道我取出来的到底是String类型的，还是Object类型的呢？ 桥方法与泛型类继承\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 class A\u0026lt;T\u0026gt; { private T val; public T getVal() { return this.val; } public void setVal(T val) { this.val = val; } } class B extends A\u0026lt;String\u0026gt; { @Override public String getVal() { // TODO Auto-generated method stub return super.getVal(); } @Override public void setVal(String val) { // TODO Auto-generated method stub super.setVal(val); } } 虽说通过类型擦除，父类参数类型应该是Object，子类应该要继承这个Object类型的成员，但是JVM采用了桥方法，将原本从父类继承而来的成员方法(public Object getVal() ;）中插入调用子类重写的(public String getVal() ;)此时注解Override其实是假象，真正意义为重载，实际编译后子类中有4个方法。而桥方法的内部实现，就只是去调用我们自己重写的那两个方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 public void setVal(java.lang.String); Code: 0: aload_0 1: aload_1 2: invokespecial #4 // Method A.setVal:(Ljava/lang/Object;)V 5: return public void setVal(java.lang.Object); Code: 0: aload_0 1: aload_1 2: checkcast #3 // class java/lang/String 5: invokevirtual #5 // Method setVal:(Ljava/lang/String;)V 8: return 此处需要注意，虽然setVal是理解为重载，但是getVal却因为协变而可以实现这个效果，子类中的桥方法Object getValue()和Date getValue()是同时存在的，可是如果是常规的两个方法，他们的方法签名是一样的，也就是说虚拟机根本不能分别这两个方法。如果是我们自己编写Java代码，这样的代码是无法通过编译器的检查的，但是虚拟机却是允许这样做的，因为虚拟机通过参数类型和返回类型来确定一个方法，所以编译器为了实现泛型的多态允许自己做这个看起来“不合法”的事情，然后交给虚拟器去区别。\n虚拟机巧妙的使用了桥方法，来解决了类型擦除和多态的冲突。\n泛型类型变量不能是基本类型\n由于类型擦除，ArrayList ar=new ArrayList\u0026lt;\u0026gt;();\n只剩下原始类型，泛型String不存在了，因此，在编译期间使用（ar instanceof ArrayList）的做法是错误的\n泛型类中的静态方法和静态变量不可以使用泛型类所声明的泛型类型参数\n1 2 3 4 5 6 public class Test2\u0026lt;T\u0026gt; { public static T one; //编译错误 public static T show(T one){ //编译错误 return null; } } 但是，这种是可以的！！！\n1 2 3 4 5 6 public class Test2\u0026lt;T\u0026gt; { public static \u0026lt;T \u0026gt;T show(T one){ //这是正确的，这个T用的是方法自己的T return null; } } 逆变、协变、不变 Java泛型的协变与逆变 - 掘金 (juejin.cn)\n1 2 3 4 5 6 7 8 9 10 11 12 // 调用方法result = method(n)； // 根据Liskov替换原则，传入形参n的类型应为method形参的子类型， // 即typeof(n) ≤ typeof(method\u0026#39;s parameter)； // result应为method返回值的基类型，即typeof(methods\u0026#39;s return) ≤ typeof(result)： static Number method(Number num) { return 1; } Object result = method(new Integer(2)); //correct Number result = method(new Object()); //error Integer result = method(new Integer(2)); //error 泛型是不变的，借助通配符可以实现“协变”\nList\u0026lt;?\u0026gt;不能add，get出来也是Object类型。它同时具有协变和逆变的两种性质，上界是Object，但不能调用add方法。\n注解 作用于代码：\n@Override\n@Deprecated\n@SuppressWarnings\n作用于其他注解的注解（元注解）：\n@Documented\n@Retention\n@Target\n@Inherited\n线程 阻塞是被动的，它是在等待获取 monitor lock。而等待是主动的，通过调用 Object.wait() 等方法进入。\n创建线程的开销：JVM 在背后帮我们做了哪些事情：\n它为一个线程栈分配内存，该栈为每个线程方法调用保存一个栈帧 每一栈帧由一个局部变量数组、返回值、操作数堆栈和常量池引用组成 一些支持本机方法的 jvm 也会分配一个本机堆栈 每个线程获得一个程序计数器，告诉它当前处理器执行的指令是什么 系统创建一个与Java线程对应的本机线程 将与线程相关的描述符添加到JVM内部数据结构中 线程共享堆和方法区 其他 方法调用 方法体传递参数时，无论是值还是对象都是“值”传递。引用类型传递的是引用变量的地址。\n面向对象的三大特性 封装：封装是指把一个对象的状态信息（也就是属性）隐藏在对象内部，不允许外部对象直接访问对象的内部信息。\n继承：不同类型的对象，相互之间经常有一定数量的共同点。\n多态：表示一个对象具有多种的状态。具体表现为父类的引用指向子类的实例。\n多态的特点:\n对象类型和引用类型之间具有继承（类）/实现（接口）的关系； 引用类型变量发出的方法调用的到底是哪个类中的方法，必须在程序运行期间才能确定； 多态不能调用“只在子类存在但在父类不存在”的方法； 如果子类重写了父类的方法，真正执行的是子类覆盖的方法，如果子类没有覆盖父类的方法，执行的是父类的方法。 集合 ArrayList 以无参数构造方法创建 ArrayList 时，实际上初始化赋值的是一个空数组。当真正对数组进行添加元素操作时，才真正分配容量。即向数组中添加第一个元素时，数组容量扩为 10。 ArrayList 每次扩容之后容量都会变为原来的 1.5 倍左右 HashMap HashMap的长度为什么是 2 的幂次方**?\n数组下标的计算方法是“ (n - 1) \u0026amp; hash”\n采用二进制位操作 \u0026amp;，相对于%能够提高运算效率，这就解释了 HashMap 的长度为什么是 2 的幂次方。\n相比于之前的版本， JDK1.8 之后在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间。\nloadFactor 太大导致查找元素效率低，太小导致数组的利用率低，存放的数据会很分散。loadFactor 的默认值为 0.75f 是官方给出的一个比较好的临界值。\nConcurrentHashMap ConcurrentHashMap 和 Hashtable 的区别 ConcurrentHashMap 和 Hashtable 的区别主要体现在实现线程安全的方式上不同。\n底层数据结构： JDK1.7 的 ConcurrentHashMap 底层采用 分段的数组+链表 实现，JDK1.8 采用的数据结构跟 HashMap1.8 的结构一样，数组+链表/红黑二叉树。Hashtable 和 JDK1.8 之前的 HashMap 的底层数据结构类似都是采用 数组+链表 的形式，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的； 实现线程安全的方式（重要）： ① 在 JDK1.7 的时候，ConcurrentHashMap（分段锁） 对整个桶数组进行了分割分段(Segment)，每一把锁只锁容器其中一部分数据，多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率。 到了 JDK1.8 的时候已经摒弃了 Segment 的概念，而是直接用 Node 数组+链表+红黑树的数据结构来实现，并发控制使用 synchronized 和 CAS 来操作。（JDK1.6 以后 对 synchronized 锁做了很多优化） 整个看起来就像是优化过且线程安全的 HashMap，虽然在 JDK1.8 中还能看到 Segment 的数据结构，但是已经简化了属性，只是为了兼容旧版本；② Hashtable(同一把锁) :使用 synchronized 来保证线程安全，效率非常低下。当一个线程访问同步方法时，其他线程也访问同步方法，可能会进入阻塞或轮询状态，如使用 put 添加元素，另一个线程不能使用 put 添加元素，也不能使用 get，竞争会越来越激烈效率越低。 JDK1.7的ConcurrentHashMap\nJDK1.8 的 ConcurrentHashMap：\n利用 ==CAS + synchronized== 来保证并发更新的安全 底层使用==数组+链表+红黑树==来实现\nCopyOnWriteArrayList 读取操作没有任何同步控制和锁操作，理由就是内部数组 array 不会发生修改，只会被另外一个 array 替换，因此可以保证数据安全。\nCopyOnWriteArrayList 写入操作 add()方法在添加集合的时候加了锁，保证了同步，避免了多线程写的时候会 copy 出多个副本出来。\n操作注意 使用集合转数组的方法，必须使用集合的 toArray(T[] array)，传入的是类型完全一致、长度为 0 的空数组。\nArrays.asList()是泛型方法，传递的数组必须是对象数组，而不是基本类型。\n使用工具类 Arrays.asList() 把数组转换成集合时，不能使用其修改集合相关的方法， 它的 add/remove/clear 方法会抛出 UnsupportedOperationException 异常。Arrays.asList() 方法返回的并不是 java.util.ArrayList ，而是 java.util.Arrays 的一个内部类,这个内部类并没有实现集合的修改方法或者说并没有重写这些方法。\n正确的将数组转换为 ArrayList：\n手动加入\n1 List list = new ArrayList\u0026lt;\u0026gt;(Arrays.asList(\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;)) 使用 Java8 的 Stream(推荐)\n1 2 3 4 5 Integer [] myArray = { 1, 2, 3 }; List myList = Arrays.stream(myArray).collect(Collectors.toList()); //基本类型也可以实现转换（依赖boxed的装箱操作） int [] myArray2 = { 1, 2, 3 }; List myList = Arrays.stream(myArray2).boxed().collect(Collectors.toList()); 使用 Guava\n使用 Apache Commons Collections\n使用 Java9 的 List.of()方法\nIO IO模型 同步阻塞IO（Blocking IO）\n在内核进行IO执行的两个阶段（内核缓冲区数据、用户缓冲区数据），用户线程都被block。\n同步非阻塞NIO（None Blocking IO）\n在内核数据没有准备好的阶段，用户线程发起IO请求时，立即返回。用户线程需要不断地发起IO系统调用。内核数据到达后，用户线程发起系统调用，用户线程阻塞。内核开始复制数据。它就会将数据从kernel内核缓冲区，拷贝到用户缓冲区（用户内存），然后kernel返回结果。\nIO多路复用模型(I/O multiplexing）\nselect/poll/epoll原理_哔哩哔哩_bilibili\nselect\n准备文件描述符fd集合，使用fdset将rset（bitmap）中对应fd的位置置为1，并复制到内核区域，内核遍历判断rset对应的fd是否有数据，若有则返回，没有的话就阻塞。内核将fd位置位表示有数据了，返回到用户态，再进行一次遍历，读出被置位的fd，读出数据。受限于bitmap的长度，监听的文件描述符是有限的（1024）。rset不能重用，每次处理要传新的。\npoll\n为了解决受限长度的问题，poll使用一个可重用的结构pollfd（fd、events、revents），其他的逻辑和select一样。events表征此时是什么事件，比如读事件、写事件。revents表示是否有数据了。\nepoll\nEPOLL原理详解（图文并茂） - Big_Chuan - 博客园 (cnblogs.com)\n调用epoll_create，内核会创建一个eventpoll对象（也就是程序中epfd所代表的对象）。eventpoll对象也是文件系统中的一员，和socket一样，它也会有等待队列。 通过 epoll_ctl 添加 Sock1、Sock2 和 Sock3 的监视，内核会将 eventpoll的引用添加到这三个 Socket 的等待队列中。（加入到红黑树中，重复添加的事件就可以通过红黑树而高效地识别出来） 当Socket收到数据之后，中断程序会执行将Socket的引用添加到eventpoll对象的rdlist就绪列表中。 假设计算机中正在运行进程 A 和进程 B、C，在某时刻进程 A 运行到了 epoll_wait 语句，会将进程A添加到eventpoll的等待队列中。 当 Socket 接收到数据，中断程序一方面修改 Rdlist，另一方面唤醒 eventpoll 等待队列中的进程，进程 A 再次进入运行状态。因为Soket包含eventpoll对象的引用，因此可以直接操作eventpoll对象。 异步IO模型（asynchronous IO）\n在内核kernel的等待数据和复制数据的两个阶段，用户线程都不是block(阻塞)的。用户线程需要接受kernel的IO操作完成的事件，或者说注册IO操作完成的回调函数，到操作系统的内核。所以说，异步IO有的时候，也叫做信号驱动 IO 。\nBIO是面向流的，NIO是面向缓冲区的；BIO的各种流是阻塞的。而NIO是非阻塞的；BIO的Stream是单向的，而NIO的channel是双向的。\nmmap\nLinux通过内存映像机制来提供用户程序对内存直接访问的能力。内存映像的意思是把内核中特定部分的内存空间映射到用户级程序的内存空间去。也就是说，用户空间和内核空间共享一块相同的内存。这样做的直观效果显而易见：内核在这块地址内存储变更的任何数据，用户可以立即发现和使用，根本无须数据拷贝。\nNetty Netty 是一个 基于 NIO 的 client-server(客户端服务器)框架，使用它可以快速简单地开发网络应用程序。它极大地简化并优化了 TCP 和 UDP 套接字服务器等网络编程,并且性能以及安全性等很多方面甚至都要更好。支持多种协议 如 FTP，SMTP，HTTP 以及各种二进制和基于文本的传统协议。\nNetty高性能表现\nIO 线程模型：同步非阻塞，用最少的资源做更多的事。 内存零拷贝：尽量减少不必要的内存拷贝，实现了更高效率的传输。 内存池设计：申请的内存可以重用，主要指直接内存。内部实现是用一颗二叉查找树管理内存分配情况。 串形化处理读写：避免使用锁带来的性能开销。 高性能序列化协议：支持 protobuf 等高性能序列化协议。 重要组件 Channel：Netty 网络操作抽象类，包括基本的 I/O 操作，如 bind、connect、read、write 等。 EventLoop：主要是配合 Channel 处理 I/O 操作，用来处理连接的生命周期中所发生的事情。 ChannelFuture：Netty 框架中所有的 I/O 操作都为异步的，因此我们需要 ChannelFuture 的 addListener()注册一个 ChannelFutureListener 监听事件，当操作执行成功或者失败时，监听就会自动触发返回结果。 ChannelHandler：充当了所有处理入站和出站数据的逻辑容器。ChannelHandler 主要用来处理各种事件，这里的事件很广泛，比如可以是连接、数据接收、异常、数据转换等。 ChannelPipeline：为 ChannelHandler 链提供了容器，当 channel 创建时，就会被自动分配到它专属的 ChannelPipeline，这个关联是永久性的。 零拷贝 Netty 的传输依赖于零拷贝特性，尽量减少不必要的内存拷贝，实现了更高效率的传输。\n传统数据拷贝过程\n仅CPU方式\nCPU+DMA方式\n目前来看，零拷贝技术的几个实现手段包括：mmap+write、sendfile、sendfile+DMA收集、splice等。\nmmap mmap是Linux提供的一种内存映射文件的机制，它实现了将内核中读缓冲区地址与用户空间缓冲区地址进行映射，从而实现内核缓冲区与用户缓冲区的共享。这样就减少了一次用户态和内核态的CPU拷贝，但是在内核空间内仍然有一次CPU拷贝，而且状态切换次数并没有减少。mmap对大文件传输有一定优势，但是小文件可能出现碎片，并且在多个进程同时操作文件时可能产生引发coredump的signal。\nsendfile sendfile方式只使用一个函数就可以完成之前的read+write 和 mmap+write的功能，这样就少了2次状态切换，由于数据不经过用户缓冲区，因此该数据无法被修改。\n优化\n升级后的sendfile将内核空间缓冲区中对应的数据描述信息（文件描述符、地址偏移量等信息）记录到socket缓冲区中。DMA控制器根据socket缓冲区中的地址和偏移量将数据从内核缓冲区拷贝到网卡中，从而省去了内核空间中仅剩1次CPU拷贝。\n这种方式有2次状态切换、0次CPU拷贝、2次DMA拷贝，但是仍然无法对数据进行修改，并且需要硬件层面DMA的支持，并且sendfile只能将文件数据拷贝到socket描述符上，有一定的局限性。\nsplice splice 系统调用可以在内核缓冲区和socket缓冲区之间建立管道来传输数据，避免了两者之间的 CPU 拷贝操作。\nsplice也有一些局限，它的两个文件描述符参数中有一个必须是管道设备。\nReactor模式 进击的NIO！Reactor模式！ (qq.com)\n单Reactor单线程 只有一个select循环接收请求，客户端（client）注册进来由Reactor接收注册事件，然后再由reactor分发（dispatch）出去，由下面的处理器（Handler）去处理。只要其中一个Handler方法阻塞了，那就会导致所有的client的Handler都被阻塞了，也会导致注册事件也无法处理，无法接收新的请求。\n单Reactor多线程 多线程Reactor模式在Handler读写处理时，交给工作线程池处理，不会导致Reactor无法执行，因为Reactor分发和Handler处理是分开的，能充分地利用资源。从而提升应用的性能。\n缺点：Reactor只在主线程中运行，承担所有事件的监听和响应，如果短时间的高并发场景下，依然会造成性能瓶颈。\n多Reactor多线程 mainReactor 主要是用来处理客户端请求连接建立的操作。subReactor主要做和建立起来的连接做数据交互和事件业务处理操作，每个subReactor一个线程来处理。\n![](../../assets/img/java/截屏2022-07-31 16.18.21.png)\nTCP粘包拆包 TCP是以流的方式来处理数据，一个完整的包可能会被TCP拆分成多个包进行发送，也可能把小的封装成一个大的数据包发送。应用程序写入的字节大小大于套接字发送缓冲区的大小，会发生拆包现象，而应用程序写入数据小于套接字缓冲区大小，网卡将应用多次写入的数据发送到网络上，这将会发生粘包现象。\n可以使用消息定长：FixedLengthFrameDecoder类，或在消息末尾加上特殊字符分割，可以使用自定义的序列化编解码器。\n专门针对 Java 语言的：Kryo，FST 等等 跨语言的：Protostuff（基于 protobuf 发展而来），ProtoBuf，Thrift，Avro，MsgPack 等等 Netty的零拷贝 Netty 的接收和发送 ByteBuffer 采用 DIRECT BUFFERS，使用堆外直接内存进行 Socket 读写，不需要进行字节缓冲区的二次拷贝。如果使用传统的堆内存（HEAP BUFFERS）进行 Socket 读写，JVM 会将堆内存 Buffer 拷贝一份到直接内存中，然后才写入 Socket 中。相比于堆外直接内存，消息在发送过程中多了一次缓冲区的内存拷贝。 Netty 提供了组合 Buffer 对象，可以聚合多个 ByteBuffer 对象，用户可以像操作一个 Buffer 那样方便的对组合 Buffer 进行操作，避免了传统通过内存拷贝的方式将几个小 Buffer 合并成一个大的 Buffer。 Netty 的文件传输采用了 transferTo 方法，它可以直接将文件缓冲区的数据发送到目标 Channel，避免了传统通过循环 write 方式导致的内存拷贝问题。 长连接与心跳机制 TCP 在进行读写之前，server 与 client 之间必须提前建立一个连接。建立连接的过程，需要我们常说的三次握手，释放/关闭连接的话需要四次挥手。这个过程是比较消耗网络资源并且有时间延迟的。短连接说的就是 server 端 与 client 端建立连接之后，读写完成之后就关闭掉连接，如果下一次再要互相发送消息，就要重新连接。\n长连接说的就是 client 向 server 双方建立连接之后，即使 client 与 server 完成一次读写，它们之间的连接并不会主动关闭，后续的读写操作会继续使用这个连接。长连接的可以省去较多的 TCP 建立和关闭的操作，降低对网络资源的依赖，节约时间。对于频繁请求资源的客户来说，非常适用长连接。\n在 TCP 保持长连接的过程中，可能会出现断网等网络异常出现，异常发生的时候， client 与 server 之间如果没有交互的话，他们是无法发现对方已经掉线的。为了解决这个问题, 我们就需要引入 心跳机制 。\nJVM 数据区 PC\n唯一一个无OOM的区域，多线程切换时，每个线程有独立的PC\n虚拟机栈\n每个方法执行的时候，Java虚拟机都会同步的创建一个栈帧用于储存局部变量表、操作数栈、动态链接、方法出口等信息。\n局部变量表存放基本数据类型、对象引用、returnAddr类型（指向一条字节码指令的地址）\n在栈深度溢出或栈扩展失败时分别抛出StackOverFlowError和OutOfMemoryError的异常。\n栈帧随着方法调用而创建，随着方法结束而销毁。无论方法正常完成还是异常完成都算作方法结束。\n本地方法栈\n为虚拟机使用到的本地（Native）方法服务。\n本地方法被执行的时候，在本地方法栈也会创建一个栈帧，用于存放该本地方法的局部变量表、操作数栈、动态链接、出口信息。\n堆\n是虚拟机所管理的内存中最大的一块。Java堆是==被所有线程共享的一块内存区域==，在虚拟机启动时创建。存放对象实例、数组。\n如果某些方法中的对象引用没有被返回或者未被外面使用（也就是未逃逸出去），那么对象可以直接在栈上分配内存。\nJDK 8 版本之后 PermGen(永久) 已被 Metaspace(元空间) 取代，元空间使用的是直接内存。\n字符串常量池 是 JVM 为了提升性能和减少内存消耗针对字符串（String 类）专门开辟的一块区域，主要目的是为了避免字符串的重复创建。\nJDK1.7 之前，字符串常量池存放在永久代。JDK1.7 字符串常量池和静态变量从永久代移动了 Java 堆中。\n永久代（方法区实现）的 GC 回收效率太低，只有在整堆收集 (Full GC)的时候才会被执行 GC。Java 程序中通常会有大量的被创建的字符串等待回收，将字符串常量池放到堆中，能够更高效及时地回收字符串内存。\n方法区\n被各个线程共享的内存区域，它用于存储已被虚拟机加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等数据。\n运行时常量池\n运行时常量池是方法区的一部分。Class文件除类字段、方法、接口等描述信息外，还有一项信息是常量池表，用于存放编译期生成的各种字面量和符号引用，在类加载后存放到运行时常量池中。\n字面量是源代码中的固定值的表示法，即通过字面我们就能知道其值的含义。字面量包括整数、浮点数和字符串字面量。符号引用包括类符号引用、字段符号引用、方法符号引用和接口方法符号引用。\n常量池表会在类加载后存放到方法区的运行时常量池中。\n方法区和永久代以及元空间是什么关系呢？\n永久代以及元空间是 HotSpot 虚拟机对虚拟机规范中方法区的两种实现方式。并且，永久代是 JDK 1.8 之前的方法区实现，JDK 1.8 及以后方法区的实现变成了元空间。\n为什么要将永久代 (PermGen) 替换为元空间 (MetaSpace) 呢?\n整个永久代有一个 JVM 本身设置的固定大小上限，无法进行调整，而元空间使用的是直接内存，受本机可用内存的限制，虽然元空间仍旧可能溢出，但是比原来出现的几率会更小。由系统的实际可用空间来控制元空间，这样能加载的类就更多了。\n直接内存\nJDK1.4 中新加入的 NIO(New Input/Output) 类，引入了一种基于通道（Channel）与缓存区（Buffer）的 I/O 方式，它可以直接使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样就能在一些场景中显著提高性能，因为避免了在 Java 堆和 Native 堆之间来回复制数据。\n样例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 public class JHSDB_TestCase { static class Test { static ObjectHolder staticObj = new ObjectHolder(); ObjectHolder instantObj = new ObjectHolder(); void foo(){ ObjectHolder localObj = new ObjectHolder(); System.out.println(\u0026#34;done\u0026#34;); } } private static class ObjectHolder{} public static void main(String[] args) { Test test = new JHSDB_TestCase.Test(); test.foo(); } } /* staticObj、instantObj、localObj三个变量本身(而不是它们所指向的对象)存放在哪里？ staticObj随着Test的信息类型存放在方法区，instantObj随着Test对象存放在java堆，localObj则存放在foo()方法栈帧的局部变量表。 staticObj对象与class对象存放在一起，存储于Eden Java堆中。（JDK7及以后的版本） instantObj对象存放在Eden Java堆中 localObj对象存放在Eden Java堆中 */ 对象的创建 类加载检查\n虚拟机遇到一条 new 指令时，首先将去检查这个指令的参数是否能在常量池中定位到这个类的符号引用，并且检查这个符号引用代表的类是否已被加载过、解析和初始化过。如果没有，那必须先执行相应的类加载过程。\n分配内存\n分配方式有 “指针碰撞” 和 “空闲列表” 两种（详见GC部分），选择哪种分配方式由 Java 堆是否规整决定，而 Java 堆是否规整又由所采用的垃圾收集器是否带有压缩整理功能决定。\n内存分配并发问题：CAS+失败重试、TLAB（线程预分配的一块内存，用完了之后再CAS+重试）\n初始化零值\n设置对象头\nHotspot 虚拟机的对象头包括两部分信息，第一部分用于存储对象自身的运行时数据（哈希码、GC 分代年龄、锁状态标志等等），另一部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。\n初始化零值完成之后，虚拟机要对对象进行必要的设置，例如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的 GC 分代年龄等信息。 这些信息存放在对象头中。 另外，根据虚拟机当前运行状态的不同，如是否启用偏向锁等，对象头会有不同的设置方式。\n执行 init 方法\n建立对象就是为了使用对象，我们的 Java 程序通过栈上的 reference 数据来操作堆上的具体对象。对象的访问方式由虚拟机实现而定，目前主流的访问方式有：使用句柄、直接指针。\nGC 程序计数器、虚拟机栈、本地方法栈随线程而生而灭，因此这几个区域的内存分配和回收都具备确定性，不需要过多考虑回收问题。\n判断对象是否已死 引用计数法\n类似于文件的打开，效率高\n缺点：难以解决对象之间互相循环引用的问题。\n可达性分析法\n堆空间外的一些结构，都可以作为 GC Roots 进行可达性分析。\n如果要使用可达性分析算法来判断内存是否可回收，那么分析工作必须在一个能保障一致性的快照中进行。这点不满足的话分析结果的准确性就无法保证。这点也是导致 GC进行时必须“stop The World”的一个重要原因。\nGC Roots的对象分为以下几种：\n虚拟机栈中的引用对象，入线程调用方法堆栈的参数、局部变量、临时变量等。\n在方法区中类静态属性引用的对象。如Java类的引用类型静态变量。\n在方法区中常量引用对象，如字符串常量池的引用。\n在本地方法栈中的JNI（Native方法）引用的对象。\nJava虚拟机内部的引用，如基本类型对应的Class对象，一些常驻异常对象（NullPointException)等，还有系统类加载器。\n所有被同步锁(synchronize关键字)持有的对象。\n反映Java虚拟机内部情况的JMXBean、JVMTI中注册的回调、本地缓存代码等。\n方法区的回收 方法区的回收主要是两部分内容：废弃的常量和不再使用的类型。\n废弃的常量：比如字符串常量进入常量池，而当前没有任何一个字符串对象的值为它，这样就会被清理出常量池。\n不再使用的类型，需要同时满足\n该类的所有实例已经被回收，也就是已经不存在该类及其任何派生的子类实例了。\n加载该类的类加载器已经被回收。正常很难达成。如OSGi、JSP的重加载会产生。\n该类对应的java.lang.Class对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。\n垃圾收集 新生代垃圾回收 eden、 survivor From 复制到 survivor To，年龄+1。\n首先，把 Eden 和 survivor From 区域中存活的对象复制到 survivor To 区域（如果有对象的年龄以及达到了老年的标准，则赋值到老年代区），同时把这些对象的年龄+1（如果 ServicorTo 不够位置了就放到老年区）；\n大对象直接进入老年代主要是为了避免为大对象分配内存时由于分配担保机制带来的复制而降低效率。\n当累积的某个年龄大小超过了 survivor 区的 50% 时，取这个年龄和 MaxTenuringThreshold 中更小的一个值，作为新的晋升年龄阈值。\n清空 eden、 survivor From。\nsurvivor To 和 survivor From 互换\n针对 HotSpot VM 的实现，它里面的 GC 其实准确分类只有两大种：\n部分收集 (Partial GC)：\n新生代收集（Minor GC / Young GC）：只对新生代进行垃圾收集；\n老年代收集（Major GC / Old GC）：只对老年代进行垃圾收集。需要注意的是 Major GC 在有的语境中也用于指代整堆收集；\n混合收集（Mixed GC）：对整个新生代和部分老年代进行垃圾收集。\n整堆收集 (Full GC)：收集整个 Java 堆和方法区。\n为什么需要Survivor区域？\n防止对象过早进入Old，导致Old频繁Full GC。Survivor具有预筛选保证，只有对象到一定岁数才会送往老年代，Survivor区可以减少被送到老年代的对象，进而减少Full GC发生。\n如果只有一个Survivor，每次垃圾回收年龄+1，会有部分对象进入老年代，导致Survivor的空间变成碎片化空间，最后触发minor gc。使用两个Survivor并进行交换，就保证了两个Survivor区，一个为空，另一个是非空且无碎片保存的。\n空间分配担保是为了确保在 Minor GC 之前老年代本身还有容纳新生代所有对象的剩余空间。\n==收集算法== 标记-清除算法\n标记出所有需要回收的对象，在标记完成后，统一回收掉所有标记的对象\n执行效率不稳定，内存碎片化\n标记-复制算法\n将内存分为两个大小相等的空间，每次只使用其中一块。当一块的内存使用完了，就将还存活的对象复制到另一块上去，然后把已使用过的空间一次性清理干净。\n老年代一般不直接使用该算法，因为老年代对象存活率较高\n标记-整理算法\n根据老年代的特点提出的一种标记算法，标记过程仍然与“标记-清除”算法一样，但后续步骤不是直接对可回收对象回收，而是让所有存活的对象向一端移动，然后直接清理掉端边界以外的内存。\n分代收集\n比如在新生代中，每次收集都会有大量对象死去，所以可以选择”标记-复制“算法，只需要付出少量对象的复制成本就可以完成每次垃圾收集。而老年代的对象存活几率是比较高的，而且没有额外的空间对它进行分配担保，所以我们必须选择“标记-清除”或“标记-整理”算法进行垃圾收集。\n在老年代这种每次回收都有大量存活的区域，移动存活对象并更新所有引用这些对象的地方会是一种极其负重的工作，工作期间必须暂停用户应用程序才能进行。\n平常用标记-清除算法，直到空间碎片化已经影响到对象分配，再使用标记-整理算法。\n==经典垃圾收集器== GC中的并行和并发：\n并行（Parallel） ：指多条垃圾收集线程并行工作，但此时用户线程仍然处于等待状态。 并发（Concurrent）：指用户线程与垃圾收集线程同时执行（但不一定是并行，可能会交替执行），用户程序在继续运行，而垃圾收集器运行在另一个 CPU 上。 Serial收集器 一个单线程的垃圾收集器，在垃圾收集时必须暂停其他所有工作线程（STW），直到收集结束，简单高效。\n新生代采用标记-复制算法，老年代采用标记-整理算法。\nParNew收集器 Serial收集器的多线程并行版本。随着可以被使用的处理核心增加，ParNew对于垃圾收集时系统可以高效利用，默认开启的收集线程数和处理器核心数量相同。\nParallel Scavenge收集器 新生代收集器，同样基于标记-复制算法，能够并行收集的多线程收集器。它看上去几乎和 ParNew 都一样，特点是达到一个可控制的吞吐量。吞吐量就是 CPU 中用于运行用户代码的时间与 CPU 总消耗时间的比值。\nSerial Old收集器 老年代使用标记-整理算法暂停所有线程。可以Parallel Scavenge收集器搭配使用，另一种是作为CMS收集器发生失败的后备方案。\nParalle Old收集器 Parallel Scavenge收集器的老年版本，支持多线程并发收集，基于标记-整理算法。与Parallel Scavenge搭配作为“吞吐量优先”的收集器搭配组合\nCMS（Concurrent Mark Sweep）收集器 一种以获取最短回收停顿时间为目标的收集器，工作于老年代。基于标记-清除算法实现。\n步骤：\n初始标记：仅仅标记一下GC Root对象能直接关联到的对象，速度很快，需要暂停所有线程。\n并发标记：从GC Root关联对象开始遍历整个对象图的过程，可以与用户线程共同执行。\n重新标记：由于第三阶段是并发的，对象引用可能会发生进一步改变，因此应用程序线程会再一次被暂停以更新这些变化。这个阶段的停顿时间一般会比初始标记阶段的时间稍长，远远比并发标记阶段时间短。\n并发清除：清理删除掉标记阶段判断的已经死亡的对象，由于不需要移动对象，因此可以与用户线程共同执行。\n特点：\n对处理器资源非常敏感。 无法处理“浮动垃圾”，有可能出现并发模式失败进而导致一次Full GC。浮动垃圾为出现在标记过程结束之后产生的对象。因为CMS要支持收集过程中与用户线程并存，因此不能在老年代几乎被填满时再运行，需要预留一部分空间供并发收集的程序运行。 它使用的回收算法-“标记-清除”算法会导致收集结束时会有大量空间碎片产生。 CMS垃圾回收分为Background和Foreground，Foreground会进行一次压缩式GC。\nBackground回收过程中STW主要在初始标记和重新标记阶段，final remark阶段和初始标记流程类似，多了Card Table 遍历、Reference 实例的清理。\nCMS并发退化为Foreground单线程串行模式有两种算法，MSC（是一种Full GC）、不带压缩动作处理Old区（和普通CMS类似）\n跨代引用：\n记忆集\n记忆集是一种抽象概念，用于在实现部分垃圾收集（Partial GC）时用于记录从非收集区域指向收集区域的指针集合，卡表是记忆集的一种实现方式。例如在分代式GC中，通常能单独收集的只有Young gen，那记忆集记录的就是Old gen指向Young gen的跨代指针。\n一个卡页的内存中通常包含不止一个对象，只要卡页内有一个（或更多）对象的字段存在着跨代指针，那就将对应卡表的数组元素的值标识为1，成这个元素变脏（Dirty），没有则标识为0。在垃圾收集发生时，只要筛选出卡表中变脏的元素，就能轻易得出哪些卡页内存块中包含跨代指针，把他们加入GC Roots中一并扫描。\n写屏障\n可以看成是虚拟机层面在”引用类型字段赋值“这个动作的AOP切面，引用对象赋值的时候产生一个环形通知，进行一些额外的处理，这样就是引用对象赋值这个操作都在写屏障的覆盖范围内，赋值前的写屏障叫写前屏障，赋值后的写屏障叫写后屏障。\nGC两个关键难点：跨代引用与并发标记_三侠剑的博客-CSDN博客\nGarbage First（G1）收集器 G1整体是基于标记-整理算法实现的收集器，但从局部又是基于标记-复制算法实现。在执行标记整理的时候，还进行了压缩的工作，这是之前的垃圾收集器都没有的。\nG1并不会等内存耗尽(串行、并行)或者快耗尽(CMS)的时候开始垃圾收集，而是在内部采用了启发式算法，在老年代找出具有高收集收益的分区进行收集。 G1采用内存分区的思路，将内存划分为一个个相等大小的内存分区，回收时则以分区为单位进行回收，存活的对象复制到另一个空闲分区中。由于都是以相等大小的分区为单位进行操作，因此G1天然就是一种压缩方案(局部压缩)； G1虽然也是分代收集器，但整个内存分区不存在物理上的年轻代与老年代的区别，也不需要完全独立的survivor(to space)堆做复制准备。G1只有逻辑上的分代概念，或者说每个分区都可能随G1的运行在不同代之间前后切换； G1收集都是STW的，但年轻代和老年代的收集界限比较模糊，采用了混合(mixed)收集的方式。 在G1中，还有一种特殊的区域，叫Humongous区域。 如果一个对象占用的空间超过了分区容量50%以上，G1收集器就认为这是一个巨型对象。这些巨型对象，默认直接会被分配在年老代，但是如果它是一个短期存在的巨型对象，就会对垃圾收集器造成负面影响。为了解决这个问题，G1划分了一个Humongous区，它用来专门存放巨型对象。如果一个H区装不下一个巨型对象，那么G1会寻找连续的H分区来存储。为了能找到连续的H区，有时候不得不启动Full GC。\nYoung GC\nG1引进了RSet的概念。它的全称是Remembered Set，作用是跟踪指向某个heap区内的对象引用。\nG1中使用point-in来解决。point-in的意思是哪些分区引用了当前分区中的对象。这样，仅仅将这些对象当做根来扫描就避免了无效的扫描。由于新生代有多个，那么我们需要在新生代之间记录引用吗？这是不必要的，原因在于每次GC时，所有新生代都会被扫描，所以只需要记录老年代到新生代之间的引用即可。\n如果引用的对象很多，赋值器需要对每个引用做处理，赋值器开销会很大，为了解决赋值器开销这个问题，在G1 中又引入了另外一个概念，卡表（Card Table）。一个Card Table将一个分区在逻辑上划分为固定大小的连续区域，每个区域称之为卡。卡通常较小，介于128到512字节之间。Card Table通常为字节数组，由Card的索引（即数组下标）来标识每个分区的空间地址。默认情况下，每个卡都未被引用。当一个地址空间被引用时，这个地址空间对应的数组索引的值被标记为”0″，即标记为脏被引用，此外RSet也将这个数组下标记录下来。一般情况下，这个RSet其实是一个Hash Table，Key是别的Region的起始地址，Value是一个集合，里面的元素是Card Table的Index。\nYoung GC 阶段：\n阶段1：根扫描 静态和本地对象被扫描 阶段2：更新RS 处理dirty card队列更新RS 阶段3：处理RS 检测从年轻代指向年老代的对象 阶段4：对象拷贝 拷贝存活的对象到survivor/old区域 阶段5：处理引用队列 软引用，弱引用，虚引用处理 Mixed GC\nMix GC不仅进行正常的新生代垃圾收集，同时也回收部分后台扫描线程标记的老年代分区。\n在进行Mix GC之前，会先进行global concurrent marking（全局并发标记）。在G1 GC中，它主要是为Mixed GC提供标记服务的，并不是一次GC过程的一个必须环节。global concurrent marking的执行过程分为五个步骤：\n初始标记（initial mark，STW）（第一次暂停所以应用线程） 在此阶段，G1 GC 对根进行标记。该阶段与常规的 (STW) 年轻代垃圾回收密切相关。 根区域扫描（root region scan） G1 GC 在初始标记的存活区扫描对老年代的引用，并标记被引用的对象。该阶段与应用程序（非 STW）同时运行，并且只有完成该阶段后，才能开始下一次 STW 年轻代垃圾回收。 并发标记（Concurrent Marking） G1 GC 在整个堆中查找可访问的（存活的）对象。该阶段与应用程序同时运行，可以被 STW 年轻代垃圾回收中断。 最终标记（Remark，STW）（第二次暂停所以应用线程） 该阶段是 STW 回收，帮助完成标记周期。G1 GC 清空 SATB 缓冲区（处理写屏障记录下的引用），跟踪未被访问的存活对象，并执行引用处理。 清除垃圾（Cleanup，STW）（第三次暂停所以应用线程） 在这个最后阶段，G1 GC 执行统计和 RSet 净化的 STW 操作。在统计期间，G1 GC 会识别完全空闲的区域和可供进行混合垃圾回收的区域。清理阶段在将空白区域重置并返回到空闲列表时为部分并发。 G1 收集器原理理解与分析 - 知乎 (zhihu.com)\n垃圾收集器之：G1收集器 - duanxz - 博客园 (cnblogs.com)\n对象的分配策略。它分为3个阶段：\nTLAB(Thread Local Allocation Buffer)线程本地分配缓冲区 Eden区中分配 Humongous区分配 TLAB为线程本地分配缓冲区，它的目的为了使对象尽可能快的分配出来。如果对象在一个共享的空间中分配，我们需要采用一些同步机制来管理这些空间内的空闲空间指针。在Eden空间中，每一个线程都有一个固定的分区用于分配对象，即一个TLAB。分配对象时，线程之间不再需要进行任何的同步。对TLAB空间中无法分配的对象，JVM会尝试在Eden空间中进行分配。如果Eden空间无法容纳该对象，就只能在老年代中进行分配空间。\n运行步骤：\n初始标记（STW），标记GC Root能直接关联的对象；\n并发标记，根据GC Root进行可达性分析，处理SATB记录并发标记时有变动的对象；\n最终标记（STW），处理并发阶段结束后少量的SATB的记录；\n筛选回收（STW）：回收集合的存活对象复制到空的Region，再清理旧的Region，使用多线程并行完成移动。\n避免在整个堆进行全区域的垃圾回收，G1会在后台维护一个优先级表，回收价值受益最大的Region。每个Region都有自己的记忆集，记录跨区域引用。\nCMS使用增量更新算法，而G1使用原始快照(SATB)算法来解决，用户线程改变对象的引用关系，不打破原有的对象图结构，防止标记错误。\n三色标记,增量更新与原始快照|8月更文挑战 - 掘金 (juejin.cn)\n通过可靠停顿预测模型的建立：根据每个Region的回收成本，分析出收集的平均值、标准偏差、置信度等统计信息。\nG1收集器同CMS收集器一样，在某些情况下，G1触发了Full GC，这时G1会退化使用Serial收集器来完成垃圾的清理工作\n触发Full GC：\nG1启动标记周期，但在Mix GC之前，老年代就被填满 晋升失败 疏散失败，Survivor空间和老年代中没有足够的空间容纳所有的幸存对象 巨型对象分配失败 G1 vs CMS\nCMS 和G1 的区别 - 简书 (jianshu.com)\n整理：G1在GC的时候都会做垃圾的碎片整理，而CMS收集器只在Full GC STW时才会做内存压缩整理。 可停顿时间：G1是一种兼顾吞吐量和停顿时间的 GC 实现，其可靠停顿预测模型可以设定目标收集停顿时间，可以实现更短的GC停顿。 对象记录算法：对于对象记录CMS使用增量更新算法，而G1使用原始快照(SATB,snapshot-at-the-beginning)记录存活对象。 收集方式：G1使用混合收集的方式。G1可以扫描年轻代和一小部分老年代，但这意味着比简单地只扫描老年代、完全的快得多。CMS收集器是老年代的收集器，可以配合新生代的Serial和ParNew收集器一起使用 G1收集器收集范围是老年代和新生代。不需要结合其他收集器使用 CMS对处理器资源非常敏感。CMS默认启动的回收线程数是(处理器数量+3)/4，因此弱核心数量在4个以上，占用内存不超过25%。若核心数量小于4，则占用内存过大。G1针对具有大内存的多处理器机器，因为其Remembered Sets的记忆集的设计，需要占用更多内存。 其他GC Shenandoah ：区别G1的特点为支持并发整理，使用转发指针和读屏障实现。\nzgc：Region具有动态性，并分为大中小三个Region，使用染色指针技术实现并发整理算法。\nEpsilon：无操作收集器。\n类文件 双亲委派模型 从虚拟机的角度来看，只存在两种不同的类加载器：\n启动类加载器BootStrap ClassLoader，由虚拟机实现，是虚拟机自身一部分。 其他所有的类加载器，由Java语言实现，独立于虚拟机之外，都是继承自抽象类java.lang.ClassLoader。 双亲委派模型加载过程：\n如果一个类加载器接收到类加载请求，它首先不会自己尝试加载这个类，而是把请求委托到父类执行。 每一层次的类加载器都会委托其父类加载器去完成，最终传到最顶层的启动类加载器中。 只有当所有父加载器都无法自己完成这个类加载请求，子加载器才会进行加载。 自定义类加载器可以用于：\n加载非classpath下的类，从非标准的来源加载代码\n加载加密过的类文件，使用秘钥进行解密。\n热部署，简单粗暴的方法是自定义类加载器，加载目录外的类对象。使用定时任务或者触发起的方法，每次创建新的类加载器。\n破坏双亲委派模型\n实现自己的ClassLoader重写loadClass，在方法中重写自己加载的逻辑。这样类加载过程中就不会通过委派父类加载的方式进行加载数据。\n线程上下文类加载器，在mysql jdbc连接中获取了当前的类加载器，这就破坏的双亲委派的类加载过程。\n这个类加载器可以通过java.lang.Thread类的setContextClassLoaser()方法进行设置，如果创建线程时还未设置，它将会从父线程中继承一个，如果在应用程序的全局范围内都没有设置过的话，那这个类加载器默认就是应用程序类加载器。\n有了线程上下文类加载器，也就是父类加载器请求子类加载器去完成类加载的动作（即，父类加载器加载的类，使用线程上下文加载器去加载其无法加载的类），这种行为实际上就是打通了双亲委派模型的层次结构来逆向使用类加载器，实际上已经违背了双亲委派模型的一般性原则。\n真正理解线程上下文类加载器（多案例分析）_小杨Vita的博客-CSDN博客_线程上下文类加载器\n类的生命周期 加载 通过全类名获取定义此类的二进制字节流\n将字节流所代表的静态存储结构转换为方法区的运行时数据结构\n在内存中生成一个代表该类的 Class 对象,作为方法区这些数据的访问入口\n连接 验证字节码文件正确性（文件格式、元数据、字节码、符号引用验证）；\n准备阶段时，给类的静态变量分配内存并赋初值（指的是零值），若是有被static final同时修饰的基本类型或者字符串，编译阶段会为之生成ConstantValue属性，此阶段赋上真正的值，而仅仅只被static修饰的要等到构造器才能获得真正的值；\n解析阶段时，类装载器装入类所引用的其他所有类，虚拟机将常量池内的符号引用替换为直接引用，主要针对类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用限定符7类符号引用进行。\nClass类文件结构之ConstantValue属性_阁楼猫的博客-CSDN博客_constantvalue\n初始化 在准备阶段已经赋初始化零值的变量，在初始化阶段，会根据程序去初始化类变量和其他资源。 初始化阶段就是执行类构造器\u0026lt;clinit\u0026gt;()方法的过程。该方法是由编译器收集类中的所有类变量的赋值动作和静态语句块（static{}块）中的语句合并产生的。\n类初始化的时机\n当遇到 new、getstatic、putstatic或invokestatic 这4条直接码指令时，比如 new 一个类，读取一个静态字段(未被 final 修饰)、或调用一个类的静态方法时。\n当 jvm 执行 new 指令时会初始化类。即当程序创建一个类的实例对象。 当 jvm 执行 getstatic 指令时会初始化类。即程序访问类的静态变量(不是静态常量，常量会被加载到运行时常量池)。 当 jvm 执行 putstatic 指令时会初始化类。即程序给类的静态变量赋值。 当 jvm 执行 invokestatic 指令时会初始化类。即程序调用类的静态方法。 反射调用\n初始化子类的时候会保证父类也要先初始化过\n包含main方法的类会在虚拟机启动的时候先初始化\nMethodHandle和VarHandle可以看作是轻量级的反射调用机制，而要想使用这2个调用， 就必须先使用findStaticVarHandle来初始化要调用的类。\n当一个接口中定义了JDK8新加入的默认方法（被default关键字修饰的接口方法）时，如果有这个接口的实现类发生了初始化，那该接口要在其之前被初始化。\n卸载 卸载类需要满足3个要求:\n该类的所有的实例对象都已被GC，也就是说堆不存在该类的实例对象。\n该类没有在其他任何地方被引用\n该类的类加载器的实例已被GC\n在 JVM 生命周期内，由 jvm 自带的类加载器（BootstrapClassLoader, ExtClassLoader, AppClassLoader）加载的类是不会被卸载的。但是由我们自定义的类加载器加载的类是可能被卸载的。\n对象 内存分配方式 （CAS+失败重试；TLAB在堆中预分配一块内存）\n规整空间将指针向空闲区域移动一段与对象大小相等的距离；\n碎片空间记录一个空闲链表；\n本地线程分配缓冲（TLAB），每个线程在堆中预先分配一小块内存，基于 CAS 的独享线程（Mutator Threads）可以优先将对象分配在 Eden 中的一块内存，因为是 Java 线程独享的内存区没有锁竞争，所以分配速度更快，每个 TLAB 都是一个线程独享的。\n对象在堆内存中的存储布局可以分为三部分：对象头、实例数据（对象有效信息）和对齐填充\n对象头 对象访问 主要有两种使用：句柄（句柄分为两块指针：指向对象实例、指向对象类型数据）和直接指针（HotSpot主要使用）。\n对象引用 任何一个对象死亡都会被系统调用一次对象死亡的方法，如果对象下一次面临回收，它的finalize()不会再执行。\n强引用：Object obj = new Object()。关系存在虚拟机就不会回收。\n软引用：用来描述一些还有用但非必须的对象。在系统要发生内存溢出会收集软引用对象，若回收完成仍内存不足，才抛出内存遗传。可用于实现内存敏感缓存。\n弱引用：弱引用关联的对象只能生存到下一次垃圾收集发生为止。\n虚引用：最弱的引用，意义为一个对象设置虚引用关联的唯一目的是为了在该对象被收集时得到一个通知。\n阿里面试： 说说强引用、软引用、弱引用、虚引用吧 - 云+社区 - 腾讯云 (tencent.com)\nJDK编译期做的工作 默认构造器： 经过编译的代码,可以看到在编译阶段，如果我们没有添加构造器。那么Java编译器会为我们添加一个无参构造方法。 自动拆装箱 泛型与类型擦除 foreach优化成Iterator String... args 可变参数优化 switch支持case使用字符串及枚举类型优化，优化成hashcode匹配。 枚举，优化成final class try-with-resources 优化，自动在finally中加入close语句 重写的优化，子类重写方法中会新增一个桥接方法。 匿名内部类：生成final 修饰的类 (32条消息) 【JVM】\u0026ndash; Java编译期处理_gyhdxFeng的博客-CSDN博客\nJVM调优 目的：将转移到老年代的对象数量降低到最小； 减少 GC 的执行时间。\n策略 将新对象预留在新生代，由于 Full GC 的成本远高于 Minor GC，因此尽可能将对象分配在新生代是明智的做法，实际项目中根据 GC 日志分析新生代空间大小分配是否合理，适当通过“-Xmn”命令调节新生代大小，最大限度降低新对象直接进入老年代的情况。 大对象进入老年代，虽然大部分情况下，将对象分配在新生代是合理的。但是对于大对象这种做法却值得商榷，大对象如果首次在新生代分配可能会出现空间不足导致很多年龄不够的小对象被分配的老年代，破坏新生代的对象结构，可能会出现频繁的 full gc。因此，对于大对象，可以设置直接进入老年代（当然短命的大对象对于垃圾回收来说简直就是噩梦）。-XX:PretenureSizeThreshold 可以设置直接进入老年代的对象大小。 合理设置进入老年代对象的年龄，-XX:MaxTenuringThreshold 设置对象进入老年代的年龄大小，减少老年代的内存占用，降低 full gc 发生的频率。 设置稳定的堆大小，堆大小设置有两个参数：-Xms 初始化堆大小，-Xmx 最大堆大小。 案例 动态扩容引起的空间震荡\n显式 GC 的去与留\n除了扩容缩容会触发 CMS GC 之外，还有\nOld 区达到回收阈值. MetaSpace 空间不足 Young 区晋升失败 大对象担保失败等几种触发条件 增加 -XX:+DisableExplicitGC 参数后，System.gc 这个方法变成了一个空方法\n而考虑到DirectByteBuffer直接内存在分配空间会显式调用 System.gc，DirectByteBuffer经常用于Netty 等各种 NIO 框架使用，所以不应该去除System.gc\nMetaSpace 区 OOM\nMetaSpace 主要由 Klass Metaspace（存Class文件运行的数据结构） 和 NoKlass Metaspace（存method、常量池） 两大部分组成，它是一块堆外内存，大小取决于机器内存大小\n给 MetaSpace 区的使用率加一个监控，如果指标有波动提前发现并解决问题。\n过早晋升\nYoung/Eden 区过小\n分配速率过大\nCMS Old GC频繁\n单次CMS Old GC耗时长\n分析Reference 处理和元数据处理耗时是否正常，一般来说最容易出问题的地方就是 Reference 中的 FinalReference 和元数据信息处理中的 scrub symbol table 两个阶段。\n内存碎片、收集器退化\n堆外OOM\n通过 UnSafe#allocateMemory，ByteBuffer#allocateDirect 主动申请了堆外内存而没有释放，常见于 NIO、Netty 等相关组件。\n代码中有通过 JNI 调用 Native Code 申请的内存没有释放。\nJNI引发的GC\n调优其他建议 禁用偏向锁：偏向锁在只有一个线程使用到该锁的时候效率很高，但是在竞争激烈情况会升级成轻量级锁，此时就需要先消除偏向锁，这个过程是 STW 的。 主动式GC 虚拟内存 JDK 监控和故障处理工具 JDK 命令行工具 jps (JVM Process Status）: 类似 UNIX 的 ps 命令。用于查看所有 Java 进程的启动类、传入参数和 Java 虚拟机参数等信息； jstat（JVM Statistics Monitoring Tool）: 用于收集 HotSpot 虚拟机各方面的运行数据; jinfo (Configuration Info for Java) : Configuration Info for Java,显示虚拟机配置信息; jmap (Memory Map for Java) : 生成堆转储快照; jhat (JVM Heap Dump Browser) : 用于分析 heapdump 文件，它会建立一个 HTTP/HTML 服务器，让用户可以在浏览器上查看分析结果; jstack (Stack Trace for Java) : 生成虚拟机当前时刻的线程快照，线程快照就是当前虚拟机内每一条线程正在执行的方法堆栈的集合。 JDK 可视化分析工具 JConsole:Java 监视与管理控制台 Visual VM:多合一故障处理工具 Java并发 进程与线程\n一个进程在其执行的过程中可以产生多个线程。与进程不同的是同类的多个线程共享进程的堆和方法区(JDK1.8 之后的元空间)资源，但每个线程有自己的程序计数器、虚拟机栈和本地方法栈。\nJava线程的6种状态及切换(透彻讲解)_潘建南的博客-CSDN博客_线程的5种状态\n堆和方法区是所有线程共享的资源，其中堆是进程中最大的一块内存，主要用于存放新创建的对象 (几乎所有对象都在这里分配内存)，方法区主要用于存放已被加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。\n死锁：\n互斥条件：该资源任意一个时刻只由一个线程占用。 请求与保持条件：一个线程因请求资源而阻塞时，对已获得的资源保持不放。 不剥夺条件:线程已获得的资源在未使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。 循环等待条件:若干线程之间形成一种头尾相接的循环等待资源关系。 sleep() 方法没有释放锁，而 wait() 方法释放了锁 。\n为什么我们调用 start() 方法时会执行 run() 方法，为什么我们不能直接调用 run() 方法？\n直接执行 run() 方法，会把 run() 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。\nJava的锁 乐观锁/悲观锁：\nJava 语言中 synchronized 和 ReentrantLock等就是典型的悲观锁，还有一些使用了 synchronized 关键字的容器类如 HashTable 等也是悲观锁的应用。\n乐观锁可以使用版本号机制和CAS算法实现。\n独占锁和共享锁：\n共享锁是指锁可被多个线程所持有。如果一个线程对数据加上共享锁后，那么其他线程只能对数据再加共享锁，不能加独占锁。获得共享锁的线程只能读数据，不能修改数据。\n互斥锁和读写锁：\n读写锁是共享锁的一种具体实现。读写锁管理一组锁，一个是只读的锁，一个是写锁。\n读锁可以在没有写锁的时候被多个线程同时持有，而写锁是独占的。写锁的优先级要高于读锁，一个获得了读锁的线程必须能看到前一个释放的写锁所更新的内容。\n读写锁相比于互斥锁并发程度更高，每次只有一个写线程，但是同时可以有多个线程并发读。\n公平锁和非公平锁\n公平锁是指多个线程按照申请锁的顺序来获取锁，这里类似排队买票，先来的人先买，后来的人在队尾排着，这是公平的。\n可重入锁\n可重入锁的一个好处是可一定程度避免死锁。\n1 2 3 4 5 6 7 8 9 10 public synchronized void mehtodA() throws Exception{ // Do some magic tings mehtodB(); } public synchronized void mehtodB() throws Exception{ // Do some magic tings } //上面的代码中 methodA 调用 methodB，如果一个线程调用methodA 已经获取了锁再去调用 methodB 就不需要再次获取锁了，这就是可重入锁的特性。如果不是可重入锁的话，mehtodB 可能不会被当前线程执行，可能造成死锁。 自旋锁\n自旋锁是指线程在没有获得锁时不是被直接挂起，而是执行一个忙循环，这个忙循环就是所谓的自旋。\n自旋锁的目的是为了减少线程被挂起的几率，因为线程的挂起和唤醒也都是耗资源的操作。\n在JDK1.6又引入了自适应自旋，这个就比较智能了，自旋时间不再固定，由前一次在同一个锁上的自旋时间以及锁的拥有者的状态来决定。如果虚拟机认为这次自旋也很有可能再次成功那就会次序较多的时间，如果自旋很少成功，那以后可能就直接省略掉自旋过程，避免浪费处理器资源。\n分段锁\n分段锁设计目的是将锁的粒度进一步细化，当操作不需要更新整个数组的时候，就仅仅针对数组中的一项进行加锁操作。在 Java 语言中 CurrentHashMap 底层就用了分段锁，使用Segment，就可以进行并发使用了。\n锁升级\nJDK1.6 为了提升性能减少获得锁和释放锁所带来的消耗，引入了4种锁的状态：无锁、偏向锁、轻量级锁和重量级锁，它会随着多线程的竞争情况逐渐升级，但不能降级。\n无锁：乐观锁\n偏向锁：只需要执行一次CAS即可获取锁；采用延迟释放锁策略；锁重入时，只需要判断mark_word.threadId(关于对象头的文章)是否为当前threadId即可\n首先JVM要设置为可用偏向锁。然后当一个进程访问同步块并且获得锁的时候，会在对象头和栈帧的锁记录里面存储取得偏向锁的线程ID。\n下一次有线程尝试获取锁的时候，首先检查这个对象头的MarkWord是不是储存着这个线程的ID。如果是，那么直接进去而不需要任何别的操作。如果不是，那么分为两种情况。1，对象的偏向锁标志位为0（当前不是偏向锁），说明发生了竞争，已经膨胀为轻量级锁，这时使用CAS操作尝试获得锁。2，偏向锁标志位为1，说明还是偏向锁不过请求的线程不是原来那个了。这时只需要使用CAS尝试把对象头偏向锁从原来那个线程指向目前求锁的线程。\n轻量级锁：当线程竞争变得比较激烈时，偏向锁就会升级为轻量级锁，轻量级锁认为虽然竞争是存在的，但是理想情况下竞争的程度很低，通过自旋方式等待上一个线程释放锁。\n线程尝试使用 CAS 将对象头中的 Mark Word 替换为指向锁记录（Lock Record）的指针。如果成功，当前线程获得轻量级锁，如果失败，虚拟机先检查当前对象头的 Mark Word 是否指向当前线程的栈帧，如果指向，则说明当前线程已经拥有这个对象的锁，则可以直接进入同步块 执行操作，否则表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。当竞争线程的自旋次数 达到界限值（threshold），轻量级锁将会膨胀为重量级锁。\n重量级锁：互斥锁\n锁粗化、锁清除\n锁粗化就是将多个同步块的数量减少，并将单个同步块的作用范围扩大，本质上就是将多次上锁、解锁的请求合并为一次同步请求。\n锁消除是指虚拟机编译器在运行时检测到了共享数据没有竞争的锁，从而将这些锁进行消除。（举例：单个线程空间中使用synchronize（Stringbuffer等））\n基础知识 死锁\n产生死锁的四个必要条件：\n互斥条件：该资源任意一个时刻只由一个线程占用。\n请求与保持条件：一个线程因请求资源而阻塞时，对已获得的资源保持不放。\n不剥夺条件:线程已获得的资源在未使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。\n循环等待条件:若干线程之间形成一种头尾相接的循环等待资源关系。\n预防死锁\n破坏请求与保持条件 ：一次性申请所有的资源。\n破坏不剥夺条件 ：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。\n破坏循环等待条件 ：靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。\n避免死锁：银行家算法。。。。。。\n两者最主要的区别在于：sleep() 方法没有释放锁，而 wait() 方法释放了锁 。\nwait() 通常被用于线程间交互/通信，sleep() 通常被用于暂停执行。\n为什么我们调用 start() 方法时会执行 run() 方法，为什么我们不能直接调用 run() 方法？\n**调用 start() 方法方可启动线程并使线程进入就绪状态，直接执行 run() 方法的话不会以多线程的方式执行。**直接执行 run() 方法，会把 run() 方法当成一个 main 线程下的普通方法去执行，并不会在某个线程中执行它，所以这并不是多线程工作。\nsynchronized 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 修饰实例方法（获取当前对象实例的锁） 修饰静态方法（获取当前class的锁） 修饰代码块 synchronized(A.class){ ... } synchronized(this){ ... } //尽量不要使用 synchronized(String a) 因为 JVM 中，字符串常量池具有缓存功能！ DCL单例模式实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 public class Singleton { private volatile static Singleton instance;//注意volitale（分配空间、初始化空间、指向空间） private Singleton() { } public Singleton getInstance() { if (instance == null) { synchronized (Singleton.class) { if (instance == null) { instance = new Singleton(); } } } return instance; } } 原理 synchronized 修饰的方法并没有 monitorenter 指令和 monitorexit 指令，取得代之的确实是 ACC_SYNCHRONIZED 标识，该标识指明了该方法是一个同步方法。JVM 通过该 ACC_SYNCHRONIZED 访问标志来辨别一个方法是否声明为同步方法，从而执行相应的同步调用。\nsynchronized优化 锁主要存在四种状态，依次是：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态，他们会随着竞争的激烈而逐渐升级。注意锁可以升级不可降级，这种策略是为了提高获得锁和释放锁的效率。\njava的锁\nsynchronized 和 ReentrantLock 的区别 两者都是可重入锁\nsynchronized 依赖于 JVM 而 ReentrantLock 依赖于 API\nreentranLock可以：\n等待可中断 : 正在等待的线程可以选择放弃等待，改为处理其他事情。\n可实现公平锁 : ReentrantLock可以指定是公平锁还是非公平锁。而synchronized只能是非公平锁。\n可实现选择性通知（锁可以绑定多个条件）: synchronized关键字与wait()和notify()/notifyAll()方法相结合可以实现等待/通知机制。ReentrantLock类当然也可以实现，但是需要借助于Condition接口与newCondition()方法。\nvolatile 把变量声明为 volatile ，这就指示 JVM，这个变量是共享且不稳定的，每次使用它都到主存中进行读取。\nvolatile 关键字 除了防止 JVM 的指令重排 ，还有一个重要的作用就是保证变量的可见性。\n并发编程的特性：\n原子性 : 一次操作或者多次操作，要么所有的操作全部都得到执行并且不会受到任何因素的干扰而中断，要么都不执行。synchronized 可以保证代码片段的原子性。 可见性 ：当一个线程对共享变量进行了修改，那么另外的线程都是立即可以看到修改后的最新值。volatile 关键字可以保证共享变量的可见性。 有序性 ：代码在执行的过程中的先后顺序，Java 在编译器以及运行期间的优化，代码的执行顺序未必就是编写代码时候的顺序。volatile 关键字可以禁止指令进行重排序优化。 volatile 关键字是线程同步的轻量级实现，所以 volatile 性能肯定比synchronized关键字要好 。但是 volatile 关键字只能用于变量而 synchronized 关键字可以修饰方法以及代码块 。\nvolatile 关键字能保证数据的可见性，但不能保证数据的原子性。synchronized 关键字两者都能保证。\nvolatile关键字主要用于解决变量在多个线程之间的可见性，而 synchronized 关键字解决的是多个线程之间访问资源的同步性。\nThreadLocal ThreadLocal类主要解决的就是让每个线程绑定自己的值，可以将ThreadLocal类形象的比喻成存放数据的盒子，盒子中可以存储每个线程的私有数据。\n每个Thread中都具备一个ThreadLocalMap，而ThreadLocalMap可以存储以ThreadLocal为 key ，Object 对象为 value 的键值对。\nThreadLocal 内存泄露问题\nThreadLocalMap 中使用的 key 为 ThreadLocal 的弱引用,而 value 是强引用。所以，如果 ThreadLocal 没有被外部强引用的情况下，在垃圾回收的时候，key 会被清理掉，而 value 不会被清理掉。这样一来，ThreadLocalMap 中就会出现 key 为 null 的 Entry。假如我们不做任何措施的话，value 永远无法被 GC 回收，这个时候就可能会产生内存泄露。ThreadLocalMap 实现中已经考虑了这种情况，在调用 set()、get()、remove() 方法的时候，会清理掉 key 为 null 的记录。使用完 ThreadLocal方法后 最好手动调用remove()方法\n过期Key清理\n探测式清理\n遍历散列数组，从开始位置向后探测清理过期数据，将过期数据的Entry设置为null，沿途中碰到未过期的数据则将此数据rehash后重新在table数组中定位，如果定位的位置已经有了数据，则会将未过期的数据放到最靠近此位置的Entry=null的桶中，使rehash后的Entry数据距离正确的桶的位置更近一些。\nexpungeStaleEntry：\n清空当前staleSlot位置的数据 继续往后迭代检查，碰到正常数据，计算该数据位置是否偏移，如果被偏移，则重新计算slot位置，目的是让正常数据尽可能存放在正确位置或离正确位置更近的位置。如果遇到k==null的过期数据，也是清空该槽位数据，size\u0026ndash;。 在往后迭代的过程中碰到空的槽位，终止探测 启发式清理\n如果没有过期数据，只要扫描logN次即可，这个算法的时间复杂度为O(logN)。 如果有过期数据，需要将n置为table的长度len，做一次探测式清理，再从下一个空的slot开始继续扫描。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // i对应的entry是非无效的 // n用于控制扫描次数 private boolean cleanSomeSlots(int i, int n) { boolean removed = false; Entry[] tab = table; int len = tab.length; do { //从i的下一个开始，因为i不是无效的 i = nextIndex(i, len); Entry e = tab[i]; if (e != null \u0026amp;\u0026amp; e.get() == null) { //扩大扫描因子 n = len; removed = true; //清理一个连续段 i = expungeStaleEntry(i); } } while ( (n \u0026gt;\u0026gt;\u0026gt;= 1) != 0); return removed; } 扩容\n在ThreadLocalMap.set()方法的最后，如果执行完启发式清理工作后，未清理到任何数据，且当前散列数组中Entry的数量已经达到了列表的扩容阈值(len*2/3)，就开始执行rehash()逻辑。\n首先是会进行探测式清理工作，从table的起始位置往后清理。清理完成之后，table中可能有一些key为null的Entry数据被清理掉，所以此时通过判断size \u0026gt;= threshold - threshold / 4 也就是size \u0026gt;= threshold * 3/4 来决定是否扩容。\n扩容逻辑：先到达阈值，再清理，之后再看是否到达阈值的3/4，到达了就开始扩容。\n父线程传线程专属数据到子线程\n我们使用ThreadLocal的时候，在异步场景下是无法给子线程共享父线程中创建的线程副本数据的。为了解决这个问题，JDK 中还有一个InheritableThreadLocal类。子线程是通过在父线程中通过调用new Thread()方法来创建子线程，Thread#init方法在Thread的构造方法中被调用。在init方法中拷贝父线程数据到子线程中。\n线程池 使用线程池的好处：\n降低资源消耗。通过重复利用已创建的线程降低线程创建和销毁造成的消耗。 提高响应速度。当任务到达时，任务可以不需要等到线程创建就能立即执行。 提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。 创建线程池\nExecutors 返回线程池对象的弊端如下：\nFixedThreadPool 和 SingleThreadExecutor ： 允许请求的队列长度为 Integer.MAX_VALUE ，可能堆积大量的请求，从而导致 OOM。 CachedThreadPool 和 ScheduledThreadPool ： 允许创建的线程数量为 Integer.MAX_VALUE ，可能会创建大量线程，从而导致 OOM。 线程池饱和策略\nThreadPoolExecutor.AbortPolicy： 抛出 RejectedExecutionException来拒绝新任务的处理。 ThreadPoolExecutor.CallerRunsPolicy： 调用执行自己的线程运行任务，也就是直接在调用execute方法的线程中运行(run)被拒绝的任务，如果执行程序已关闭，则会丢弃该任务。因此这种策略会降低对于新任务提交速度，影响程序的整体性能。如果您的应用程序可以承受此延迟并且你要求任何一个任务请求都要被执行的话，你可以选择这个策略。 ThreadPoolExecutor.DiscardPolicy： 不处理新任务，直接丢弃掉。 ThreadPoolExecutor.DiscardOldestPolicy： 此策略将丢弃最早的未处理的任务请求。 Atomic原子类 AtomicInteger 类的原理\nAtomicInteger 类主要利用 CAS (compare and swap) + volatile 和 native 方法来保证原子操作，从而避免 synchronized 的高开销，执行效率大为提升。\nCAS 的原理是拿期望的值和原本的一个值作比较，如果相同则更新成新的值。UnSafe 类的 objectFieldOffset() 方法是一个本地方法，这个方法是用来拿到“原来的值”的内存地址，返回值是 valueOffset。另外 value 是一个 volatile 变量，在内存中可见，因此 JVM 可以保证任何时刻任何线程总能拿到该变量的最新值。\nAQS AQS（AbstractQueuedSynchronizer），是一个用来构建锁和同步器的框架，使用 AQS 能简单且高效地构造出大量应用广泛的同步器，比如我们提到的 ReentrantLock，Semaphore，其他的诸如 ReentrantReadWriteLock，SynchronousQueue，FutureTask 等等皆是基于 AQS 的。\n核心思想：如果被请求的共享资源空闲，则将当前请求资源的线程设置为有效的工作线程，并且将共享资源设置为锁定状态。如果被请求的共享资源被占用，那么就需要一套线程阻塞等待以及被唤醒时锁分配的机制，这个机制 AQS 是用 CLH 队列锁实现的，即将暂时获取不到锁的线程加入到队列中。\nAQS 定义两种资源共享方式\nExclusive（独占）：只有一个线程能执行，如ReentrantLock。又可分为公平锁和非公平锁：\n公平锁：按照线程在队列中的排队顺序，先到者先拿到锁 非公平锁：当线程要获取锁时，无视队列顺序直接去抢锁，谁抢到就是谁的 Share（共享）：多个线程可同时执行，如 CountDownLatch、Semaphore、 CyclicBarrier、ReadWriteLock 。\nCountDownLatch 是计数器，只能使用一次，而 CyclicBarrier 的计数器提供 reset 功能，可以多次使用。\n对于 CountDownLatch 来说，重点是“一个线程（多个线程）等待”，而其他的 N 个线程在完成“某件事情”之后，可以终止，也可以等待。而对于 CyclicBarrier，重点是多个线程，在任意一个线程没有完成，所有的线程都必须等待。\nAQS使用\n从ReentrantLock的实现看AQS的原理及应用 | JavaGuide\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 public class LeeLock { private static class Sync extends AbstractQueuedSynchronizer { @Override protected boolean tryAcquire (int arg) { return compareAndSetState(0, 1); } @Override protected boolean tryRelease (int arg) { setState(0); return true; } @Override protected boolean isHeldExclusively () { return getState() == 1; } } private Sync sync = new Sync(); public void lock () { sync.acquire(1); } public void unlock () { sync.release(1); } } public class LeeMain { static int count = 0; static LeeLock leeLock = new LeeLock(); public static void main (String[] args) throws InterruptedException { Runnable runnable = new Runnable() { @Override public void run () { try { leeLock.lock(); for (int i = 0; i \u0026lt; 10000; i++) { count++; } } catch (Exception e) { e.printStackTrace(); } finally { leeLock.unlock(); } } }; Thread thread1 = new Thread(runnable); Thread thread2 = new Thread(runnable); thread1.start(); thread2.start(); thread1.join(); thread2.join(); System.out.println(count); } } CopyOnWriteArrayList CopyOnWriteArrayList 类的所有可变操作（add，set 等等）都是通过创建底层数组的新副本来实现的。当 List 需要被修改的时候，我并不修改原有内容，而是对原有数据进行一次复制，将修改的内容写入副本。写完之后，再将修改完的副本替换原来的数据，这样就可以保证写操作不会影响读操作了。\n读取操作没有任何同步控制和锁操作，理由就是内部数组 array 不会发生修改，只会被另外一个 array 替换，因此可以保证数据安全。\nCopyOnWriteArrayList 写入操作 add()方法在添加集合的时候加了锁，保证了同步，避免了多线程写的时候会 copy 出多个副本出来。\n==Spring== IoC 控制反转就是把创建和管理 bean 的过程转移给了第三方。而这个第三方，就是 Spring IoC Container，对于 IoC 来说，最重要的就是容器。\n配置文件把资源从外部注入到内部，容器加载了外部的文件、对象、数据，然后把这些资源注入给程序内的对象，维护了程序内外对象之间的依赖关系。依赖注入是实现控制反转的一种方式，IoC 是设计思想，DI 是具体的实现方式。\nBean的生命周期：\nBean的作用域：\nsingleton : 唯一 bean 实例，Spring 中的 bean 默认都是单例的。(可以定义ThreadLocal保证线程安全) prototype : 每次请求都会创建一个新的 bean 实例。 request : 每一次HTTP请求都会产生一个新的bean，该bean仅在当前HTTP request内有效。 session : 每一次HTTP请求都会产生一个新的 bean，该bean仅在当前 HTTP session 内有效。 global-session：全局session作用域，仅仅在基于portlet的web应用中才有意义，Spring5已经没有了。Portlet是能够生成语义代码(例如：HTML)片段的小型Java Web插件。它们基于portlet容器，可以像servlet一样处理HTTP请求。但是，与 servlet 不同，每个 portlet 都有不同的会话 AOP JointPoint、Pointcut、Advice\n动态代理和静态代理\nJava 源代码经过编译生成字节码，然后再由 JVM 经过类加载，连接，初始化成 Java 类型，而字节码是关键，静态和动态的区别就在于字节码生成的时机。\n静态代理：由程序员创建代理类或特定工具自动生成源代码再对其编译。在编译时已经将接口，被代理类（委托类），代理类等确定下来，在程序运行前代理类的.class文件就已经存在了。\n静态代理主要有两大劣势\n代理类只代理一个委托类（其实可以代理多个，但不符合单一职责原则），也就意味着如果要代理多个委托类，就要写多个代理（别忘了静态代理在编译前必须确定） 第一点还不是致命的，再考虑这样一种场景：如果每个委托类的每个方法都要被织入同样的逻辑，比如说我要计算前文提到的每个委托类每个方法的耗时，就要在方法开始前，开始后分别织入计算时间的代码，那就算用代理类，它的方法也有无数这种重复的计算时间的代码，难以复用，修改不方便。 动态代理：在程序运行后通过反射创建生成字节码再由 JVM 加载而成\nJDK动态代理第二个参数newProxyInstance的 Interfaces 是委托类的接口，是必传的， JDK 动态代理是通过与委托类实现同样的接口，然后在实现的接口方法里进行增强来实现的，这就意味着如果要用 JDK 代理，委托类必须实现接口。\nCGLIB并不要求委托类实现任何接口，而且 CGLIB 是高效的代码生成包，底层依靠 ASM（开源的 java 字节码编辑类库）操作字节码实现的，性能比 JDK 强，所以 Spring AOP 最终使用了 CGlib 来生成动态代理。（CGLIB通过继承的方法进行代理，因此委托类如果是被final修饰的话不能被代理）。\n由于反射的效率比较低，所以 CGlib 采用了FastClass 的机制来实现对被拦截方法的调用。FastClass 机制就是对一个类的方法建立索引，通过索引来直接调用相应的方法。\nhttps://www.cnblogs.com/cruze/p/3865180.html\nSpring AOP vs AspectJ AOP\nSpring AOP 属于运行时增强，而 AspectJ 是编译时增强。 Spring AOP 基于代理(Proxying)，而 AspectJ 基于字节码操作(Bytecode Manipulation)。\nSpring AOP 已经集成了 AspectJ ，AspectJ 应该算的上是 Java 生态系统中最完整的 AOP 框架了。AspectJ 相比于 Spring AOP 功能更加强大，但是 Spring AOP 相对来说更简单，\n如果我们的切面比较少，那么两者性能差异不大。但是，当切面太多的话，最好选择 AspectJ ，它比Spring AOP 快很多。\nTomcat (45条消息) 四张图带你了解Tomcat系统架构_愿天堂没有阿雨的博客-CSDN博客_tomcat架构图\n理解Tomcat工作原理 - 简书 (jianshu.com)\n事务 REQUIRED 只要内层方法报错抛出异常，即使外层有try-catch，该事务也会回滚！\n因为内外层方法在同一个事务中，内层只要抛出了异常，这个事务就会被设置成rollback-only，即使外层try-catch内层的异常，该事务也会回滚。\nREQUIRES_NEW 内层事务结束，内层就提交了，不用等着外层一起提交。\n外层报错回滚，不影响内层。\n内层报错回滚，外层try-catch内层的异常，外层不会回滚。\n内层报错回滚，然后又会抛出异常，外层如果没有捕获处理内层抛出来的这个异常，外层还是会回滚的。\nNESTED 内层事务结束，要等着外层一起提交。\n外层回滚，内层也回滚。\n如果只是内层回滚，不影响外层。但是这个内层回滚不影响外层的特性是有前提的，否则内外都回滚。\n使用前提：\n1.JDK版本要在1.4以上，有java.sql.Savepoint。因为nested就是用savepoint来实现的。\n2.事务管理器的nestedTransactionAllowed属性为true。\n3.外层try-catch内层的异常。\nSUPPORTS 支持事务。当前有事务就支持。当前没有事务就算了，不会开启一个事物。\nMANDATORY 支持事务，如果业务方法执行时已经在一个事务中，则加入当前事务。否则抛出异常。\nNOT_SUPPORTED 不支持事务，如果业务方法执行时已经在一个事务中，则挂起当前事务，等方法执行完毕后，事务恢复进行。\nNEVER 不支持事务。如果当前已经在一个事务中了，抛出异常。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 //若同一类中的其他没有 `@Transactional` 注解的方法内部调用有 `@Transactional` 注解的方法，有`@Transactional` 注解的方法的事务会失效。这是由于`Spring AOP`代理的原因造成的，因为只有当 `@Transactional` 注解的方法在类以外被调用的时候，Spring 事务管理才生效。 @Service public class MyService { private void method1() { //MyService 类中的 method1() 调用 method2() 就会导致 method2() 的事务失效。 method2(); //...... } @Transactional public void method2() { //...... } } //解决办法就是避免同一类中自调用或者使用 AspectJ 取代 Spring AOP 代理。 解决循环依赖 singletonObjects 它是我们最熟悉的朋友，俗称“单例池”“容器”，缓存创建完成单例Bean的地方。 singletonFactories 映射创建Bean的原始工厂 earlySingletonObjects 映射Bean的早期引用，也就是说在这个Map里的Bean不是完整的，甚至还不能称之为“Bean”，只是一个Instance. 后两个Map其实是“垫脚石”级别的，只是创建Bean的时候，用来借助了一下，创建完成就清掉了。\n类比Two Sum算法题\nhttps://mp.weixin.qq.com/s/5mwkgJB7GyLdKDgzijyvXw\nSpring中的设计模式 工厂设计模式 : Spring使用工厂模式通过 BeanFactory、ApplicationContext 创建 bean 对象。 代理设计模式 : Spring AOP 功能的实现。 单例设计模式 : Spring 中的 Bean 默认都是单例的。 模板方法模式 : Spring 中 jdbcTemplate、hibernateTemplate 等以 Template 结尾的对数据库操作的类，它们就使用到了模板模式。 包装器设计模式 : 我们的项目需要连接多个数据库，而且不同的客户在每次访问中根据需要会去访问不同的数据库。这种模式让我们可以根据客户的需求能够动态切换不同的数据源。 观察者模式: Spring 事件驱动模型就是观察者模式很经典的一个应用。 适配器模式 :Spring AOP 的增强或通知(Advice)使用到了适配器模式、spring MVC 中也是用到了适配器模式适配Controller。 MyBatis Dao 接口，就是人们常说的 Mapper 接口，接口的全限名，就是映射文件中的 namespace 的值，接口的方法名，就是映射文件中 MappedStatement 的 id 值，接口方法内的参数，就是传递给 sql 的参数。\nDao 接口里的方法可以重载，但是 Mybatis 的 XML 里面的 ID 不允许重复。\nDao 接口的工作原理是 JDK 动态代理，MyBatis 运行时会使用 JDK 动态代理为 Dao 接口生成代理 proxy 对象，代理对象 proxy 会拦截接口方法，转而执行 MappedStatement 所代表的 sql，然后将 sql 执行结果返回。\nMyBatis 仅可以编写针对 ParameterHandler 、 ResultSetHandler 、 StatementHandler 、 Executor 这 4 种接口的插件，MyBatis 使用 JDK 的动态代理，为需要拦截的接口生成代理对象以实现接口方法拦截功能\n系统设计与设计模式 设计原则 单一职责\n里氏替换\n所有引用基类的地方必须能透明地使用其子类的对象。\n子类必须完全实现父类的方法\n子类可以有自己的个性\n覆盖或实现父类的方法时参数可以被放大\n覆写或实现父类的方法时输出结构可以被缩小\n依赖倒置\n依赖倒置原则的核心思想是面向接口编程。\n依赖是可以传递的，对象的依赖关系有三种方式来传递：\n构造函数传递依赖对象。在类中通过构造函数声明依赖对象，按照依赖注入的说法，这种方式叫作构造函数注入； Setter方法传递依赖对象。在抽象类中设置Setter方法声明依赖关系，依照依赖注入的说法，这是Setter依赖注入； 接口声明依赖对象。在接口的方法中声明依赖对象，这种方法也叫做接口注入。 接口隔离\n客户端不应该依赖它不需要的接口；一个类对另一个类的依赖应该建立在最小的接口上。\n建立单一接口，不要建立臃肿庞大的接口。更通俗的讲：接口尽量细化，同时接口中的方法尽量少。\n接口隔离原则 vs. 单一职责原则:\n二者的审视角度不同，单一职责要求的是类和接口职责单一，注重的是职责，这是业务逻辑上的划分，而接口隔离原则要求接口的方法尽量少，它要求”尽量使用多个专门的接口“。\n迪米特\n最少知识原则：一个对象应该对其他对象有最少的了解，即一个类应该对自己需要耦合或调用的类知道得最少，只关注自己调用的public方法，其他的一概不关心。\n迪米特法则的核心思想就是类间解耦，弱耦合，只有弱耦合了以后，类的复用率才可以提高。其要求的结果就是产生了大量的中转或跳转类，导致系统的复杂性提高，同时也为维护带来了的难度。因此在采用迪米特法则时，既要做到让结构清晰，又做到高内聚低耦合。\n开闭\n一个软件实体类，如类、模块和函数应该对扩展开放，对修改关闭。\n抽象约束：抽象是对一组事物的通用描述，没有具体的实现，也就表示它可以有非常多的可能性，可以跟随需求的变化而变化。因此接口或抽象类可以约束一组可能变化的行为，并且能够实现对扩展开放。 元数据控制模块行为：元数据是用来描述环境和数据的数据，通俗地讲就是配置参数，参数可以从文件中获得，也可以从数据库中获得，使用此方法的极致就是控制反转，使用最多的就是Spring容器。 制定项目章程：对项目来说，约定优于配置。章程中指定了所有人员都必须遵守的约定。 封装变化：将相同的变化封装到一个接口或抽象类中；将不同的变化封装到不同的接口或抽象类中，不应该有两个不同的变化出现在同一个接口或抽象类中。封装变化，也就是受保护的变化，找出预计有变化或不稳定的点，为这些变化点创建稳定的接口。 设计原则 一句话归纳 目的 开闭原则 对扩展开放，对修改关闭 降低维护带来的新风险 依赖倒置原则 高层不应该依赖低层，要面向接口编程 更利于代码结构的升级扩展 单一职责原则 一个类只干一件事，实现类要单一 便于理解，提高代码的可读性 接口隔离原则 一个接口只干一件事，接口要精简单一 功能解耦，高聚合、低耦合 迪米特法则 不该知道的不要知道，一个类应该保持对其它对象最少的了解，降低耦合度 只和朋友交流，不和陌生人说话，减少代码臃肿 里氏替换原则 不要破坏继承体系，子类重写方法功能发生改变，不应该影响父类方法的含义 防止继承泛滥 合成复用原则 尽量使用组合或者聚合关系实现代码复用，少使用继承 降低代码耦合 设计模式 创建型模式（5种） 工厂模式 简单工厂模式就是建立一个实例化对象的类，在该类中对多个对象实例化。\n工厂方法模式是定义了一个创建对象的抽象方法，由子类决定要实例化的类。这样做的好处是再有新的类型的对象需要实例化只要增加子类即可。\n抽象工厂模式定义了一个接口用于创建对象族，而无需明确指定具体类。抽象工厂也是把对象的实例化交给了子类，即支持拓展。同时提供给客户端接口，避免了用户直接操作子类工厂。\n单例模式（多种实现） 饿汉式\n1 2 3 4 5 6 7 8 9 10 11 class A { public static A instance = new A(); public static A getA() { return instance; } //外部无法自行构造 private A() { } } 懒汉式（DLC线程安全方式）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 //jvm为了提高程序执行性能，会对没有依赖关系的代码进行重排序，new一个对象是不能保证顺序性的，创建对象要分配空间、初始化空间、指向空间，若指向空间提前，则其他线程会跳过外层判空逻辑，此时还没有初始化内存，就会产生错误，因此，我们需要使用关键字volatile保证对象实例化过程的顺序性。 class A { public static volatile A instance = null; public static A getInstance() { if (instance == null) synchronized (A.class) { if (instance == null) instance = new A(); } return instance; } private A() { } } 静态内部类\n静态内部类在外部类装载时不会实例化，当调用的时候才会装载并实例化，且JVM保证了其装载时的线程安全性。也能保证懒加载和线程安全，有点像自带版的双重检查。\n1 2 3 4 5 6 7 8 9 class Singleton { private Singleton() {} private static class SingletonInstance { private static final Singleton INSTANCE = new Singleton(); } public static Singleton getInstance() { return SingletonInstance.INSTANCE; } } 枚举\n不仅能避免多线程同步问题，也能防止反序列化重新创建新的对象。\n1 2 3 public enum Singleton6 { INSTANCE; } 生成器模式 封装一个复杂对象构造过程，并允许按步骤构造。\n我们可以将生成器模式理解为，假设我们有一个对象需要建立，这个对象是由多个组件（Component）组合而成，每个组件的建立都比较复杂，但运用组件来建立所需的对象非常简单，所以我们就可以将构建复杂组件的步骤与运用组件构建对象分离，使用builder模式可以建立。\n与工厂模式的区别：\n生成器模式构建对象的时候，对象通常构建的过程中需要多个步骤，就像我们例子中的先有主机，再有显示屏，再有鼠标等等，生成器模式的作用就是将这些复杂的构建过程封装起来。工厂模式构建对象的时候通常就只有一个步骤，调用一个工厂方法就可以生成一个对象。\n原型模式 通过复制现有实例来创建新的实例，无需知道相应类的信息。\n深拷贝、浅拷贝\n原型模式的具体实现：一个原型类，只需要实现Cloneable接口，覆写clone方法，此处clone方法可以改成任意的名称，因为Cloneable接口是个空接口，你可以任意定义实现类的方法名。\nsuper.clone()并不能完全实现深拷贝，比如类中引用的其他类实例。\n结构型模式（7种） 适配器模式 根据合成复用原则，组合大于继承。因此，类的适配器模式应该少用。\n类适配器模式\n通过多重继承目标接口和被适配者类方式来实现适配\n对象适配器模式\n对象适配器使用组合，类适配器使用继承。\n当希望将一个对象转换成满足另一个新接口的对象时，可以创建一个Wrapper类，持有原类的一个实例，在Wrapper类的方法中，调用实例的方法就行。\n1 2 3 4 5 6 7 public class AdapterUSB2VGA implements VGA { USB u = new USBImpl(); @Override public void projection() { u.showPPT(); } } 接口适配器模式\n当不需要全部实现接口提供的方法时，可先设计一个抽象类实现接口，并为该接口中每个方法提供一个默认实现（空方法），那么该抽象类的子类可有选择地覆盖父类的某些方法来实现需求\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 public abstract class AdapterUSB2VGA implements VGA { USB u = new USBImpl(); @Override public void projection() { u.showPPT(); } @Override public void b() { }; @Override public void c() { }; } public class AdapterUSB2VGAImpl extends AdapterUSB2VGA { public void projection() { super.projection(); } } 装饰者模式 动态的将新功能附加到对象上。在对象功能扩展方面，它比继承更有弹性。\n装饰者和被装饰者之间必须是一样的类型,也就是要有共同的超类。在这里应用继承并不是实现方法的复制,而是实现类型的匹配。因为装饰者和被装饰者是同一个类型,因此装饰者可以取代被装饰者,这样就使被装饰者拥有了装饰者独有的行为。根据装饰者模式的理念,我们可以在任何时候,实现新的装饰者增加新的行为。如果是用继承,每当需要增加新的行为时,就要修改原程序了。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 //demo public class Coffee extends Drink { @Override public float cost() { // TODO Auto-generated method stub return super.getPrice(); } } public class Decaf extends Coffee { public Decaf() { super.setDescription(\u0026#34;Decaf\u0026#34;); super.setPrice(3.0f); } } //可以往装饰器里面传装饰器，比如先用牛奶修饰咖啡，再用巧克力修饰这个饮品。 public class Decorator extends Drink { private Drink Obj; public Decorator(Drink Obj) { this.Obj = Obj; }; @Override public float cost() { // TODO Auto-generated method stub return super.getPrice() + Obj.cost(); } @Override public String getDescription() { return super.description + \u0026#34;-\u0026#34; + super.getPrice() + \u0026#34;\u0026amp;\u0026amp;\u0026#34; + Obj.getDescription(); } } public class Milk extends Decorator { public Milk(Drink Obj) { super(Obj); // TODO Auto-generated constructor stub super.setDescription(\u0026#34;Milk\u0026#34;); super.setPrice(2.0f); } } 代理模式 代理模式给某一个对象提供一个代理对象，并由代理对象控制对原对象的引用。\n静态代理\n代理对象与目标对象要实现相同的接口，我们得为每一个服务都得创建代理类，工作量太大，不易管理。同时接口一旦发生改变，代理类也得相应修改。\n动态代理\n代理对象的生成,是利用JDK的API,动态的在内存中构建代理对象(需要我们指定创建代理对象/目标对象实现的接口的类型)。代理类不用再实现接口了。但是，要求被代理对象必须有接口。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 //demo public class DynamicProxyHandler implements InvocationHandler { private Object object; public DynamicProxyHandler(final Object object) { this.object = object; } @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { System.out.println(\u0026#34;买房前准备\u0026#34;); Object result = method.invoke(object, args); System.out.println(\u0026#34;买房后装修\u0026#34;); return result; } } public class DynamicProxyTest { public static void main(String[] args) { BuyHouse buyHouse = new BuyHouseImpl(); BuyHouse proxyBuyHouse = (BuyHouse) Proxy.newProxyInstance( BuyHouse.class.getClassLoader(), new Class[]{BuyHouse.class}, new DynamicProxyHandler(buyHouse)); proxyBuyHouse.buyHosue(); } } CGLIB代理\nCGLIB创建的动态代理对象比JDK创建的动态代理对象的性能更高，但是CGLIB创建代理对象时所花费的时间却比JDK多得多。所以对于单例的对象，因为无需频繁创建对象，用CGLIB合适，反之使用JDK方式要更为合适一些。同时由于CGLib由于是采用动态创建子类的方法，对于final修饰的方法无法进行代理。\n外观模式 隐藏了系统的复杂性，并向客户端提供了一个可以访问系统的接口。\n使得客户端和子系统之间解耦，让子系统内部的模块功能更容易扩展和维护；\n有些方法是对系统外的，有些方法是系统内部相互交互的使用的。子系统把那些暴露给外部的功能集中到门面中，这样就可以实现客户端的使用，很好的隐藏了子系统内部的细节。\n桥接模式 将抽象部分与它的实现部分分离，使它们都可以独立地变化。\n桥接模式通常适用于以下场景。\n当一个类存在两个独立变化的维度，且这两个维度都需要进行扩展时。 当一个系统不希望使用继承或因为多层次继承导致系统类的个数急剧增加时。 当一个系统需要在构件的抽象化角色和具体化角色之间增加更多的灵活性时。 组合模式 有时又叫作部分-整体模式，它是一种将对象组合成树状的层次结构的模式，用来表示“部分-整体”的关系，使用户对单个对象和组合对象具有一致的访问性。\n优势\n组合模式使得客户端代码可以一致地处理单个对象和组合对象，无须关心自己处理的是单个对象，还是组合对象，这简化了客户端代码； 更容易在组合体内加入新的对象，客户端不会因为加入了新的对象而更改源代码，满足“开闭原则”； 缺陷：设计较复杂，客户端需要花更多时间理清类之间的层次关系；不容易限制容器中的构件；不容易用继承的方法来增加构件的新功能；\n举例（访问一颗树）\n享元模式 通过共享的方式高效的支持大量细粒度的对象。\n何时使用： 1、系统中有大量对象。 2、这些对象消耗大量内存。 3、这些对象的状态大部分可以外部化。 4、这些对象可以按照内蕴状态分为很多组，当把外蕴对象从对象中剔除出来时，每一组对象都可以用一个对象来代替。 5、系统不依赖于这些对象身份，这些对象是不可分辨的。\n**优点：**大大减少对象的创建，降低系统的内存，使效率提高。\n缺点：提高了系统的复杂度，需要分离出外部状态和内部状态，而且外部状态具有固有化的性质，不应该随着内部状态的变化而变化，否则会造成系统的混乱。\n享元工厂类创建并且管理享元类，享元工厂类针对享元类来进行编程，通过提供一个享元池来进行享元对象的管理。一般享元池设计成键值对（哈希表存储），或者其他的存储结构来存储。当客户端进行享元对象的请求时，如果享元池中有对应的享元对象则直接返回对应的对象，否则工厂类创建对应的享元对象并保存到享元池。\n行为型模式（关系模式11种） 策略模式 策略模式定义了一系列算法，并将每个算法封装起来，使他们可以相互替换，且算法的变化不会影响到使用算法的客户。\n模板方法模式 定义一个操作中算法的骨架，而将一些步骤延迟到子类中，模板方法使得子类可以不改变算法的结构即可重定义该算法的某些特定步骤。\n优点：\n（1）具体细节步骤实现定义在子类中，子类定义详细处理算法是不会改变算法整体结构。\n（2）代码复用的基本技术，在数据库设计中尤为重要。\n（3）存在一种反向的控制结构，通过一个父类调用其子类的操作，通过子类对父类进行扩展增加新的行为，符合“开闭原则”。\n缺点： 每个不同的实现都需要定义一个子类，会导致类的个数增加，系统更加庞大。\n观察者模式 定义对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。\n举例：在抽象类里有一个 ArrayList 存放观察者们。当被观察者更新信息的时候就将通知发送到List里面各个观察者们。\n迭代器模式 提供一种方法顺序访问一个聚合对象中各个元素, 而又无须暴露该对象的内部表示。\n不同种类的对象可能需要不同的遍历方式，我们对每一种类型的对象配一个迭代器，最后多个迭代器合成一个。\n**主要解决：**不同的方式来遍历整个整合对象。\n**关键代码：**定义接口：hasNext, next。\n责任链模式 如果有多个对象有机会处理请求，责任链可使请求的发送者和接受者解耦，请求沿着责任链传递，直到有一个对象处理了它为止。\ndemo\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 public class GroupApprover extends Approver { public GroupApprover(String Name) { super(Name + \u0026#34; GroupLeader\u0026#34;); // TODO Auto-generated constructor stub } @Override public void ProcessRequest(PurchaseRequest request) { // TODO Auto-generated method stub if (request.GetSum() \u0026lt; 5000) { System.out.println(\u0026#34;**This request \u0026#34; + request.GetID() + \u0026#34; will be handled by \u0026#34; + this.Name + \u0026#34; **\u0026#34;); } else { successor.ProcessRequest(request); } } } public class DepartmentApprover extends Approver { public DepartmentApprover(String Name) { super(Name + \u0026#34; DepartmentLeader\u0026#34;); } @Override public void ProcessRequest(PurchaseRequest request) { // TODO Auto-generated method stub if ((5000 \u0026lt;= request.GetSum()) \u0026amp;\u0026amp; (request.GetSum() \u0026lt; 10000)) { System.out.println(\u0026#34;**This request \u0026#34; + request.GetID() + \u0026#34; will be handled by \u0026#34; + this.Name + \u0026#34; **\u0026#34;); } else { successor.ProcessRequest(request); } } } public class MainTest { public static void main(String[] args) { Client mClient = new Client(); //定义好责任链 Approver GroupLeader = new GroupApprover(\u0026#34;Tom\u0026#34;); Approver DepartmentLeader = new DepartmentApprover(\u0026#34;Jerry\u0026#34;); Approver VicePresident = new VicePresidentApprover(\u0026#34;Kate\u0026#34;); Approver President = new PresidentApprover(\u0026#34;Bush\u0026#34;); GroupLeader.SetSuccessor(VicePresident); DepartmentLeader.SetSuccessor(President); VicePresident.SetSuccessor(DepartmentLeader); President.SetSuccessor(GroupLeader); GroupLeader.ProcessRequest(mClient.sendRequst(1, 10000, 40)); } } 命令模式 将一个请求封装为一个对象，使发出请求的责任和执行请求的责任分割开。这样两者之间通过命令对象进行沟通，这样方便将命令对象进行储存、传递、调用、增加与管理。\n状态模式 在状态模式中，我们创建表示各种状态的对象和一个行为随着状态对象改变而改变的 context 对象。简单理解，一个拥有状态的context对象，在不同的状态下，其行为会发生改变。\n通常命令模式的接口中只有一个方法。而状态模式的接口中有一个或者多个方法。而且，状态模式的实现类的方法，一般返回值，或者是改变实例变量的值。也就是说，状态模式一般和对象的状态有关。实现类的方法有不同的功能，覆盖接口中的方法。状态模式和命令模式一样，也可以用于消除 if\u0026hellip;else 等条件选择语句。\n备忘录模式 在不破坏封装性的前提下，捕获一个对象的内部状态，并在该对象之外保存这个状态，以便以后当需要时能将该对象恢复到原先保存的状态。该模式又叫快照模式。\ndemo\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 public class Memento implements MementoIF{ @Getter private String state; public Memento(String state) { this.state = state; } } public class Originator { @Getter @Setter private String state; public Memento saveToMemento() { return new Memento(state); } public String getStateFromMemento(MementoIF memento) { return ((Memento) memento).getState(); } } public class CareTaker { //保存历史纪录 private List\u0026lt;MementoIF\u0026gt; mementoList = new ArrayList\u0026lt;MementoIF\u0026gt;(); public void add(MementoIF memento) { mementoList.add(memento); } public MementoIF get(int index) { return mementoList.get(index); } } 访问者模式 将作用于某种数据结构中的各元素的操作分离出来封装成独立的类，使其在不改变数据结构的前提下可以添加作用于这些元素的新的操作，为数据结构中的每个元素提供多种访问方式。它将对数据的操作与数据结构进行分离。\ndemo\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 public abstract class Visitor { public abstract void visitConcreteElementA(ConcreteElementA concreteElementA); } public class ConcreteVisitorA extends Visitor { @Override public void visitConcreteElementA(ConcreteElementA concreteElementA) { System.out.println(concreteElementA.getClass() + \u0026#34;被\u0026#34; + this.getClass() + \u0026#34;访问\u0026#34;); } } public abstract class Element { public abstract void accept(Visitor visitor); } public class ConcreteElementA extends Element { @Override public void accept(Visitor visitor) { visitor.visitConcreteElementA(this); } //其它相关方法 public void operationA(){} } public class ObjectStructure { private List\u0026lt;Element\u0026gt; elements = new ArrayList\u0026lt;Element\u0026gt;(); //添加元素 public void attach(Element element){ elements.add(element); } //移除元素 public void detach(Element element){ elements.remove(element); } //元素接受访问者访问 public void accept(Visitor visitor){ for (Element e : elements) { e.accept(visitor); } } } public class VisitorPatternDemo { public static void main(String[] args) { ObjectStructure objectStructure = new ObjectStructure(); //将需要被访问的element实例添加到数据结构ObjectStructure中 objectStructure.attach(new ConcreteElementA()); ConcreteVisitorA concreteVisitorA = new ConcreteVisitorA(); //element接受访问者的访问 objectStructure.accept(concreteVisitorA); } } 中介者模式 定义一个中介对象来封装一系列对象之间的交互，使原有对象之间的耦合松散，且可以独立地改变它们之间的交互。中介者模式又叫调停模式，它是迪米特法则的典型应用。\ndemo：（消息发送）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 //消息中介 public class ConcreteMediator implements Mediator { private List\u0026lt;Colleague\u0026gt; colleagues = new ArrayList\u0026lt;Colleague\u0026gt;(); @Override public void register(Colleague colleague) { // TODO Auto-generated method stub if (!colleagues.contains(colleague)) { colleagues.add(colleague); colleague.setMedium(this); } } @Override public void relay(String from, String to, String ad) { // TODO Auto-generated method stub for (Colleague cl : colleagues) { String name = cl.getName(); if (name.equals(to)) { cl.receive(from, ad); } } } } //消息方 public abstract class Colleague { protected Mediator mediator; protected String name; public Colleague(String name) { this.name = name; } public void setMedium(Mediator mediator) { this.mediator = mediator; } public String getName() { return name; } public abstract void Send(String to, String ad); public abstract void receive(String from, String ad); } //消息方impl类 public class Buyer extends Colleague { public Buyer(String name) { super(name); } @Override public void Send(String to, String ad) { // TODO Auto-generated method stub mediator.relay(name, to, ad); } @Override public void receive(String from, String ad) { // TODO Auto-generated method stub System.out.println(name + \u0026#34;接收到来自\u0026#34; + from + \u0026#34;的消息:\u0026#34; + ad); } } 解释器模式（略） 给分析对象定义一个语言，并定义该语言的文法表示，再设计一个解析器来解释语言中的句子。也就是说，用编译语言的方式来分析应用中的实例。这种模式实现了文法表达式处理的接口，该接口解释一个特定的上下文。\n解释器模式实现的关键是定义文法规则、设计终结符类与非终结符类、画出结构图，必要时构建语法树\n(32条消息) 23 种设计模式详解（全23种）_鬼灭之刃的博客-CSDN博客_设计模式\n","date":"2023-05-11T17:06:50+08:00","permalink":"https://hifing.github.io/p/java%E6%8A%80%E6%9C%AF%E6%A0%88%E9%9B%86%E9%94%A6/","title":"Java技术栈集锦"},{"content":"","date":"2023-05-03T17:06:50+08:00","permalink":"https://hifing.github.io/p/redis%E5%9F%BA%E7%A1%80/","title":"Redis基础"},{"content":"MySQL日志 undo log（回滚日志）：用于实现事务原子性、MVCC（ReadView + undo log）。 redo log（重做日志）：用于实现事务的持久性、数据掉电恢复。 binlog（归档日志）：数据备份、主从同步。 undo log 一条记录的每一次更新操作产生的 undo log 格式都有一个 roll_pointer 指针和一个 trx_id 事务id：\n通过 trx_id 可以知道该记录是被哪个事务修改的； 通过 roll_pointer 指针可以将这些 undo log 串成一个链表，这个链表就被称为版本链； TIP\nundo log刷盘和数据页的刷盘逻辑是一样的，通过redo log保证数据持久化. buffer pool 中有 undo 页，对 undo 页的修改也都会记录到 redo log。redo log 会每秒刷盘，提交事务时也会刷盘，数据页和 undo 页都是靠这个机制保证持久化的。\nbuffer pool buffer pool所在的位置：\nbuffer pool结构：\n当修改数据时，如果数据存在于 Buffer Pool 中，那直接修改 Buffer Pool 中数据所在的页，然后将其页设置为脏页（该页的内存数据和磁盘上的数据已经不一致），为了减少磁盘I/O，不会立即将脏页写入磁盘，后续由后台线程选择一个合适的时机将脏页写入到磁盘。这就是 WAL （Write-Ahead Logging）技术。 开启事务后，InnoDB 层更新记录前，首先要记录相应的 undo log，如果是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面。 redo log 为什么要redo log Buffer Pool 是提高了读写效率没错，但是问题来了，Buffer Pool 是基于内存的，而内存总是不可靠，万一断电重启，还没来得及落盘的脏页数据就会丢失。\n为了防止断电导致数据丢失的问题，当有一条记录需要更新的时候，InnoDB 引擎就会先更新内存（同时标记为脏页），然后将本次对这个页的修改以 redo log 的形式记录下来，这个时候更新就算完成了。\nTIP\n被修改 Undo 页面，需要记录对应 redo log： 开启事务后，InnoDB 层更新记录前，首先要记录相应的 undo log，如果是更新操作，需要把被更新的列的旧值记下来，也就是要生成一条 undo log，undo log 会写入 Buffer Pool 中的 Undo 页面。 不过，在内存修改该 Undo 页面后，需要记录对应的 redo log。\n写入 redo log 的方式使用了追加操作， 所以磁盘操作是顺序写，而写入数据需要先找到写入位置，然后才写到磁盘，所以磁盘操作是随机写。 磁盘的「顺序写 」比「随机写」 高效的多，因此 redo log 写入磁盘的开销更小。\nredo log持久化机制 主要有下面几个时机： MySQL 正常关闭时； 当 redo log buffer 中记录的写入量大于 redo log buffer 内存空间的一半时，会触发落盘； InnoDB 的后台线程每隔 1 秒，将 redo log buffer 持久化到磁盘。 每次事务提交时都将缓存在 redo log buffer 里的 redo log 直接持久化到磁盘（这个策略可由 innodb_flush_log_at_trx_commit 参数控制，下面会说）。 如何通过innodb_flush_log_at_trx_commit进行刷盘时机控制：\nTIP\nInnoDB 的后台线程每隔 1 秒：\n针对参数 0 ：会把缓存在 redo log buffer 中的 redo log ，通过调用 write() 写到操作系统的 Page Cache，然后调用 fsync() 持久化到磁盘。所以参数为 0 的策略，MySQL 进程的崩溃会导致上一秒钟所有事务数据的丢失;\n针对参数 2 ：调用 fsync，将缓存在操作系统中 Page Cache 里的 redo log 持久化到磁盘。所以参数为 2 的策略，较取值为 0 情况下更安全，因为 MySQL 进程的崩溃并不会丢失数据，只有在操作系统崩溃或者系统断电的情况下，上一秒钟所有事务数据才可能丢失。\nredo log 写满了怎么办 redo log 是循环写的方式，相当于一个环形，InnoDB 用 write pos 表示 redo log 当前记录写到的位置，用 checkpoint 表示当前要擦除的位置：\n如果 write pos 追上了 checkpoint，就意味着 redo log 文件满了，这时 MySQL 不能再执行新的更新操作，也就是说 MySQL 会被阻塞（因此所以针对并发量大的系统，适当设置 redo log 的文件大小非常重要），此时会停下来将 Buffer Pool 中的脏页刷新到磁盘中，然后标记 redo log 哪些记录可以被擦除，接着对旧的 redo log 记录进行擦除，等擦除完旧记录腾出了空间，checkpoint 就会往后移动（图中顺时针），然后 MySQL 恢复正常运行，继续执行新的更新操作。\nbinlog MySQL 在完成一条更新操作后，Server 层还会生成一条 binlog，等之后事务提交的时候，会将该事物执行过程中产生的所有 binlog 统一写 入 binlog 文件。\nredo log 和 binlog的比较 binlog 是 MySQL 的 Server 层实现的日志，所有存储引擎都可以使用；redo log 是 Innodb 存储引擎实现的日志； binlog 有 3 种格式类型，分别是 STATEMENT（默认格式，相当于记录逻辑操作）、ROW、 MIXED。（STATEMENT 有动态函数的问题） redo log 是物理日志，记录的是在某个数据页做了什么修改； binlog 是追加写，写满一个文件，就创建一个新的文件继续写，不会覆盖以前的日志，保存的是全量的日志。redo log 是循环写，日志空间大小是固定。 binlog 用于备份恢复、主从复制；redo log 用于掉电等故障恢复。 主从复制 在完成主从复制之后，可以在写数据时只写主库，在读数据时只读从库，这样即使写请求会锁表或者锁记录，也不会影响读请求的执行。 主从复制模型：同步、异步（默认）、半同步（半数复制成功即认为成功）\n刷盘时机 事务执行过程中，先把日志写到 binlog cache（Server 层的 cache），事务提交的时候，再把 binlog cache 写到 binlog 文件中。\nMySQL提供一个 sync_binlog 参数来控制数据库的 binlog 刷到磁盘上的频率：\nsync_binlog = 0 的时候，表示每次提交事务都只 write，不 fsync，后续交由操作系统决定何时将数据持久化到磁盘； sync_binlog = 1 的时候，表示每次提交事务都会 write，然后马上执行 fsync； sync_binlog =N(N\u0026gt;1) 的时候，表示每次提交事务都 write，但累积 N 个事务后才 fsync。 page cache介绍\n一个update语句的执行流程（从日志角度看） UPDATE t_user SET name = 'xiaolin' WHERE id = 1; 执行器负责具体执行，会调用存储引擎的接口，通过主键索引树搜索获取 id = 1 这一行记录：如果数据在buffer pool中，则直接返回给执行器，否则从磁盘加载数据页到pool中； 执行器得到聚簇索引记录后，会看一下更新前的记录和更新后的记录是否一样：一样的话就不用执行了，否则交给引擎层去处理； 开启事务，记录undo log，写入buffer pool的undo log页，同时记录redo log； 更新内存数据，标记为脏页，记录redo log，不直接将脏页刷盘，等待合适的时机再将脏页数据持久化； 语句执行完毕后，记录binlog，将binlog保存到binlog cache中，等待事务提交后（涉及两阶段提交）将binlog cache中的数据刷盘。 事务提交（两阶段提交为例）： prepare 阶段：将 redo log 对应的事务状态设置为 prepare，然后将 redo log 刷新到硬盘； commit 阶段：将 binlog 刷新到磁盘，接着调用引擎的提交事务接口，将 redo log 状态设置为 commit（将事务设置为 commit 状态后，刷入到磁盘 redo log 文件，更新redo log commit阶段标记）； 两阶段提交 为什么需要两阶段提交 事务提交后，redo log 和 binlog 都要持久化到磁盘，但是这两个是独立的逻辑，可能出现半成功的状态，这样就造成两份日志之间的逻辑不一致。\n过程 prepare 阶段：将 XID（内部 XA 事务的 ID） 写入到 redo log，同时将 redo log 对应的事务状态设置为 prepare，然后将 redo log 持久化到磁盘（innodb_flush_log_at_trx_commit = 1 的作用）；\ncommit 阶段：把 XID 写入到 binlog，然后将 binlog 持久化到磁盘（sync_binlog = 1 的作用），接着调用引擎的提交事务接口，将 redo log 状态设置为 commit，此时该状态并不需要持久化到磁盘，只需要 write 到文件系统的 page cache 中就够了，因为只要 binlog 写磁盘成功，就算 redo log 的状态还是 prepare 也没有关系，一样会被认为事务已经执行成功；\nTIP\n事务没提交的时候，redo log 可能会被持久化到磁盘： 事务执行中间过程的 redo log 也是直接写在 redo log buffer 中的，这些缓存在 redo log buffer 里的 redo log 也会被「后台线程」每隔一秒一起持久化到磁盘。 也就是说，事务没提交的时候，redo log 也是可能被持久化到磁盘的。但是，若binlog还没刷盘，则还是认为事务失败，日志需要回滚。\n两阶段提交的缺点 磁盘I/O压力大 使用组提交可以减少I/O次数 将 sync_binlog 设置为大于 1 的值（比较常见是 100~1000），表示每次提交事务都 write，但累积 N 个事务后才 fsync。 将 innodb_flush_log_at_trx_commit 设置为 2，由OS决定page cache的刷盘时机。 锁竞争激烈 拓展阅读：分布式事务\n","date":"2023-05-03T14:47:17+08:00","permalink":"https://hifing.github.io/p/mysql%E6%97%A5%E5%BF%97/","title":"MySQL日志"},{"content":"Golang基础 基础知识合集 unsafe Unsafe code是一种绕过go类型安全和内存安全检查的Go代码。大多数情况，unsafe code是和指针相关的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 func main() { array := [...]int{1, 2, 3, 4, 5} ptr := \u0026amp;array[0] baseAddr := uintptr(unsafe.Pointer(ptr)) for i := 0; i \u0026lt; len(array)-1; i++ { baseAddr += unsafe.Sizeof(array[0]) ptr := (*int)(unsafe.Pointer(baseAddr)) fmt.Println(*ptr) } baseAddr += (unsafe.Sizeof(array[0]) + unsafe.Sizeof(array[0]) + unsafe.Sizeof(array[0])) + unsafe.Sizeof(array[0]) ptr = (*int)(unsafe.Pointer(baseAddr)) fmt.Println(*ptr) } --- 2 3 4 5 4307106152 // a random number, 超过范围后输出了一些不可预料的值 琐碎知识点 Flag与命令行\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 package main import ( \u0026#34;flag\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;strings\u0026#34; ) var n = flag.Bool(\u0026#34;n\u0026#34;, false, \u0026#34;omit trailing newline\u0026#34;) var sep = flag.String(\u0026#34;s\u0026#34;, \u0026#34; \u0026#34;, \u0026#34;separator\u0026#34;) func main() { flag.Parse() fmt.Print(strings.Join(flag.Args(), *sep)) if !*n { fmt.Println() } } --- go build main.go ./main -n -s / a b c #这里-n在程序中为true，无需再在后面指定布尔值，sep接收了\u0026#34;/\u0026#34;，最后输出为a/b/c 可以使用下划线丢弃不要的值\n1 2 _, err = io.Copy(dst, src) // 丢弃字节数 _, ok = x.(T) // 只检测类型，忽略具体值 赋值时类型要完全匹配，nil可以赋值给任何指针或引用类型的变量\n变量类型转换\n1 2 3 4 5 6 7 8 9 10 package main import \u0026#34;fmt\u0026#34; type F float64 func main() { var a float64 = 1.0 * 1e15 fmt.Println(F(a)) //并不是调用函数 } 作用域与变量覆盖\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 package main import \u0026#34;fmt\u0026#34; func main() { b := 10 { // 在这个域中，b为字符串，外部定义的b对内部不可见 b := \u0026#34;12\u0026#34; fmt.Println(b) } fmt.Println(b) } --- output: 12 10 可能存在的问题:\n1 2 3 4 5 6 7 8 9 10 var cwd string func init() { // 全局的cwd变量依然是没有被正确初始化的，而且看似正常的日志输出更是让这个BUG更加隐晦。 cwd, err := os.Getwd() // NOTE: wrong! if err != nil { log.Fatalf(\u0026#34;os.Getwd failed: %v\u0026#34;, err) } log.Printf(\u0026#34;Working directory = %s\u0026#34;, cwd) } 符号数与无符号数计算越界\n1 2 3 4 5 var u uint8 = 255 fmt.Println(u, u+1, u*u) // \u0026#34;255 0 1\u0026#34; u*u通过计算可得 var i int8 = 127 fmt.Println(i, i+1, i*i) // \u0026#34;127 -128 1\u0026#34; u*u通过计算可得 unicode\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 package main import \u0026#34;fmt\u0026#34; func main() { str := \u0026#34;我真的会谢\u0026#34; for i := len(str) - 1; i \u0026gt;= 0; i-- { if str[i-3:i] == string(\u0026#39;会\u0026#39;) { fmt.Println(i, str[:i]) break } } fmt.Println(strings.LastIndex(str, \u0026#34;会\u0026#34;)) } ---- 12 我真的会 //一个汉字在utf-8中用3个字节编码 9 判断两个字符串是否乱序相同：（转为utf-8编码）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 //个人实现，仅供参考 package main import \u0026#34;fmt\u0026#34; func calculate(r []rune) map[rune]int { m := make(map[rune]int) for _, item := range r { m[item] = m[item] + 1 } return m } func checkSimilarity(m1, m2 map[rune]int) bool { if len(m1) != len(m2) { return false } for k, v := range m1 { if v != m2[k] { return false } } return true } func main() { a := \u0026#34;我真的会谢wozhendehuixie\u0026#34; b := \u0026#34;我wozhende真的huixie会谢\u0026#34; ua := []rune(a) ub := []rune(b) ma := calculate(ua) mb := calculate(ub) fmt.Println(checkSimilarity(ma, mb)) } 枚举\n1 2 3 4 5 6 7 8 9 const ( _ = 1 \u0026lt;\u0026lt; (10 * iota) KiB // 1024 MiB // 1048576 GiB // 1073741824 TiB // 1099511627776 (exceeds 1 \u0026lt;\u0026lt; 32) PiB // 1125899906842624 EiB // 1152921504606846976 ) error处理注意事项（摘自Go语言圣经）\n我们应该在每次函数调用后，都养成考虑错误处理的习惯，当你决定忽略某个错误时，你应该清晰地写下你的意图。\n在Go中，错误处理有一套独特的编码风格。检查某个子函数是否失败后，我们通常将处理失败的逻辑代码放在处理成功的代码之前。如果某个错误会导致函数返回，那么成功时的逻辑代码不应放在else语句块中，而应直接放在函数体中。Go中大部分函数的代码结构几乎相同，首先是一系列的初始检查，防止错误发生，之后是函数的实际逻辑。\nGo与C语言互调的方式 C中调用Go代码 在Go文件中编写好被调用的代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 //导入\u0026#34;C\u0026#34;包 import \u0026#34;C\u0026#34; import \u0026#34;fmt\u0026#34; //加export注释后才能被识别，注意斜杠和export之间没有空格！ //export PrintMsg func PrintMsg() { fmt.Println(\u0026#34;Let\u0026#39;s Go!\u0026#34;) } //export Mul func Mul(a, b int) int { return a * b } go build -o usedByC.o -buildmode=c-shared usedByC.go 执行完成后会有.h文件和.o文件。 使用导出的模块 1 2 3 4 5 6 7 8 9 10 11 12 #include \u0026lt;stdio.h\u0026gt; #include \u0026#34;usedByC.h\u0026#34; int main(int argc, char **argv) { GoInt x = 12; //头文件中的定义：typedef GoInt64 GoInt; GoInt y = 23; printf(\u0026#34;Call PrintMsg in C!\\n\u0026#34;); PrintMsg(); GoInt p = Mul(x, y); printf(\u0026#34;Call Mul in C! The value is %d\\n\u0026#34;, (int)p); return 0; } 生成二进制可执行文件并执行程序 gcc -o willUseGo willUseGo.c ./usedByC.o ./willUseGo Go中调用C代码 代码嵌套 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 package main /* // C 标志io头文件，你也可以使用里面提供的函数 #include \u0026lt;stdio.h\u0026gt; void pri(){ printf(\u0026#34;hey\\n\u0026#34;); } int add(int a,int b){ return a+b; } */ import \u0026#34;C\u0026#34; // 切勿换行再写这个 import \u0026#34;fmt\u0026#34; func main() { fmt.Println(C.add(2, 1)) C.pri() } 导入动态库（最安全、最麻烦） 直接引用（其实就是将嵌套代码挂出去了，然后在go文件中嵌套少许引用代码即可，非常简洁） 1 2 3 4 5 6 7 8 9 10 11 package util /* #include \u0026#34;util.h\u0026#34; */ import \u0026#34;C\u0026#34; func Sum(a, b int) int { s := C.sum(C.int(a), C.int(b)) return (int)(s) } 在c文件这边： 1 2 3 4 5 //.h int sum(int a,int b); //.c #include \u0026#34;util.h\u0026#34; int sum(int a, int b) { return (a + b); } 最后在main函数里： 1 2 3 4 5 6 7 8 9 10 11 12 13 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;barry.com/master/util\u0026#34; ) func main() { fmt.Println(util.Sum(4, 5)) } //输出：9 defer，panic，recover defer函数在外围函数返回之后，以后进先出(LIFO)的原则执行。\n使用defer语句时遇到的坑 函数返回的过程是这样的：先给返回值赋值，然后调用defer表达式，最后才是返回到调用函数中。（因为：return xxx语句并不是一条原子指令）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 func f() (r int) { t := 5 defer func() { t = t + 5 }() return t // 相当于 r=t; return; } // r:=t; t+=5; return r func main() { fmt.Println(f()) } // 输出：5 --- func t1() { i := 0 defer fmt.Println(i) //引用的外部参数会立刻被拷贝 i++ } // 输出：0 --- func t2() { i := 0 defer func() { //函数被延迟执行 fmt.Println(i) }() i++ } // 输出：1 panic 只会保证当前 goroutine 中的 defer 代码一定会执行，其他 goroutine 中的 defer 代码不保证能执行。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 func main() { go func() { defer fmt.Println(\u0026#34;goroutine1 invoke\u0026#34;) go func() { defer fmt.Println(\u0026#34;goroutine2 invoke\u0026#34;) go func() { defer fmt.Println(\u0026#34;goroutine3 invoke\u0026#34;) panic(\u0026#34;panic\u0026#34;) }() }() }() time.Sleep(1 * time.Second) } --- goroutine1 invoke goroutine2 invoke goroutine3 invoke panic: panic goroutine1 invoke goroutine3 invoke goroutine2 invoke panic: panic goroutine3 invoke panic: panic recover都是在当前的goroutine里进行捕获的，这就是说，对于创建goroutine的外层函数，如果goroutine内部发生panic并且内部没有用recover，外层函数是无法用recover来捕获的，这样会造成程序崩溃。（其他 goroutine 中的 defer 代码不保证能执行）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 func main() { defer func() { // 直接崩溃不执行 fmt.Println(\u0026#34;trying to stop main\u0026#34;) if c := recover(); c != nil { fmt.Println(\u0026#34;panic caught\u0026#34;) } }() go func() { defer func() { fmt.Println(\u0026#34;inner stopped\u0026#34;) }() panic(\u0026#34;OK?\u0026#34;) }() time.Sleep(1 * time.Second) fmt.Println(\u0026#34;OK, main stopped safely\u0026#34;) } --- inner stopped panic: OK? goroutine 4 [running]: main.main.func2() xxx/main.go:20 +0x48 created by main.main xxx/main.go:16 +0x40 exit status 2 recover返回的是interface{}类型而不是go中的 error 类型，如果外层函数需要调用err.Error()，会编译错误，也可能会在执行时panic。\n1 2 3 4 5 6 7 8 9 10 11 12 func main() { defer func() { if err := recover(); err != nil { fmt.Println(\u0026#34;捕获异常:\u0026#34;, err.(error)) } }() panic(\u0026#34;a\u0026#34;) } --- panic: a [recovered] panic: interface conversion: string is not error: missing method Error 复合结构 数组 如果一个数组的元素类型是可以相互比较的，那么数组类型也是可以相互比较的，这时候我们可以直接通过==比较运算符来比较两个数组，只有当两个数组的所有元素都是相等的时候数组才是相等的。 1 2 3 4 5 6 a := [2]int{1, 2} b := [...]int{1, 2} c := [2]int{1, 3} fmt.Println(a == b, a == c, b == c) // \u0026#34;true false false\u0026#34; d := [3]int{1, 2} fmt.Println(a == d) // compile error: cannot compare [2]int == [3]int 数组可以这样定义：\n1 months := [...]string{1: \u0026#34;January\u0026#34;, /* ... */, 12: \u0026#34;December\u0026#34;} 切片 Go方法传参为值传参，关于slice、map、chan的传参效果同引用传参相同的问题，主要是因为slice为一个struct，里面包含了一个底层数组的指针、len、cap，当传参为slice时，拷贝整个struct，其中，指针所指的底层数组不变，因此，在接受传参的方法中修改slice的底层数组会影响到外部slice的底层数组；map和chan的原理类似，都是指针类型，因此传参传的是地址。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 func main() { // array := []int{7, 8, 9} array := make([]int, 3, 4) array[0] = 7 array[1] = 8 array[2] = 9 fmt.Printf(\u0026#34;main ap brfore: len: %d cap:%d data:%+v\\n\u0026#34;, len(array), cap(array), array) ap(array) fmt.Printf(\u0026#34;main ap after: len: %d cap:%d data:%+v\\n\u0026#34;, len(array), cap(array), array) array = array[0:4] fmt.Printf(\u0026#34;main ap after: len: %d cap:%d data:%+v\\n\u0026#34;, len(array), cap(array), array) } func ap(array []int) { fmt.Printf(\u0026#34;ap brfore: len: %d cap:%d data:%+v\\n\u0026#34;, len(array), cap(array), array) array = append(array, 10) array[0] = 1 fmt.Printf(\u0026#34;ap after: len: %d cap:%d data:%+v\\n\u0026#34;, len(array), cap(array), array) } --- main ap brfore: len: 3 cap:4 data:[7 8 9] ap brfore: len: 3 cap:4 data:[7 8 9] ap after: len: 4 cap:4 data:[1 8 9 10] main ap after: len: 3 cap:4 data:[1 8 9] main ap after: len: 4 cap:4 data:[1 8 9 10] java - go语言参数传递到底是传值还是传引用？ - 个人文章 - SegmentFault 思否\n结构体\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 // 匿名嵌入demo type Person struct { HairType // 由于定义了一个匿名成员，因此修改属性时，可以直接获取该成员的成员 age int } type HairType struct { color string } func main() { p := Person{age: 18} p.color = \u0026#34;red\u0026#34; //直接获取 fmt.Println(p) } // 这种情况编译会不通过：p := Person{age: 18, color: \u0026#34;red\u0026#34;} -------------------- package main import \u0026#34;fmt\u0026#34; type Person struct { HairType string age int } type HairType struct { color string } func main() { p := Person{age: 18} p.color = \u0026#34;red\u0026#34; p.string = \u0026#34;redd\u0026#34; p.HairType.color = \u0026#34;reddd\u0026#34; fmt.Println(p) } // output: {{reddd} redd 18} json\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 type Person struct { HairType Age int `json:\u0026#34;age\u0026#34;` privatestuff string // 若为私有，则属性不参与json序列化 } type HairType struct { Color string } type People struct { FaceType Age int } type FaceType struct { Damn int `json:\u0026#34;age\u0026#34;` // 解码时优先根据tag匹配 } func main() { p := Person{Age: 18} p.Color = \u0026#34;red\u0026#34; data, _ := json.MarshalIndent(p, \u0026#34;\u0026#34;, \u0026#34;\\t\u0026#34;) fmt.Println(string(data)) pp := new(People) if err := json.Unmarshal(data, pp); err != nil { log.Fatalln(\u0026#34;JSON Unmarshal failed\u0026#34;) } fmt.Println(pp) } /* output: { \u0026#34;Color\u0026#34;: \u0026#34;red\u0026#34;, \u0026#34;age\u0026#34;: 18 } \u0026amp;{{18} 0} */ template 使用模板渲染结果，参考教程链接\n函数 函数类型的零值是nil。调用值为nil的函数值会引起panic错误： 1 2 var f func(int) int f(3) // 此处f的值为nil, 会引起panic错误 函数值可以与nil比较： 1 2 3 4 var f func(int) int if f != nil { f(3) } 捕获迭代变量（常见陷阱！！！） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 var rmdirs []func() for _, d := range tempDirs() { dir := d // NOTE: necessary! os.MkdirAll(dir, 0755) // creates parent directories too // 若操作不是立即同步执行的，需要拷贝一份数据，这也是为什么要创建dir这个局部变量的原因 rmdirs = append(rmdirs, func() { os.RemoveAll(dir) }) } // ...do some work… for _, rmdir := range rmdirs { rmdir() // clean up } Defer注意事项与技巧 程序执行顺序 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 func bigSlowOperation() { defer trace(\u0026#34;bigSlowOperation\u0026#34;)() // don\u0026#39;t forget the extra parentheses // ...lots of work… time.Sleep(10 * time.Second) // simulate slow operation by sleeping } func trace(msg string) func() { start := time.Now() log.Printf(\u0026#34;enter %s\u0026#34;, msg) return func() { log.Printf(\u0026#34;exit %s (%s)\u0026#34;, msg,time.Since(start)) } } func main() { bigSlowOperation() } ------ // 先初始化trace对应的返回函数，再执行原程序主体代码，最后执行trace的返回函数 2023/06/11 14:06:14 enter bigSlowOperation 2023/06/11 14:06:24 exit bigSlowOperation (10.001373916s) defer还可以用于观察函数的返回值 1 2 3 4 5 6 7 func square(f float64) (res float64) { defer func() { fmt.Printf(\u0026#34;square(%f) = %f\\n\u0026#34;, f, res) }() res = f * f return } 如果defer相关的逻辑在循环体中，且想要及时执行而不是等整个函数返回后执行，可以考虑将循环部分抽取出来作为一个函数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 func main(){ for _, filename := range filenames { // 关闭file的时机就在doFile结束后，而不是等到main函数返回 if err := doFile(filename); err != nil { return err } } } func doFile(filename string) error { f, err := os.Open(filename) if err != nil { return err } defer f.Close() // doFile结束即关闭file } OOP 方法 在Go语言里，我们可以方便地为一些简单的数值、字符串、slice、map来定义一些附加行为。我们可以给同一个包内的任意命名类型定义方法，只要这个命名类型不是指针或interface。 基于指针对象的方法 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 type Person struct { } func (p *Person) PtrFunc() { fmt.Println(\u0026#34;PtrFunc called\u0026#34;) } func (p Person) Func() { fmt.Println(\u0026#34;Func called\u0026#34;) } func main() { p := Person{} ptr := \u0026amp;p p.Func() ptr.Func() p.PtrFunc() ptr.PtrFunc() } ------ Func called Func called PtrFunc called PtrFunc called 不管method的receiver是指针类型还是非指针类型，都是可以通过指针/非指针类型进行调用的，编译器会帮你做类型转换。 如果receiver声明为非指针变量时，调用会产生一次拷贝；如果用指针类型作为receiver，那么这种指针类型指向的始终是一块内存地址。 Nil也是一个合法的接收器类型（可能会成为一个坑） Go圣经传送门 结构体对内嵌结构体调用方法的优化 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 type Point struct{ X, Y float64 } // Point有Distance这个方法 type ColoredPoint struct { Point Color color.RGBA } var p = ColoredPoint{Point{1, 1}, red} var q = ColoredPoint{Point{5, 4}, blue} fmt.Println(p.Distance(q.Point)) // \u0026#34;5\u0026#34; /* 相当于： func (p ColoredPoint) Distance(q Point) float64 { return p.Point.Distance(q) } func (p *ColoredPoint) ScaleBy(factor float64) { p.Point.ScaleBy(factor) } 这样是不行的： p.Distance(q) // compile error: cannot use q (ColoredPoint) as Point */ 一个小trick，使代码更简洁： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 var cache = struct { sync.Mutex //Lock和Unlock方法被引入到了这个匿名结构中 mapping map[string]string }{ mapping: make(map[string]string), } func Lookup(key string) string { cache.Lock() // 使用了Mutex的方法 v := cache.mapping[key] cache.Unlock() return v } 方法转为函数方式调用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 type Point struct{ X, Y float64 } func (p Point) Add(q Point) Point { return Point{p.X + q.X, p.Y + q.Y} } func (p Point) Sub(q Point) Point { return Point{p.X - q.X, p.Y - q.Y} } type Path []Point func (path Path) TranslateBy(offset Point, add bool) { var op func(p, q Point) Point if add { op = Point.Add } else { op = Point.Sub } for i := range path { // Call either path[i].Add(offset) or path[i].Sub(offset). path[i] = op(path[i], offset) } } 接口 接口可以通过组合已有的接口来实现其定义 1 2 3 4 5 6 7 8 9 type Mammal interface { Yell() Shout() } type People interface { Mammal Speak() } 接口值可以使用==和!＝来进行比较。两个接口值相等仅当它们都是nil值，或者它们的动态类型相同并且动态值也根据这个动态类型的==操作相等。因为接口值是可比较的，所以它们可以用在map的键或者作为switch语句的操作数。 1 2 3 4 5 6 7 8 9 10 type Person struct { name string } func main() { var a interface{} = Person{\u0026#34;A\u0026#34;} var b interface{} = Person{\u0026#34;A\u0026#34;} fmt.Println(a == b) // true // == 在这里比较的是值，注意和java区别 } 值得注意的点： 如果两个接口值的动态类型相同，但是这个动态类型是不可比较的（比如切片），将它们进行比较就会失败并且panic 1 2 var x interface{} = []int{1, 2, 3} fmt.Println(x == x) // panic: comparing uncomparable type []int ==更加值得注意的点：== 一个接口为nil的充要条件为接口的运行时类型为nil，并且接口的运行时值为nil。 1 2 3 4 5 6 7 8 9 func main() { var w io.Writer var f *os.File fmt.Println(w == nil) // true w = f // type of this interface is \u0026#34;*os.File\u0026#34; fmt.Println(f == nil) // true fmt.Println(w == nil) // false fmt.Printf(\u0026#34;%T,%T\u0026#34;, w, f) } fmt包内部，使用反射来获取接口动态类型的名称 1 2 3 4 5 6 var w io.Writer fmt.Printf(\u0026#34;%T\\n\u0026#34;, w) // \u0026#34;\u0026lt;nil\u0026gt;\u0026#34; w = os.Stdout fmt.Printf(\u0026#34;%T\\n\u0026#34;, w) // \u0026#34;*os.File\u0026#34; w = new(bytes.Buffer) fmt.Printf(\u0026#34;%T\\n\u0026#34;, w) // \u0026#34;*bytes.Buffer\u0026#34; 并发 反射 Leetcode刷题相关 golang堆实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 //小顶堆Demo import ( \u0026#34;container/heap\u0026#34; \u0026#34;fmt\u0026#34; ) type ListNode struct { Val int Next *ListNode } type NodeHeap []*ListNode func (nh NodeHeap) Less(i, j int) bool { return nh[i].Val \u0026lt; nh[j].Val } //大顶堆就改成大于号 func (nh NodeHeap) Swap(i, j int) { nh[i], nh[j] = nh[j], nh[i] } func (nh NodeHeap) Len() int { return len(nh) } func (nh *NodeHeap) Push(x interface{}) { *nh = append(*nh, x.(*ListNode)) } //注意Pop的写法！！！ func (nh *NodeHeap) Pop() interface{} { old := *nh res := old[len(old)-1] //取出lastOne，但是对于切片来说是去除头一个，即堆顶元素 *nh = old[:len(old)-1] return res } func mergeKLists(lists []*ListNode) *ListNode { h := NodeHeap{} heap.Init(\u0026amp;h) for i := 0; i \u0026lt; len(lists); i++ { head := lists[i] for head != nil { heap.Push(\u0026amp;h, head) head = head.Next } } blank := new(ListNode) follower := blank for i := 0; i \u0026lt; len(h); i++ { fmt.Print(h[i].Val, \u0026#34; \u0026#34;) } for len(h) \u0026gt; 0 { follower.Next = heap.Pop(\u0026amp;h).(*ListNode) follower = follower.Next } follower.Next = nil return blank.Next } ","date":"2023-04-29T17:59:47+08:00","permalink":"https://hifing.github.io/p/golang%E5%9F%BA%E7%A1%80/","title":"Golang基础"},{"content":"MySQL事务与锁 事务 事务特性与隔离级别 ACID 原子性（Atomicity）：一个事务中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。（undo log保证） 一致性（Consistency）：事务操作前和操作后，数据满足完整性约束，数据库保持一致性状态。（通过A、I、D保证） 隔离性（Isolation）：多个事务同时使用相同的数据时，不会相互干扰，每个事务都有一个完整的数据空间，对其他并发事务是隔离的。（MVCC或锁保证） 持久性（Durability）：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。（通过redo log保证） 隔离级别 并行事务处理时会发生的现象：脏读、不可重复读、幻读\n脏读：事务A读到了事务B未提交的数据。 不可重复读：在一个事务内多次读取同一个数据，如果出现前后两次读到的数据不一样的情况，就意味着发生了不可重复读现象。 幻读：在一个事务内多次查询某个符合查询条件的记录数量，如果出现前后两次查询到的记录数量不一样的情况，就意味着发生了幻读现象。 四个隔离级别\n读未提交（read uncommitted），指一个事务还没提交时，它做的变更就能被其他事务看到；（会出现脏读、不可重复读、幻读） 读提交（read committed），指一个事务提交之后，它做的变更才能被其他事务看到；（会出现不可重复读、幻读） 可重复读（repeatable read），指一个事务执行过程中看到的数据，一直跟这个事务启动时看到的数据是一致的，MySQL InnoDB 引擎的默认隔离级别；（会出现幻读） 串行化（serializable ）；会对记录加上读写锁，在多个事务对这条记录进行读写操作时，如果发生了读写冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行； TIP\n对于「读提交」和「可重复读」隔离级别的事务来说，它们是通过 Read View 来实现的，它们的区别在于创建 Read View 的时机不同。「读提交」隔离级别是在「每个语句执行前」都会重新生成一个 Read View，而「可重复读」隔离级别是「启动事务时」生成一个 Read View，然后整个事务期间都在用这个 Read View。\nMySQL的可重复读隔离级别对幻读的处理（不能完全避免）\n针对快照读（普通 select 语句）：通过 MVCC 方式解决了幻读； 针对当前读（select \u0026hellip; for update 等语句）：通过 next-key lock（记录锁+间隙锁）方式解决了幻读。 TIP\n什么情况下还是会出现幻读？ case 1: case 2:\nT1 时刻：事务 A 先执行「快照读语句」：select * from t_test where id \u0026gt; 100 得到了 3 条记录。 T2 时刻：事务 B 往插入一个 id= 200 的记录并提交； T3 时刻：事务 A 再执行「当前读语句」 select * from t_test where id \u0026gt; 100 for update 就会得到 4 条记录，此时也发生了幻读现象。 要避免这类特殊场景下发生幻读的现象的话，就是尽量在开启事务之后，马上执行 select \u0026hellip; for update 这类当前读的语句，因为它会对记录加 next-key lock，从而避免其他事务插入一条新记录。 ReadView和MVCC ReadView结构：\nTIP\n一个事务去访问记录的时候，除了自己的更新记录总是可见之外，还有这几种情况：\n如果记录的 trx_id 值小于 Read View 中的 min_trx_id 值，表示这个版本的记录是在创建 Read View 前已经提交的事务生成的，所以该版本的记录对当前事务可见。 如果记录的 trx_id 值大于等于 Read View 中的 max_trx_id 值，表示这个版本的记录是在创建 Read View 后才启动的事务生成的，所以该版本的记录对当前事务不可见。 如果记录的 trx_id 值在 Read View 的 min_trx_id 和 max_trx_id 之间，需要判断 trx_id 是否在 m_ids 列表中： 如果记录的 trx_id 在 m_ids 列表中，表示生成该版本记录的活跃事务依然活跃着（还没提交事务），所以该版本的记录对当前事务不可见。 如果记录的 trx_id 不在 m_ids列表中，表示生成该版本记录的活跃事务已经被提交，所以该版本的记录对当前事务可见。 聚簇索引隐藏列：\nroll_ptr指向下一条undo log，下一条undo log也是这样的结构，这样，就构成了一条版本链。\n锁 MySQL有哪些锁 全局锁 表级锁 表锁 元数据锁：MDL 是为了保证当用户对表执行 CRUD 操作时，防止其他线程对这个表结构做了变更。MDL 是在事务提交后才会释放，这意味着事务执行期间，MDL 是一直持有的，这主要是考虑到长事务中对数据表的结构修改会影响其他事务的执行。（读读兼容、读写互斥、写写互斥） 意向锁：对表内某些记录加行级读写锁之前会先申请表级意向锁。意向锁的目的是为了快速判断表里是否有记录被加锁。 意向共享锁和意向独占锁是表级锁，不会和行级的共享锁和独占锁发生冲突，而且意向锁之间也不会发生冲突，只会和表读锁和表写锁发生冲突。 AUTO-INC锁：表里的主键通常都会设置成自增的，这是通过对主键字段声明 AUTO_INCREMENT 属性实现的。AUTO-INC 锁是特殊的表锁机制，锁不是再一个事务提交后才释放，而是再执行完插入语句后就会立即释放。 行级锁 InnoDB 引擎是支持行级锁的，而 MyISAM 引擎并不支持行级锁。 Record Lock Gap Lock Nexy-Key Lock：Record Lock + Gap Lock 的组合，锁定一个范围，并且锁定记录本身。 插入意向锁（注意和表级锁中的意向锁进行区分）：它是一种特殊的间隙锁，属于行级别锁。两个事务却不能在同一时间内，一个拥有间隙锁，另一个拥有该间隙区间内的插入意向锁。 MySQL是怎么加锁的 几个案例\n注意非唯一索引加锁情况。\nselect * from user where age \u0026gt;= 22 for update; TIP\nMySQL 行级锁的加锁规则：\n唯一索引等值查询： 当查询的记录是「存在」的，在索引树上定位到这一条记录后，将该记录的索引中的 next-key lock 会退化成「记录锁」。 当查询的记录是「不存在」的，在索引树找到第一条大于该查询记录的记录后，将该记录的索引中的 next-key lock 会退化成「间隙锁」。 非唯一索引等值查询： 当查询的记录「存在」时，由于不是唯一索引，所以肯定存在索引值相同的记录，于是非唯一索引等值查询的过程是一个扫描的过程，直到扫描到第一个不符合条件的二级索引记录就停止扫描，然后在扫描的过程中，对扫描到的二级索引记录加的是 next-key 锁，而对于第一个不符合条件的二级索引记录，该二级索引的 next-key 锁会退化成间隙锁。同时，在符合查询条件的记录的主键索引上加记录锁。 当查询的记录「不存在」时，扫描到第一条不符合条件的二级索引记录，该二级索引的 next-key 锁会退化成间隙锁。因为不存在满足查询条件的记录，所以不会对主键索引加锁。 MySQL死锁了怎么办 原因 间隙锁的意义只在于阻止区间被插入，因此是可以共存的。一个事务获取的间隙锁不会阻止另一个事务获取同一个间隙范围的间隙锁。 这里的共同间隙包括两种场景：\n其一是两个间隙锁的间隙区间完全一样； 其二是一个间隙锁包含的间隙区间是另一个间隙锁包含间隙区间的子集。 但是有一点要注意，next-key lock 是包含间隙锁+记录锁的，如果一个事务获取了 X 型的 next-key lock，那么另外一个事务在获取相同范围的 X 型的 next-key lock 时，是会被阻塞的，即记录锁要考虑 X 型与 S 型关系。\n死锁案例\n插入意向锁与间隙锁是冲突的，所以当其它事务持有该间隙的间隙锁时，需要等待其它事务释放间隙锁之后，才能获取到插入意向锁。间隙锁与间隙锁之间是兼容的。\n插入意向锁只在并发插入时会用到。\n死锁避免 死锁的四个必要条件：互斥、占有且等待、不可强占用、循环等待。只要系统发生死锁，这些条件必然成立，但是只要破坏任意一个条件就死锁就不会成立。 因此可以：\n设置事务超时时间 开启主动死锁检测 ","date":"2023-04-21T14:47:17+08:00","permalink":"https://hifing.github.io/p/mysql%E4%BA%8B%E5%8A%A1%E4%B8%8E%E9%94%81/","title":"MySQL事务与锁"},{"content":"MySQL结构 MySQL的一个设计思想：如果内存够用，就要多利用内存，尽量减少磁盘访问。\n一条select语句的执行流程 连接器负责与客户端进行TCP三次握手，校验用户名密码，读取用户身份与操作权限。\n此处的查询缓存是在Server层执行的，并不是存储引擎中的buffer pool。当数据表频繁更新，或者查询的数据非常庞大时，缓存命中率可能不会很高，考虑到Server层的缓存实用性不大，因此，从MySQL 8.0 开始，执行一条 SQL 查询语句，不会再在Server层中执行查询缓存的步骤了。\n在执行SQL语句前，先由解析器对SQL语句进行解析，该步骤分为词法分析和语法分析。其中，在词法分析时，MySQL根据SQL关键词构建SQL语法树；语法分析时，解析器会根据语法规则，判断输入的 SQL 语句是否满足 MySQL 语法，比如，把from写成form。\n在执行SQL语句时，会分为以下三个阶段：\n预处理：检查SQL中的表或者字段是否存在，将*扩展为表上所有的列。\n优化：优化器负责将SQL查询语句的执行方案确定下来。\n执行：（以select * from product where id = 1;为例）\n优化的访问类型为const（常量查询，此外还有all、range等），首次查询调用read_first_record函数指针指向的函数，让存储引擎读取符合条件的第一条记录；\n通过主键索引的B+树定位第一条记录；\n执行器（Server层）判断记录是否符合查询条件；\n查询过程为while循环，调用read_record函数指针指向的函数，因为是const访问类型，该指针指向-1，查询结束。\n索引下推对执行阶段的优化 使用索引下推（MySQL 5.6 以后）能减少二级索引在查询时的回表操作，提高效率，它将Server层部分负责的任务交给引擎层去处理。\n以select * from t_user where age \u0026gt; 20 and reward = 100000;为例（已建立age和reward的联合索引）：\n联合索引遇到范围查找会停止匹配，此SQL仅age能使用联合索引，当开启索引下推时，根据二级索引查询获取到的一条记录，引擎层直接判断reward是否符合条件，若不符合，则直接舍弃。（若不开启，则需要先进行回表操作，把完整数据反馈至Server层，由Server层判断）\nInnoDB和MyISAM的不同 MyISAM 只有表级锁，而 InnoDB 支持行级锁和表级锁，默认为行级锁。\nMyISAM 不提供事务支持。InnoDB 提供事务支持，实现了 SQL 标准定义了四个隔离级别，具有提交和回滚事务的能力。并且，InnoDB 默认使用的可重读隔离级别是可以解决幻读问题发生的（基于 MVCC 和 Next-Key Lock）。\nMyISAM 不支持外键，而 InnoDB 支持。\n使用 InnoDB 的数据库在异常崩溃后，数据库重新启动的时候会保证数据库恢复到崩溃前的状态。这个恢复的过程依赖于 redo log 。MyISAM不支持。\n虽然 MyISAM 引擎和 InnoDB 引擎都是使用 B+Tree 作为索引结构，但是两者的实现方式不太一样。\nInnoDB 引擎中，其数据文件本身就是索引文件。相比 MyISAM，索引文件和数据文件是分离的，其表数据文件本身就是按 B+Tree 组织的一个索引结构，树的叶节点 data 域保存了完整的数据记录。\n","date":"2023-04-21T14:47:17+08:00","permalink":"https://hifing.github.io/p/mysql%E5%9F%BA%E7%A1%80/","title":"MySQL基础"},{"content":"MySQL索引 概念 几种数据结构对比：平衡二叉树、B树、B+树、B*树介绍 与 演示链接\n回表：查询二级索引时将会得到主键值，根据主键值查询主键索引才能得到整行数据，这个过程叫做回表，即需要查询这两个B+树才能得到数据本身。\n覆盖查找：如SQL语句select id from product where product_no = '0002';，在二级索引中即可得到主键值，因此直接返回主键ID即可而无需查询主键索引，这个过程叫覆盖查找。\n索引下推：MySQL 5.6 引入的索引下推优化，可以在联合索引遍历过程中，对联合索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数，该优化过程在引擎层进行。\n联合索引：联合索引树形结构如下（该图建立了\u0026lt;id,name\u0026gt;的二级联合索引，叶子结点为双向链表）： 并不是查询过程使用了联合索引查询，就代表联合索引中的所有字段都用到了联合索引进行索引查询，比如字段需要范围查找时，则该范围查找字段后的字段无法使用联合索引，因为在这个范围中，后面的字段是无序的。\nTIP\n但是select * from t_table where a \u0026gt;= 1 and b = 2;这个语句查询过程中，虽然在符合a \u0026gt;= 1条件的二级索引记录的范围里，b字段的值是无序的，但是对于符合a = 1的二级索引记录的范围里，b字段的值是有序的。 于是，在确定需要扫描的二级索引的范围时，当二级索引记录的a字段值为1时，可以通过b = 2条件减少需要扫描的二级索引记录范围（b字段可以利用联合索引进行索引查询的意思）。 也就是说，从符合a = 1 and b = 2条件的第一条记录开始扫描，而不需要从第一个a字段值为1的记录开始扫描。\nMySQL的B+树 为什么选择B+树？ B+Tree 是一种多叉树，叶子节点才存放数据，非叶子节点只存放索引，而且每个节点里的数据是按主键顺序存放的，索引叶子结点结构为一条双向链表。 数据库的索引和数据都是存储在硬盘的。B+Tree 只在叶子节点存储数据，而 B 树 的非叶子节点也要存储数据，所以 B+Tree 的单个节点的数据量更小，在相同的磁盘 I/O 次数下，就能查询更多的节点。另外，B+Tree 叶子节点采用的是双向链表连接，适合 MySQL 中常见的基于范围的顺序查找，而 B 树无法做到这一点。 在实际应用中，B+树的度大于100，保证千万量级数据下B+树的高度为3-4，减少磁盘I/O次数。 Hash在等值查询时非常高效，但是Hash表不适合做范围查询。 MySQL B+树数据页 数据页中的记录按照主键顺序组成单向链表，数据页中有一个页目录，起到记录的索引作用： 通过槽查找记录时，可以使用二分法快速定位要查询的记录在哪个槽（哪个记录分组），定位到槽后，再遍历槽内的所有记录，找到对应的记录。 索引失效与索引优化 索引失效 联合索引失效：如前文所示，使用联合索引时，存在最左匹配原则，即若不设定id的查询条件直接根据name的条件查询，则该联合索引失效。值得注意的是，由于优化器对SQL语句的优化措施，打乱where中的顺序不影响查询方案的确定。 左或者左右模糊匹配：like %xx 或者 like %xx%。 对索引列做了计算、函数、类型转换操作。 在 WHERE 子句中，如果在 OR 前的条件列是索引列，而在 OR 后的条件列不是索引列，那么索引会失效。 TIP\n索引效率排行（低到高）：\nAll（全表扫描）； index（全索引扫描）； range（索引范围扫描）； ref（非唯一索引扫描）； eq_ref（唯一索引扫描）； const（结果只有一条的主键或唯一索引扫描）。 索引优化 前缀优化：使用某个字段中字符串的前几个字符建立索引，既减小索引字段大小，又有效提高索引的查询速度。 覆盖索引优化：当不需要查询出所有字段时，可以建立一个联合索引，即「商品ID、名称、价格」作为一个联合索引。使用覆盖索引的好处就是，不需要查询出包含整行记录的所有信息，也就减少了大量的 I/O 操作。 主键自增：主键自增时新增记录是追加操作，能避免页分裂的情况。页分裂会造成大量的存储碎片，导致查询效率不高。 NOT NULL：索引列存在 NULL 就会导致优化器在做索引选择的时候更加复杂，更加难以优化。NULL 值是一个没意义的值，但是它会占用物理空间，所以会带来的存储空间的问题。 避免索引失效 什么时候用索引 使用索引的场景：字段唯一性、经常where、group by、order by\n不需要使用索引的场景：字段存在大量重复数据（比如性别）、经常更新的字段\n拓展 MyISAM 和 InnoDB 中 B+ 树的差异：\nMyISAM 引擎中，B+Tree 叶节点的 data 域存放的是数据记录的地址。在索引检索的时候，首先按照 B+Tree 搜索算法搜索索引，如果指定的 Key 存在，则取出其 data 域的值，然后以 data 域的值为地址读取相应的数据记录。这被称为“非聚簇索引”。 InnoDB 引擎中，其数据文件本身就是索引文件。相比 MyISAM，索引文件和数据文件是分离的，其表数据文件本身就是按 B+Tree 组织的一个索引结构，树的叶节点 data 域保存了完整的数据记录。这个索引的 key 是数据表的主键，因此 InnoDB 表数据文件本身就是主索引。这被称为“聚簇索引（或聚集索引）”，而其余的索引都作为辅助索引，辅助索引的 data 域存储相应记录主键的值而不是地址，这也是和 MyISAM 不同的地方。在根据主索引搜索时，直接找到 key 所在的节点即可取出数据；在根据辅助索引查找时，则需要先取出主键的值，再走一遍主索引。 因此，在设计表的时候，不建议使用过长的字段作为主键，也不建议使用非单调的字段作为主键，这样会造成主索引频繁分裂。\nMySQL 在遇到字符串和数字比较的时候，会自动把字符串转为数字，然后再进行比较。\n脑筋急转弯：使用左模糊匹配（like \u0026ldquo;%xx\u0026rdquo;）并不一定会走全表扫描，关键还是看数据表中的字段。如果数据库表中的字段只有主键+二级索引，那么即使使用了左模糊匹配，也不会走全表扫描（type=all），而是走全扫描二级索引树(type=index)。\ncount性能对比： count()是一个聚合函数，函数的参数不仅可以是字段名，也可以是其他任意表达式，该函数作用是统计符合查询条件的记录中，函数指定的参数不为 NULL的记录有多少个。\ncount(*)=count(1)\u0026gt;count(主键字段)\u0026gt;count(字段)\nMySQL 会对 count(*) 和 count(1) 有个优化，如果有多个二级索引的时候，优化器会使用key_len最小的二级索引进行扫描。\n大表count()操作时费时间：\n使用近似值（如explain命令） 新建额外表保存计数信息 ","date":"2023-04-21T14:47:17+08:00","permalink":"https://hifing.github.io/p/mysql%E7%B4%A2%E5%BC%95/","title":"MySQL索引"},{"content":"计数 投票 多数元素 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 class Solution { public int majorityElement(int[] nums) { int now = nums[0]; int count = 1; for (int i = 1; i \u0026lt; nums.length; i++) { if (nums[i] == now) count++; else { if (count \u0026gt; 0) count--; else { count = 1; now = nums[i]; } } } return now; } } 使用摩尔投票法将复杂度将为O（n），也可以用分治的思想，左右选出的候选人再在整个区间内进行比较，数目多的取胜，复杂度为O（nlogn）。\n","date":"2022-08-19T01:04:20+08:00","permalink":"https://hifing.github.io/p/%E8%AE%A1%E6%95%B0/","title":"计数"},{"content":"","date":"2022-08-18T22:48:50+08:00","permalink":"https://hifing.github.io/p/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/","title":"分布式文件系统"},{"content":"哈希 HashSet 最长连续序列 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 class Solution { public int longestConsecutive(int[] nums) { Set\u0026lt;Integer\u0026gt; set = new HashSet\u0026lt;\u0026gt;(); for (int ele : nums) set.add(ele); int res = 0; for (int ele : nums) { if (!set.contains(ele - 1)) { int count = 1; int tmp = ele + 1; while (set.contains(tmp)) { count++; tmp++; } res = Math.max(res, count); } } return res; } } 将元素都收到Set中，从连续序列的最小元素开始搜索到最大处，如果还有连续的更小的，则放弃此次循环\nHashMap 和为 K 的子数组 将前缀记录在map里头，往后边扫描边查缺的数字。\n","date":"2022-08-18T00:21:42+08:00","permalink":"https://hifing.github.io/p/%E5%93%88%E5%B8%8C/","title":"哈希"},{"content":"贪心 相关题目：下一个排列 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 class Solution { public void reverse(int[] nums, int l, int r) { int tmp; while (l \u0026lt; r) { tmp = nums[l]; nums[l] = nums[r]; nums[r] = tmp; l++; r--; } } public void nextPermutation(int[] nums) { int i = nums.length - 1; for (; i \u0026gt; 0; i--) { if (nums[i] \u0026gt; nums[i - 1]) break; } if (i == 0) reverse(nums, 0, nums.length - 1); else { for (int j = nums.length - 1; j \u0026gt; i - 1; j--) { if (nums[j] \u0026gt; nums[i - 1]) { int tmp = nums[j]; nums[j] = nums[i - 1]; nums[i - 1] = tmp; reverse(nums, i, nums.length - 1); return; } } } } } 从尾到头找到一个极大值点，在极值点右侧这个递减序列中从右往左找到极值点左侧元素的位置，使得左侧元素刚好比这个位置的元素大，替换后，翻转右侧序列。\n","date":"2022-08-17T22:13:57+08:00","permalink":"https://hifing.github.io/p/%E8%B4%AA%E5%BF%83/","title":"贪心"},{"content":"SpringCloud Gateway SpringCloud Gateway 使用的Webflux中的reactor-netty响应式编程组件，底层使用了Netty通讯框架。\nGateway的使用：SpringCloud gateway\nZuul的IO模型 Springcloud中所集成的Zuul版本，采用的是Tomcat容器，使用的是传统的Servlet IO处理模型，会为每个请求分配一个线程来处理，无法应付高并发场景下的需求，所以Springcloud Zuul 是基于servlet之上的一个阻塞式处理模型。\nWebflux 服务器 Reactive Stream 是一套反应式编程 标准 和 规范；它由发布者、订阅者、订阅、处理器组成。 Reactor 是基于 Reactive Streams 一套 反应式编程框架；Mono实现了发布者功能，返回0-1个元素，Flux返回N个元素。 WebFlux 以 Reactor 为基础，实现 Web 领域的 反应式编程框架。在 WebFlux 接口中，请求不会被阻塞，所以服务端的接口耗时为 0。 注册中心 服务注册中心本质上是为了解耦服务提供者和服务消费者。对于任何一个微服务，原则上都应存在或者支持多个提供者，这是由微服务的分布式属性决定的。更进一步，为了支持弹性扩缩容特性，一个微服务的提供者的数量和分布往往是动态变化的，也是无法预先确定的。因此，原本在单体应用阶段常用的静态LB机制就不再适用了，需要引入额外的组件来管理微服务提供者的注册与发现，而这个组件就是服务注册中心。\n需要考虑的问题：\n测活：服务注册之后，如何对服务进行测活以保证服务的可用性？ 负载均衡：当存在多个服务提供者时，如何均衡各个提供者的负载？ 集成：在服务提供端或者调用端，如何集成注册中心？ 运行时依赖：引入注册中心之后，对应用的运行时环境有何影响？ 可用性：如何保证注册中心本身的可用性，特别是消除单点故障？ CAP理论 一致性(Consistency) (所有节点在同一时间具有相同的数据) 可用性(Availability) (保证每个请求不管成功或者失败都有响应) 分隔容忍(Partition tolerance) (系统中任意信息的丢失或失败不会影响系统的继续运作) Nacos Nacos内部接收到注册的请求时，不会立即写数据，而是将服务注册的任务放入一个阻塞队列就立即响应给客户端。然后利用线程池读取阻塞队列中的任务，异步来完成实例更新，从而提高并发写能力。 Nacos在更新实例列表时，会采用CopyOnWrite技术，首先将旧的实例列表拷贝一份，然后更新拷贝的实例列表，再用更新后的实例列表来覆盖旧的实例列表。 通过Ribbon实现负载均衡。（随机、轮询、加权、少并发连接优先、重试、区域敏感、可用性敏感） vs Eureka： Nacos的实例有永久和临时实例之分；而Eureka只支持临时实例 Nacos对临时实例采用心跳模式检测，对永久实例采用主动请求来检测；Eureka只支持心跳模式 Nacos支持定时拉取和订阅推送两种模式；Eureka只支持定时拉取模式 配置中心： 一般会存：可能会经常变化的配置信息，例如连接池，日志，线程池，限流熔断规则 我们的服务一般会先从内存中读取配置信息，同时我们的微服务还可以定时向nacos配置中心发请求拉取更新的配置信息 限流 限流算法 固定窗口限流\n首先维护一个计数器，将单位时间段当做一个窗口，计数器记录这个窗口接收请求的次数。\n当次数少于限流阀值，就允许访问，并且计数器+1 当次数大于限流阀值，就拒绝访问。 当前的时间窗口过去之后，计数器清零。 滑动窗口限流\n滑动窗口限流解决固定窗口临界值的问题。它将单位时间周期分为n个小周期，分别记录每个小周期内接口的访问次数，并且根据时间滑动删除过期的小周期。\n漏桶算法\n往漏桶中以任意速率流入水，以固定的速率流出水。当水超过桶的容量时，会被溢出，也就是被丢弃。因为桶容量是不变的，保证了整体的速率。\n在正常流量的时候，系统按照固定的速率处理请求，是我们想要的。但是面对突发流量的时候，漏桶算法还是循规蹈矩地处理请求，这就不是我们想看到的啦。流量变突发时，我们肯定希望系统尽量快点处理请求，提升用户体验嘛。\n令牌桶算法\n有一个令牌管理员，根据限流大小，定速往令牌桶里放令牌。如果令牌数量满了，超过令牌桶容量的限制，那就丢弃。系统在接受到一个用户请求时，都会先去令牌桶要一个令牌。如果拿到令牌，那么就处理这个请求的业务逻辑；如果拿不到令牌，就直接拒绝这个请求。\nGateway则采用了基于Redis实现的令牌桶算法，而Sentinel内部却比较复杂：\n默认限流模式是基于滑动时间窗口算法 排队等待的限流模式则基于漏桶算法 而热点参数限流则是基于令牌桶算法 Sentinel vs Hystrix：\nHystix默认是基于线程池实现的线程隔离，每一个被隔离的业务都要创建一个独立的线程池，线程过多会带来额外的CPU开销，性能一般，但是隔离性更强。\nSentinel是基于信号量（计数器）实现的线程隔离，不用创建线程池，性能较好，但是隔离性一般。\n流量控制：\n直接拒绝 冷启动 匀速器 RPC Feign Dubbo 一致性哈希算法 一致性Hash原理与实现 - 简书 (jianshu.com)\n链路追踪 实战 使用nacos、openfegin、gateway、链路追踪管理微服务_你看星星很亮的博客-CSDN博客\n","date":"2022-08-16T16:35:51+08:00","permalink":"https://hifing.github.io/p/springcloud/","title":"SpringCloud"},{"content":"回溯 全排列 II 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 class Solution { List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; res; public void swap(int[] nums, int i, int j) { int tmp = nums[i]; nums[i] = nums[j]; nums[j] = tmp; } public void recur(int[] nums, int index) { if (index == nums.length) { List\u0026lt;Integer\u0026gt; list = new ArrayList\u0026lt;\u0026gt;(); for (int ele : nums) list.add(ele); res.add(list); return; } Set\u0026lt;Integer\u0026gt; set = new HashSet\u0026lt;\u0026gt;(); for (int i = index; i \u0026lt; nums.length; i++) { if (!set.contains(nums[i])) { set.add(nums[i]); swap(nums, index, i); recur(nums, index + 1); swap(nums, index, i); } } } public List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; permuteUnique(int[] nums) { res = new ArrayList\u0026lt;\u0026gt;(); recur(nums, 0); return res; } } 使用Set防止重复元素的操作。\n缺失的第一个正数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 class Solution { public int firstMissingPositive(int[] nums) { int tmp = 0; for (int i = 0; i \u0026lt; nums.length;) { if (nums[i] == i + 1 || nums[i] \u0026gt; nums.length || nums[i] \u0026lt; 1) { i++; continue; } tmp = nums[i]; if (nums[i] == nums[nums[i] - 1]) { i++; continue; } nums[i] = nums[nums[i] - 1]; nums[tmp - 1] = tmp; } for (int i = 0; i \u0026lt; nums.length; i++) { if (nums[i] != i + 1) return i + 1; } return nums.length + 1; } } 运用置换的方法，可以实现O(n)的时间复杂度。 因为当数组每一个位置都正确地放置了该放置的数之后，最小的正数会是数组之外的数，若是数组还有成员没有被正确放置，那么他可能就是答案。\n要注意可能会有无限循环的情况，比如出现重复的数，这个时候只要跳出去本次遍历直接处理下一个就好了。\n","date":"2022-08-16T11:26:43+08:00","permalink":"https://hifing.github.io/p/%E5%9B%9E%E6%BA%AF/","title":"回溯"},{"content":"搜索 二分查找 搜索旋转排序数组 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 class Solution { public int recur(int[] nums, int begin, int end, int target) { if (begin == end) { if (target == nums[begin]) return begin; else return -1; } int mid = (begin + end) \u0026gt;\u0026gt; 1; if (nums[mid] \u0026gt;= nums[begin]) if (nums[begin] \u0026lt;= target \u0026amp;\u0026amp; target \u0026lt;= nums[mid]) return Arrays.binarySearch(nums, begin, end + 1, target); else return recur(nums, mid + 1, end, target); else if (nums[end] \u0026gt;= target \u0026amp;\u0026amp; target \u0026gt;= nums[mid]) return Arrays.binarySearch(nums, begin, end + 1, target); else return recur(nums, begin, mid - 1, target); } public int search(int[] nums, int target) { int res = recur(nums, 0, nums.length - 1, target); return res \u0026gt;= 0 ? res : -1; } } 将旋转数组分为两段，一段必然升序，若在升序段中找不到，则在另一段中再分再找。\n最长递增子序列 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 // O(n^2)的方法为dp，下面用二分优化达到O(nlogn)级别 class Solution { public int lengthOfLIS(int[] nums) { int n = nums.length; int[] record = new int[n]; int index = 0; for (int ele : nums) { int l = 0, r = index; while (l \u0026lt; r) { int mid = (l + r) \u0026gt;\u0026gt; 1; if (ele \u0026gt; record[mid]) l = mid + 1; else r = mid; } record[l] = ele; if (l == index) index++; } return index; } } record的长度就是结果，在过程中更新record中的元素，使之越来越小以满足后面的元素插入数组来拓宽长度，这不影响之前获得的临时最长递增子序列长度的结果。\n寻找两个正序数组的中位数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 class Solution { public double findMedianSortedArrays(int[] nums1, int[] nums2) { int[] less; int[] more; if (nums1.length \u0026lt; nums2.length) { less = nums1; more = nums2; } else { less = nums2; more = nums1; } int n1 = less.length; int n2 = more.length; int left = 0, right = less.length; // 右边会持有单独的中位数 while (left \u0026lt; right) { int mid = (left + right) / 2; int secondIndex = (n1 + n2 - 2 * mid) / 2; if (mid - 1 \u0026gt;= 0 \u0026amp;\u0026amp; secondIndex \u0026lt; n2 \u0026amp;\u0026amp; less[mid - 1] \u0026gt; more[secondIndex]) right = mid - 1; else if (secondIndex - 1 \u0026gt;= 0 \u0026amp;\u0026amp; mid \u0026lt; n1 \u0026amp;\u0026amp; less[mid] \u0026lt; more[secondIndex - 1]) left = mid + 1; else break; } double res = 0; int one = (left + right) / 2; int two = (n1 + n2 - 2 * one) / 2; if ((n1 + n2) % 2 == 1) { // 奇数取右边 res = Math.min((one == n1 ? Integer.MAX_VALUE : less[one]), (two == n2 ? Integer.MAX_VALUE : more[two])); } else { double tmpLeft = Math.max((one == 0 ? Integer.MIN_VALUE : less[one - 1]), (two == 0 ? Integer.MIN_VALUE : more[two - 1])); double tmpRight = Math.min((one == n1 ? Integer.MAX_VALUE : less[one]), (two == n2 ? Integer.MAX_VALUE : more[two])); res = (tmpLeft + tmpRight) / 2; } return res; } } 找到两个数组的index，使得这两个index左侧的数都小于右侧的数。最终结果根据奇偶性分开处理。\n在排序数组中查找元素的第一个和最后一个位置 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 class Solution { public int[] searchRange(int[] nums, int target) { if (nums.length == 0) return new int[]{ -1, -1 }; int l = 0, r = nums.length - 1; while (l \u0026lt; r) { // 位运算优先级低，要用括号包起来 int mid = l + ((r - l) \u0026gt;\u0026gt; 1); if (nums[mid] \u0026gt;= target) r = mid; else l = mid + 1; } int low = -1; if (nums[l] == target) low = l; l = 0; r = nums.length - 1; while (l \u0026lt; r) { // 补一个1，让mid倾向于右边的元素 int mid = l + ((r - l + 1) \u0026gt;\u0026gt; 1); if (nums[mid] \u0026gt; target) r = mid - 1; else l = mid; } int high = -1; if (nums[l] == target) high = l; return new int[] { low, high }; } } 并查集 最大人工岛 先dfs把独立块的大小都计算出来存下来，再计算翻转每个0的时候能获得的联合块的大小。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 // 一种省事一些的并查集方法 // 还没有编写反转0之后的逻辑 public class Main { int[] dr = new int[] { -1, 0, 1, 0 }; int[] dc = new int[] { 0, -1, 0, 1 }; int[][] grid; boolean[][] chk; int[] father; int m; int n; public int maxAreaOfIsland(int[][] grid) { this.grid = grid; m = grid.length; n = grid[0].length; chk = new boolean[m][n]; father = new int[m * n]; Arrays.fill(father, -1); int result = 0; for (int i = 0; i \u0026lt; m; i++) { for (int j = 0; j \u0026lt; n; j++) { if (grid[i][j] == 0 || chk[i][j]) continue; int myIndex = i * n + j; // 携带father下标传下去，dfs过程中，扫到的下标都会变成这个下标 int res = dfs(i, j, myIndex); father[myIndex] = -1 * res; result = Math.max(result, res); } } return result; } public int dfs(int i, int j, int index) { if (i \u0026lt; 0 || i \u0026gt;= m || j \u0026lt; 0 || j \u0026gt;= n || chk[i][j] || grid[i][j] == 0) return 0; int res = 1; int myIndex = i * n + j; father[myIndex] = index; chk[i][j] = true; for (int k = 0; k \u0026lt; 4; k++) { res += dfs(i + dr[k], j + dc[k], index); } return res; } 二维查找 搜索二维矩阵 II 1 2 3 4 5 6 7 8 9 10 11 12 13 public boolean searchMatrix(int[][] matrix, int target) { int x = matrix[0].length - 1; int y = 0; while (y \u0026lt; matrix.length \u0026amp;\u0026amp; x \u0026gt;= 0) { if (matrix[y][x] == target) return true; else if (matrix[y][x] \u0026gt; target) x--; else y++; } return false; } Z字形搜索，控制一个方向为增大，一个方向为减小，这样就不用考虑两个方向同为增大而进行分类讨论了。\n也可以逐行进行二分查找。\n双指针搜索 三数之和\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 func threeSum(nums []int) [][]int { sort.Ints(nums) res := [][]int{} // 找出a + b + c = 0 // a = nums[i], b = nums[left], c = nums[right] for i := 0; i \u0026lt; len(nums)-2; i++ { // 排序之后如果第一个元素已经大于零，那么无论如何组合都不可能凑成三元组，直接返回结果就可以了 n1 := nums[i] if n1 \u0026gt; 0 { break } // 去重a if i \u0026gt; 0 \u0026amp;\u0026amp; n1 == nums[i-1] { continue } l, r := i+1, len(nums)-1 for l \u0026lt; r { n2, n3 := nums[l], nums[r] if n1+n2+n3 == 0 { res = append(res, []int{n1, n2, n3}) // 去重逻辑应该放在找到一个三元组之后，对b 和 c去重 for l \u0026lt; r \u0026amp;\u0026amp; nums[l] == n2 { l++ } for l \u0026lt; r \u0026amp;\u0026amp; nums[r] == n3 { r-- } } else if n1+n2+n3 \u0026lt; 0 { l++ } else { r-- } } } return res } ","date":"2022-08-15T21:19:38+08:00","permalink":"https://hifing.github.io/p/%E6%90%9C%E7%B4%A2/","title":"搜索"},{"content":"链表 翻转链表 K 个一组翻转链表 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 public ListNode reverseKGroup(ListNode head, int k) { if (k == 1 || head == null) return head; ListNode blank = new ListNode(); blank.next = head; int count = k; ListNode last = head; while (count \u0026gt; 0) { last = last.next; --count; if (last == null \u0026amp;\u0026amp; count \u0026gt; 0) return head; } ListNode prev = blank; ListNode now = head; ListNode next = now; while(now!=last){ next = now.next; now.next = prev; prev = now; now = next; } head.next = reverseKGroup(now, k); return prev; } 重排链表 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 //使用Deque更方便，为追求极致的空间复杂度可以先找中点，再反转，再拼接 class Solution { public void reorderList(ListNode head) { Deque\u0026lt;ListNode\u0026gt; deque = new LinkedList\u0026lt;\u0026gt;(); ListNode tmp = head.next; while (tmp != null) { deque.addLast(tmp); tmp = tmp.next; } boolean flag = true; tmp = head; while (!deque.isEmpty()) { tmp.next = (flag ? deque.pollLast() : deque.pollFirst()); tmp = tmp.next; flag = !flag; } tmp.next=null; } } 排序链表 1 2 3 //可以对链表一分为二进行归并排序，在操作的过程中可以断开两个链表的链接，这样处理更加方便 //也可以参考快速排序，用两个空节点收录比pivot大的节点串和比pivot小的节点串，再对这两个串处理，处理之后按照“小-\u0026gt;pivot-\u0026gt;大”这样的顺序组装返回 环形链表找环的入口 环形链表 II 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 public class Solution { public ListNode detectCycle(ListNode head) { if(head == null) return null; ListNode slow = head; ListNode fast = head.next; ListNode empty = new ListNode(); empty.next = head; while (slow != fast \u0026amp;\u0026amp; fast != null) { slow = slow.next; fast = fast.next; if (fast == null) break; fast = fast.next; } if (fast == null) return null; ListNode tmp = empty; while (tmp != fast) { tmp = tmp.next; fast = fast.next; } return tmp; } } LRU缓存机制 使用双向链表和哈希表的方式模拟LRU\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 class Node { Node next; Node prev; int value; int key; } class LRUCache { int capacity; Node head; Node tail; Map\u0026lt;Integer, Node\u0026gt; map; public LRUCache(int capacity) { this.capacity = capacity; head = new Node(); tail = new Node(); head.next = tail; tail.prev = head; map = new HashMap\u0026lt;\u0026gt;(); } // get附带更新最新节点功能 public int get(int key) { if (map.containsKey(key)) { Node target = map.get(key); Node prev = target.prev; Node next = target.next; prev.next = next; next.prev = prev; Node headNext = head.next; head.next = target; target.prev = head; headNext.prev = target; target.next = headNext; return target.value; } else return -1; } public void put(int key, int value) { if (capacity \u0026lt;= 0) return; if (map.containsKey(key)) { Node n = map.get(key); n.value = value; } else { Node tmp = new Node(); tmp.value = value; tmp.key = key; if (capacity == map.size()) { Node last = tail.prev; map.remove(last.key); last.prev.next = last.next; last.next.prev = last.prev; } Node last = tail.prev; last.next = tmp; tmp.prev = last; tmp.next = tail; tail.prev = tmp; map.put(key, tmp); } // 更新时调用一下get即可 get(key); } } ","date":"2022-08-15T10:46:49+08:00","permalink":"https://hifing.github.io/p/%E9%93%BE%E8%A1%A8/","title":"链表"},{"content":"","date":"2022-08-15T01:13:46+08:00","permalink":"https://hifing.github.io/p/%E5%AD%97%E7%AC%A6%E4%B8%B2/","title":"字符串"},{"content":"排序 快速排序 模板题 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 class Solution { private void swap(int[] nums, int a, int b) { int tmp = nums[a]; nums[a] = nums[b]; nums[b] = tmp; } private void fastSort(int[] nums, int l, int r) { if (l \u0026gt;= r) return; // 也可以直接认定pivot为左端点 int start = l, end = r; swap(nums, start, (start + end) / 2); // 指针重合时退出 while (start \u0026lt; end) { // 先动右指针，避免指针重复时左指针指向超过pivot的数字 while (start \u0026lt; end \u0026amp;\u0026amp; nums[end] \u0026gt;= nums[l]) end--; while (start \u0026lt; end \u0026amp;\u0026amp; nums[start] \u0026lt;= nums[l]) start++; swap(nums, start, end); } // 交换左指针和pivot的位置 swap(nums, l, start); fastSort(nums, l, start - 1); fastSort(nums, start + 1, r); } public int[] sortArray(int[] nums) { fastSort(nums, 0, nums.length - 1); return nums; } } 出现频率最高的 k 个数字(TOPK) topK(无序：小顶堆、单分支快排)\n快排变体（单分支快排），当然，本题用堆来做思路非常清晰\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 public int[] topKFrequent(int[] nums, int k) { Map\u0026lt;Integer, Integer\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); for (int num : nums) { map.put(num, map.getOrDefault(num, 0) + 1); } List\u0026lt;int[]\u0026gt; values = new ArrayList\u0026lt;\u0026gt;(); for (Map.Entry\u0026lt;Integer, Integer\u0026gt; entry : map.entrySet()) { int num = entry.getKey(), count = entry.getValue(); values.add(new int[] { num, count }); } findK(k, values); int[] ret = new int[k]; for (int i = 0; i \u0026lt; k; i++) ret[i] = values.get(i)[0]; return ret; } public void findK(int k, List\u0026lt;int[]\u0026gt; values) { int l = 0; int n = values.size(); int r = n - 1; while (l \u0026lt; r) { int index = qsort(l, r, values); if (index == k - 1) return; else if (index \u0026lt; k - 1) l = index + 1; else r = index - 1; } } public int qsort(int l, int r, List\u0026lt;int[]\u0026gt; values) { int pivot = values.get(l)[1]; int start = l; while (l \u0026lt; r) { while (l \u0026lt; r \u0026amp;\u0026amp; values.get(r)[1] \u0026lt;= pivot) r--; while (l \u0026lt; r \u0026amp;\u0026amp; values.get(l)[1] \u0026gt;= pivot) l++; if (l \u0026lt; r) Collections.swap(values, l, r); } Collections.swap(values, start, r); return r; } 堆排序 手撕堆排序 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 class Solution { public void dropDown(int[] nums, int index, int limit) { if (index * 2 + 1 \u0026gt;= limit) return; boolean flag = false; int change = index; if (nums[index] \u0026lt; nums[index * 2 + 1]) { flag = true; change = index * 2 + 1; } if (index * 2 + 2 \u0026lt; limit \u0026amp;\u0026amp; nums[change] \u0026lt; nums[index * 2 + 2]) { flag = true; change = index * 2 + 2; } if (flag) { int tmp = nums[change]; nums[change] = nums[index]; nums[index] = tmp; dropDown(nums, change, limit); } } public int[] sortArray(int[] nums) { int start = (nums.length - 2) / 2; for (; start \u0026gt;= 0; start--) { dropDown(nums, start, nums.length); } for (int i = nums.length - 1; i \u0026gt; 0; i--) { int tmp = nums[i]; nums[i] = nums[0]; nums[0] = tmp; dropDown(nums, 0, i); } return nums; } } ","date":"2022-07-04T16:46:07+08:00","permalink":"https://hifing.github.io/p/%E6%8E%92%E5%BA%8F/","title":"排序"},{"content":"栈与队列 单调栈 直方图最大矩形面积 优化版本\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 class Solution { public int largestRectangleArea(int[] heights) { int res = 0; int n = heights.length; int[] left = new int[n]; int[] right = new int[n]; Arrays.fill(right, n); Deque\u0026lt;Integer\u0026gt; deque = new LinkedList\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; n; i++) { // 记录右边界 while (!deque.isEmpty() \u0026amp;\u0026amp; heights[deque.peekLast()] \u0026gt;= heights[i]) { int top = deque.removeLast(); right[top] = i; } // 因为是单调递增的，所以左边界也确定了 left[i] = deque.isEmpty() ? -1 : deque.peekLast(); deque.addLast(i); } for (int i = 0; i \u0026lt; n; i++) { res = Math.max(res, heights[i] * (right[i] - left[i] - 1)); } return res; } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 class Solution { public int valueOfArray(int[] heights, int index) { if (index \u0026lt; 0) return -1; if (index \u0026gt;= heights.length) return 0; else return heights[index]; } public int largestRectangleArea(int[] heights) { Stack\u0026lt;Integer\u0026gt; stack = new Stack\u0026lt;\u0026gt;(); int res = 0; stack.add(-1); int n = heights.length; for (int i = 0; i \u0026lt;= n; i++) { if (valueOfArray(heights, i) \u0026gt; valueOfArray(heights, stack.peek())) stack.push(i); else { while (valueOfArray(heights, i) \u0026lt;= valueOfArray(heights, stack.peek())) { int top = valueOfArray(heights, stack.pop()); int width = i - stack.peek() - 1; res = Math.max(res, top * width); } stack.push(i); } } return res; } } 接雨水 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 //单调栈做法 public int trap(int[] height) { int res = 0; Stack\u0026lt;Integer\u0026gt; stk = new Stack\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; height.length; i++) { while (!stk.isEmpty()) { if (height[i] \u0026lt; height[stk.peek()]) break; int index = stk.pop(); if (stk.isEmpty()) break; int minHeight = Math.min(height[i], height[stk.peek()]); res += (minHeight - height[index]) * (i - stk.peek() - 1); } stk.add(i); } return res; } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 //双指针做法 class Solution { public int trap(int[] height) { int res = 0; int left = 0, right = height.length - 1; int leftMax = height[left], rightMax = height[right]; while (left \u0026lt;= right) { while (leftMax \u0026lt;= rightMax \u0026amp;\u0026amp; left \u0026lt;= right) { if (height[left] \u0026gt; leftMax) { leftMax = height[left]; } else { res += (leftMax - height[left]); } left++; } while (leftMax \u0026gt; rightMax \u0026amp;\u0026amp; left \u0026lt;= right) { if (height[right] \u0026gt; rightMax) { rightMax = height[right]; } else { res += (rightMax - height[right]); } right--; } } return res; } } //稍微优雅一些的写法 public int trap(int[] height) { int res = 0; int left = 0, leftMax = height[left], right = height.length - 1, rightMax = height[right]; while (left \u0026lt;= right) { leftMax = Math.max(leftMax, height[left]); rightMax = Math.max(rightMax, height[right]); if (leftMax \u0026gt; rightMax) res += rightMax - height[right--]; else res += leftMax - height[left++]; } return res; } 单调队列 滑动窗口最大值 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 class Solution { public int[] maxSlidingWindow(int[] nums, int k) { Deque\u0026lt;Integer\u0026gt; deque = new LinkedList\u0026lt;\u0026gt;(); List\u0026lt;Integer\u0026gt; res = new ArrayList\u0026lt;\u0026gt;(); int i = 0; for (; i \u0026lt; k; i++) { while (!deque.isEmpty() \u0026amp;\u0026amp; deque.peekLast() \u0026lt; nums[i]) deque.pollLast(); deque.addLast(nums[i]); } res.add(deque.peekFirst()); for (; i \u0026lt; nums.length; i++) { if (deque.peekFirst() == nums[i - k]) deque.pollFirst(); while (!deque.isEmpty() \u0026amp;\u0026amp; deque.peekLast() \u0026lt; nums[i]) deque.pollLast(); deque.addLast(nums[i]); res.add(deque.peekFirst()); } int[] resArray = new int[res.size()]; for (int j = 0; j \u0026lt; res.size(); j++) { resArray[j] = res.get(j); } return resArray; } } 滑动窗口滑动的过程中势必要记录下新进来的元素，删除被挤出的元素，只不过在收入新进来的元素的时候先保持滑动窗口中的最大值不小于这个元素，这样一来小的元素就无需被队列记录下来了。等到这个元素出去的时候再比对队首元素与之是否相同，若相同则直接删掉就好了。遇到重复的值的时候也要记录下来，防止一个被弹出另一个不知道。\n栈 最长有效括号 让没有用的元素垫底作为界定标准，先弹栈再计算\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 class Solution { public int longestValidParentheses(String s) { Stack\u0026lt;Integer\u0026gt; stk = new Stack\u0026lt;\u0026gt;(); stk.push(-1); int res = 0; for (int i = 0; i \u0026lt; s.length(); i++) { if (s.charAt(i) == \u0026#39;(\u0026#39;) { stk.push(i); } else { stk.pop(); if (!stk.isEmpty()) { res = Math.max(res, i - stk.peek()); } else { stk.push(i); } } } return res; } } 本题还可以使用DP来做，当遇到右括号的时候，记录下与之匹配的左括号的位置，倘若在这个过程中找到了之前的一个已经匹配完成的右括号，则顺着它继续往前面找，直到找到一个左括号，找不到左括号就记为0.\n还可以根据贪心来做，从左边开始扫描，记录下左括号数目和右括号数目，当两者相等时，记录下此时的长度，当右括号数目大一些时，清零。因为会遇到“（（）”这种情况使得算不出结果，因此需要从右往左再进行一次相对的扫描。\n","date":"2022-07-04T16:04:44+08:00","permalink":"https://hifing.github.io/p/%E6%A0%88%E4%B8%8E%E9%98%9F%E5%88%97/","title":"栈与队列"},{"content":"小妙招 枚举结果（20220820网易：a和b选其一去除掉一个数位使得他们能是某一方的倍数） count设为long类型 ","date":"2022-07-04T12:10:40+08:00","permalink":"https://hifing.github.io/p/%E5%B0%8F%E5%A6%99%E6%8B%9B/","title":"小妙招"},{"content":"树 序列化与反序列化 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 class TreeNode { int val; TreeNode left; TreeNode right; TreeNode(int x) { val = x; } } class Codec { // Encodes a tree to a single string. public String serialize(TreeNode root) { Queue\u0026lt;TreeNode\u0026gt; queue = new LinkedList\u0026lt;\u0026gt;(); StringBuilder sb = new StringBuilder(); queue.add(root); while (!queue.isEmpty()) { TreeNode tn = queue.remove(); if (tn == null) { sb.append(\u0026#34;*,\u0026#34;); } else { sb.append(tn.val + \u0026#34;,\u0026#34;); queue.add(tn.left); queue.add(tn.right); } } System.out.println(sb.toString()); return sb.toString(); } // Decodes your encoded data to tree. public TreeNode deserialize(String data) { if (data.length() == 0) return null; String[] strs = data.split(\u0026#34;,\u0026#34;); int n = strs.length; if (strs[0].equals(\u0026#34;*\u0026#34;)) return null; TreeNode head = new TreeNode(Integer.valueOf(strs[0])); Queue\u0026lt;TreeNode\u0026gt; queue = new LinkedList\u0026lt;\u0026gt;(); queue.add(head); int index = 1; while (!queue.isEmpty() \u0026amp;\u0026amp; index \u0026lt; n) { TreeNode tn = queue.remove(); TreeNode left = (strs[index].equals(\u0026#34;*\u0026#34;) ? null : new TreeNode(Integer.valueOf(strs[index]))); index++; TreeNode right = (strs[index].equals(\u0026#34;*\u0026#34;) ? null : new TreeNode(Integer.valueOf(strs[index]))); index++; tn.left = left; tn.right = right; if (left != null) queue.add(left); if (right != null) queue.add(right); } return head; } } 树的搜索 LCA：二叉树的最近公共祖先 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class Solution { public TreeNode lowestCommonAncestor(TreeNode root, TreeNode p, TreeNode q) { if (root == null) return root; if (root == p || root == q) return root; TreeNode left = lowestCommonAncestor(root.left, p, q); TreeNode right = lowestCommonAncestor(root.right, p, q); if (left != null \u0026amp;\u0026amp; right != null) return root; if (left != null) return left; if (right != null) return right; return null; } } 二叉树中的最大路径和 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 final int minimum = -1000; int res = minimum; public int search(TreeNode root) { if (root == null) return minimum; int left = search(root.left); int right = search(root.right); int maximumCombine = Math.max(0, Math.max(left, right)) + root.val; res = Math.max(res, Math.max(maximumCombine, left + right + root.val)); return maximumCombine; } public int maxPathSum(TreeNode root) { search(root); return res; } 更新res的时候有多种情况。返回上层时要确保root在计算结果中，以便上层能够连接子树结果。\n验证二叉搜索树 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class Solution { public boolean chk(TreeNode root, long min, long max) { if (root == null) return true; if (root.val \u0026gt;= max || root.val \u0026lt;= min) return false; return chk(root.left, min, root.val) \u0026amp;\u0026amp; chk(root.right, root.val, max); } public boolean isValidBST(TreeNode root) { if (root == null) return true; return chk(root, Long.MIN_VALUE, Long.MAX_VALUE); } } 递归的时候把上下界传下去。\n二叉树最大宽度 DFS思路：按照先序，记录每层次最左侧的节点的满二叉树中的下标到Map中，若是已经有了，则减去已有的作为一个tmpResult。\nBFS思路：按照层次遍历，入队时记录下满二叉树对应的下标，每一层最后一个元素和第一个元素下标做差。\n","date":"2022-07-04T12:10:40+08:00","permalink":"https://hifing.github.io/p/%E6%A0%91/","title":"树"},{"content":"动态规划 串 回文子字符串的个数 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 // dp[i][j]表示形如“......，A[i]，A[j]”的序列 public int lenLongestFibSubseq(int[] arr) { int n = arr.length; Map\u0026lt;Integer, Integer\u0026gt; map = new HashMap\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; n; i++) { map.putIfAbsent(arr[i], i); } int res = 0; Map\u0026lt;Integer, Integer\u0026gt; longest = new HashMap\u0026lt;\u0026gt;(); for (int i = 0; i \u0026lt; n; i++) { for (int j = 0; j \u0026lt; i; j++) { int index = map.getOrDefault(arr[i] - arr[j], -1); if (index \u0026gt;= 0 \u0026amp;\u0026amp; index \u0026lt; j) { int length = longest.getOrDefault(index * n + j, 2) + 1; longest.put(j * n + i, length); res = Math.max(res, length); } } } return res; } public int countSubstrings(String s) { int n = s.length(); char[] str = s.toCharArray(); int[][] dp = new int[n][n]; int res = n; for (int i = 0; i \u0026lt; n; i++) { dp[i][i] = 1; } for (int i = 0; i \u0026lt; n; i++) { for (int j = i - 1; j \u0026gt;= 0; j--) { if (str[i] == str[j]) { if (j == i - 1) { dp[j][i] = 1; res++; } else if (dp[j + 1][i - 1] == 1) { dp[j][i] = 1; res++; } } } } return res; } 关联题：最长回文子串 （也可使用中心扩展的方法获取，要分奇偶两种情况）\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 class Solution { char[] seq; private int findLength(int start, boolean flag) { int left = start - (flag ? 1 : 0); int right = start; int length = (left == right ? -1 : 0); while (left \u0026gt;= 0 \u0026amp;\u0026amp; right \u0026lt; seq.length) { if (seq[left] == seq[right]) { length += 2; left--; right++; } else break; } return length; } public String longestPalindrome(String s) { seq = s.toCharArray(); int nowMax = 0; int index = 0; for (int i = 0; i \u0026lt; seq.length; i++) { int singled = findLength(i, true); int doubled = findLength(i, false); if (singled \u0026gt; nowMax) { index = i; nowMax = singled; } if (doubled \u0026gt; nowMax) { index = i; nowMax = doubled; } } return s.substring(index - (nowMax / 2), index - (nowMax / 2) + nowMax); } } 最长公共子序列 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class Solution { public int longestCommonSubsequence(String text1, String text2) { char[] s1, s2; s1 = text1.toCharArray(); s2 = text2.toCharArray(); int[][] dp = new int[s1.length + 1][s2.length + 1]; for (int i = 1; i \u0026lt;= s1.length; i++) { for (int j = 1; j \u0026lt;= s2.length; j++) { dp[i][j] = Math.max(dp[i][j - 1], dp[i - 1][j]); dp[i][j] = Math.max(dp[i][j], dp[i - 1][j - 1] + (s1[i - 1] == s2[j - 1] ? 1 : 0)); } } return dp[s1.length][s2.length]; } } 处理i、j处的时候，分三种情况讨论，（i，j-1），（i-1，j），（i-1，j-1）\n矩阵 矩阵中的距离 1 2 输入：mat = [[0,0,0],[0,1,0],[1,1,1]] 输出：[[0,0,0],[0,1,0],[1,2,1]] 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 class Solution { public int[][] updateMatrix(int[][] mat) { int m = mat.length; int n = mat[0].length; int dp[][] = new int[m][n]; for (int i = 0; i \u0026lt; m; i++) { for (int j = 0; j \u0026lt; n; j++) { if (mat[i][j] == 0) continue; if (i == 0 \u0026amp;\u0026amp; j == 0 \u0026amp;\u0026amp; mat[0][0] != 0) { dp[0][0] = m + n; continue; } int up = (i == 0 ? m + n : dp[i - 1][j]); int left = (j == 0 ? m + n : dp[i][j - 1]); dp[i][j] = Math.min(up, left) + 1; } } for (int i = m - 1; i \u0026gt;= 0; i--) { for (int j = n - 1; j \u0026gt;= 0; j--) { if (i == m - 1 \u0026amp;\u0026amp; j == n - 1) continue; int down = (i == m - 1 ? m + n : dp[i + 1][j]); int right = (j == n - 1 ? m + n : dp[i][j + 1]); dp[i][j] = Math.min(dp[i][j], Math.min(down, right) + 1); } } return dp; } } 背包 背包问题总结：『 一文搞懂完全背包问题 』从0-1背包到完全背包，逐层深入+数学推导 - 最少的硬币数目 - 力扣（LeetCode）\n最少的硬币数目(完全背包数个数) 1 2 3 给定不同面额的硬币 coins 和一个总金额 amount。编写一个函数来计算可以凑成总金额所需的最少的硬币个数。如果没有任何一种硬币组合能组成总金额，返回 -1。 你可以认为每种硬币的数量是无限的。 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 class Solution { public int coinChange(int[] coins, int amount) { int[] dp = new int[amount + 1]; Arrays.fill(dp, Integer.MAX_VALUE); dp[0] = 0; for (int k = 0; k \u0026lt; coins.length; k++) { for (int i = 1; i \u0026lt;= amount; i++) { if (i - coins[k] \u0026lt; 0 || dp[i - coins[k]] == Integer.MAX_VALUE) continue; dp[i] = Math.min(dp[i], dp[i - coins[k]] + 1); } } return dp[amount] == Integer.MAX_VALUE ? -1 : dp[amount]; } } public int coinChange(int[] coins, int amount) { int[] dp = new int[amount + 1]; Arrays.fill(dp, Integer.MAX_VALUE); dp[0] = 0; for (int i = 1; i \u0026lt;= amount; i++) { for (int k = 0; k \u0026lt; coins.length; k++) { if (i - coins[k] \u0026lt; 0 || dp[i - coins[k]] == Integer.MAX_VALUE) continue; dp[i] = Math.min(dp[i], dp[i - coins[k]] + 1); } } return dp[amount] == Integer.MAX_VALUE ? -1 : dp[amount]; } 背包变体：剑指 Offer II 102. 加减的目标值 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 class Solution { public int findTargetSumWays(int[] nums, int target) { int sum = 0; for (int ele : nums) sum += ele; if (target \u0026gt; sum || target \u0026lt; sum * -1) return 0; int[][] dp = new int[nums.length + 1][sum * 2 + 1]; dp[0][sum] = 1; for (int i = 1; i \u0026lt;= nums.length; i++) { for (int j = 0; j \u0026lt; sum * 2 + 1; j++) { int tmp = 0; // nums[i - 1]为当前元素 if (j - nums[i - 1] \u0026gt;= 0) tmp += dp[i - 1][j - nums[i - 1]]; if (j + nums[i - 1] \u0026lt; sum * 2 + 1) tmp += dp[i - 1][j + nums[i - 1]]; dp[i][j] = tmp; } } return dp[nums.length][target + sum]; } } //优化：只考虑正或负 class Solution { public int findTargetSumWays(int[] nums, int target) { int sum = 0; for (int ele : nums) sum += ele; if (target \u0026gt; sum || target \u0026lt; sum * -1 || (target + sum) % 2 == 1) return 0; int pos = (target + sum) / 2; int[][] dp = new int[nums.length + 1][pos + 1]; dp[0][0] = 1; for (int i = 1; i \u0026lt;= nums.length; i++) { for (int j = 0; j \u0026lt; pos + 1; j++) { dp[i][j] += dp[i - 1][j]; if (j - nums[i - 1] \u0026gt;= 0) { dp[i][j] += dp[i - 1][j - nums[i - 1]]; } } } return dp[nums.length][pos]; } } 关联题目：416. 分割等和子集\n少状态DP 买卖股票的最佳时机 II 1 2 3 4 5 6 7 8 9 10 11 public int maxProfit(int[] prices) { int[] buy = new int[prices.length]; int[] sell = new int[prices.length]; buy[0] = -1 * prices[0]; sell[0] = 0; for (int i = 1; i \u0026lt; prices.length; i++) { buy[i] = Math.max(sell[i - 1] - prices[i], buy[i - 1]); sell[i] = Math.max(sell[i - 1], buy[i - 1] + prices[i]); } return sell[prices.length - 1]; } 两个状态，持有股票和不持有股票\n乘积最大子数组 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 class Solution { public int maxProduct(int[] nums) { int positiveMax = 0; int negativeMax = 0; int maximun = nums[0]; int tmp = 0; if (maximun \u0026gt; 0) positiveMax = maximun; else negativeMax = maximun; for (int i = 1; i \u0026lt; nums.length; i++) { if (nums[i] \u0026gt; 0) { negativeMax = negativeMax * nums[i]; positiveMax = Math.max(positiveMax * nums[i], nums[i]); } else if (nums[i] \u0026lt; 0) { tmp = negativeMax * nums[i]; negativeMax = Math.min(positiveMax * nums[i], nums[i]); positiveMax = tmp; } else { negativeMax = 0; positiveMax = 0; } maximun = Math.max(maximun, positiveMax); } return maximun; } } ","date":"2022-06-12T21:20:31+08:00","permalink":"https://hifing.github.io/p/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/","title":"动态规划"}]